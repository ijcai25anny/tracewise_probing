{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 2900,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006896551724137931,
      "grad_norm": 0.25986140966415405,
      "learning_rate": 1.999985279873006e-05,
      "loss": 0.6825,
      "step": 10
    },
    {
      "epoch": 0.013793103448275862,
      "grad_norm": 0.2245662361383438,
      "learning_rate": 1.999867521457224e-05,
      "loss": 0.6165,
      "step": 20
    },
    {
      "epoch": 0.020689655172413793,
      "grad_norm": 0.2505818009376526,
      "learning_rate": 1.9996320184929093e-05,
      "loss": 0.5678,
      "step": 30
    },
    {
      "epoch": 0.027586206896551724,
      "grad_norm": 0.2380511462688446,
      "learning_rate": 1.9992787987129253e-05,
      "loss": 0.5139,
      "step": 40
    },
    {
      "epoch": 0.034482758620689655,
      "grad_norm": 0.2453131079673767,
      "learning_rate": 1.9988079037124866e-05,
      "loss": 0.5029,
      "step": 50
    },
    {
      "epoch": 0.041379310344827586,
      "grad_norm": 0.20972944796085358,
      "learning_rate": 1.9982193889442583e-05,
      "loss": 0.4713,
      "step": 60
    },
    {
      "epoch": 0.04827586206896552,
      "grad_norm": 0.22748492658138275,
      "learning_rate": 1.9975133237118276e-05,
      "loss": 0.4509,
      "step": 70
    },
    {
      "epoch": 0.05517241379310345,
      "grad_norm": 0.2263898253440857,
      "learning_rate": 1.9966897911615417e-05,
      "loss": 0.455,
      "step": 80
    },
    {
      "epoch": 0.06206896551724138,
      "grad_norm": 0.2492675632238388,
      "learning_rate": 1.9957488882727163e-05,
      "loss": 0.4621,
      "step": 90
    },
    {
      "epoch": 0.06896551724137931,
      "grad_norm": 0.24973267316818237,
      "learning_rate": 1.994690725846216e-05,
      "loss": 0.4496,
      "step": 100
    },
    {
      "epoch": 0.07586206896551724,
      "grad_norm": 0.2791566252708435,
      "learning_rate": 1.9935154284914063e-05,
      "loss": 0.4404,
      "step": 110
    },
    {
      "epoch": 0.08275862068965517,
      "grad_norm": 0.2903839647769928,
      "learning_rate": 1.9922231346114795e-05,
      "loss": 0.4426,
      "step": 120
    },
    {
      "epoch": 0.0896551724137931,
      "grad_norm": 0.2672344744205475,
      "learning_rate": 1.9908139963871547e-05,
      "loss": 0.4378,
      "step": 130
    },
    {
      "epoch": 0.09655172413793103,
      "grad_norm": 0.2837745249271393,
      "learning_rate": 1.98928817975876e-05,
      "loss": 0.4235,
      "step": 140
    },
    {
      "epoch": 0.10344827586206896,
      "grad_norm": 0.2880101501941681,
      "learning_rate": 1.9876458644066896e-05,
      "loss": 0.4314,
      "step": 150
    },
    {
      "epoch": 0.1103448275862069,
      "grad_norm": 0.37688112258911133,
      "learning_rate": 1.985887243730244e-05,
      "loss": 0.429,
      "step": 160
    },
    {
      "epoch": 0.11724137931034483,
      "grad_norm": 0.3042563498020172,
      "learning_rate": 1.9840125248248564e-05,
      "loss": 0.42,
      "step": 170
    },
    {
      "epoch": 0.12413793103448276,
      "grad_norm": 0.3467246890068054,
      "learning_rate": 1.9820219284577052e-05,
      "loss": 0.4184,
      "step": 180
    },
    {
      "epoch": 0.1310344827586207,
      "grad_norm": 0.3302839994430542,
      "learning_rate": 1.9799156890417156e-05,
      "loss": 0.4267,
      "step": 190
    },
    {
      "epoch": 0.13793103448275862,
      "grad_norm": 0.31286633014678955,
      "learning_rate": 1.9776940546079552e-05,
      "loss": 0.413,
      "step": 200
    },
    {
      "epoch": 0.14482758620689656,
      "grad_norm": 0.2989582121372223,
      "learning_rate": 1.975357286776427e-05,
      "loss": 0.4067,
      "step": 210
    },
    {
      "epoch": 0.15172413793103448,
      "grad_norm": 0.3084734082221985,
      "learning_rate": 1.972905660725259e-05,
      "loss": 0.4188,
      "step": 220
    },
    {
      "epoch": 0.15862068965517243,
      "grad_norm": 0.3202539086341858,
      "learning_rate": 1.970339465158301e-05,
      "loss": 0.4155,
      "step": 230
    },
    {
      "epoch": 0.16551724137931034,
      "grad_norm": 0.3674808144569397,
      "learning_rate": 1.967659002271126e-05,
      "loss": 0.413,
      "step": 240
    },
    {
      "epoch": 0.1724137931034483,
      "grad_norm": 0.3256385326385498,
      "learning_rate": 1.9648645877154435e-05,
      "loss": 0.4026,
      "step": 250
    },
    {
      "epoch": 0.1793103448275862,
      "grad_norm": 0.3494366705417633,
      "learning_rate": 1.9619565505619288e-05,
      "loss": 0.4132,
      "step": 260
    },
    {
      "epoch": 0.18620689655172415,
      "grad_norm": 0.3614308536052704,
      "learning_rate": 1.9589352332614708e-05,
      "loss": 0.3964,
      "step": 270
    },
    {
      "epoch": 0.19310344827586207,
      "grad_norm": 0.3807845115661621,
      "learning_rate": 1.955800991604846e-05,
      "loss": 0.4017,
      "step": 280
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.3832167088985443,
      "learning_rate": 1.9525541946808187e-05,
      "loss": 0.3921,
      "step": 290
    },
    {
      "epoch": 0.20689655172413793,
      "grad_norm": 0.4200301170349121,
      "learning_rate": 1.9491952248326805e-05,
      "loss": 0.4017,
      "step": 300
    },
    {
      "epoch": 0.21379310344827587,
      "grad_norm": 0.3838615119457245,
      "learning_rate": 1.9457244776132208e-05,
      "loss": 0.4046,
      "step": 310
    },
    {
      "epoch": 0.2206896551724138,
      "grad_norm": 0.39885830879211426,
      "learning_rate": 1.942142361738151e-05,
      "loss": 0.392,
      "step": 320
    },
    {
      "epoch": 0.22758620689655173,
      "grad_norm": 0.4205036759376526,
      "learning_rate": 1.9384492990379703e-05,
      "loss": 0.4044,
      "step": 330
    },
    {
      "epoch": 0.23448275862068965,
      "grad_norm": 0.477316290140152,
      "learning_rate": 1.934645724408294e-05,
      "loss": 0.4102,
      "step": 340
    },
    {
      "epoch": 0.2413793103448276,
      "grad_norm": 0.3743092119693756,
      "learning_rate": 1.9307320857586377e-05,
      "loss": 0.4084,
      "step": 350
    },
    {
      "epoch": 0.2482758620689655,
      "grad_norm": 0.3562770187854767,
      "learning_rate": 1.9267088439596728e-05,
      "loss": 0.3943,
      "step": 360
    },
    {
      "epoch": 0.25517241379310346,
      "grad_norm": 0.43415212631225586,
      "learning_rate": 1.9225764727889543e-05,
      "loss": 0.3885,
      "step": 370
    },
    {
      "epoch": 0.2620689655172414,
      "grad_norm": 0.4256402850151062,
      "learning_rate": 1.9183354588751274e-05,
      "loss": 0.3949,
      "step": 380
    },
    {
      "epoch": 0.2689655172413793,
      "grad_norm": 0.3931458294391632,
      "learning_rate": 1.9139863016406237e-05,
      "loss": 0.3866,
      "step": 390
    },
    {
      "epoch": 0.27586206896551724,
      "grad_norm": 0.3857537508010864,
      "learning_rate": 1.9095295132428485e-05,
      "loss": 0.416,
      "step": 400
    },
    {
      "epoch": 0.2827586206896552,
      "grad_norm": 0.39333099126815796,
      "learning_rate": 1.904965618513868e-05,
      "loss": 0.3894,
      "step": 410
    },
    {
      "epoch": 0.2896551724137931,
      "grad_norm": 0.4077732563018799,
      "learning_rate": 1.900295154898607e-05,
      "loss": 0.3921,
      "step": 420
    },
    {
      "epoch": 0.296551724137931,
      "grad_norm": 0.43032097816467285,
      "learning_rate": 1.8955186723915573e-05,
      "loss": 0.3952,
      "step": 430
    },
    {
      "epoch": 0.30344827586206896,
      "grad_norm": 0.4315658211708069,
      "learning_rate": 1.8906367334720125e-05,
      "loss": 0.3899,
      "step": 440
    },
    {
      "epoch": 0.3103448275862069,
      "grad_norm": 0.4788299798965454,
      "learning_rate": 1.885649913037827e-05,
      "loss": 0.3798,
      "step": 450
    },
    {
      "epoch": 0.31724137931034485,
      "grad_norm": 0.44563788175582886,
      "learning_rate": 1.8805587983377208e-05,
      "loss": 0.397,
      "step": 460
    },
    {
      "epoch": 0.32413793103448274,
      "grad_norm": 0.47785791754722595,
      "learning_rate": 1.8753639889021197e-05,
      "loss": 0.3823,
      "step": 470
    },
    {
      "epoch": 0.3310344827586207,
      "grad_norm": 0.40599074959754944,
      "learning_rate": 1.8700660964725583e-05,
      "loss": 0.3839,
      "step": 480
    },
    {
      "epoch": 0.33793103448275863,
      "grad_norm": 0.4306589961051941,
      "learning_rate": 1.8646657449296394e-05,
      "loss": 0.3823,
      "step": 490
    },
    {
      "epoch": 0.3448275862068966,
      "grad_norm": 0.39206013083457947,
      "learning_rate": 1.8591635702195672e-05,
      "loss": 0.3788,
      "step": 500
    },
    {
      "epoch": 0.35172413793103446,
      "grad_norm": 0.42218318581581116,
      "learning_rate": 1.8535602202792567e-05,
      "loss": 0.3822,
      "step": 510
    },
    {
      "epoch": 0.3586206896551724,
      "grad_norm": 0.38796889781951904,
      "learning_rate": 1.8478563549600318e-05,
      "loss": 0.3778,
      "step": 520
    },
    {
      "epoch": 0.36551724137931035,
      "grad_norm": 0.4690000116825104,
      "learning_rate": 1.8420526459499252e-05,
      "loss": 0.3967,
      "step": 530
    },
    {
      "epoch": 0.3724137931034483,
      "grad_norm": 0.4182768762111664,
      "learning_rate": 1.8361497766945747e-05,
      "loss": 0.3966,
      "step": 540
    },
    {
      "epoch": 0.3793103448275862,
      "grad_norm": 0.3974815607070923,
      "learning_rate": 1.8301484423167456e-05,
      "loss": 0.3792,
      "step": 550
    },
    {
      "epoch": 0.38620689655172413,
      "grad_norm": 0.44838395714759827,
      "learning_rate": 1.8240493495344695e-05,
      "loss": 0.3905,
      "step": 560
    },
    {
      "epoch": 0.3931034482758621,
      "grad_norm": 0.4924449920654297,
      "learning_rate": 1.8178532165778225e-05,
      "loss": 0.3879,
      "step": 570
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.4020562767982483,
      "learning_rate": 1.811560773104346e-05,
      "loss": 0.3911,
      "step": 580
    },
    {
      "epoch": 0.4068965517241379,
      "grad_norm": 0.46688976883888245,
      "learning_rate": 1.8051727601131228e-05,
      "loss": 0.3757,
      "step": 590
    },
    {
      "epoch": 0.41379310344827586,
      "grad_norm": 0.464694082736969,
      "learning_rate": 1.798689929857516e-05,
      "loss": 0.3846,
      "step": 600
    },
    {
      "epoch": 0.4206896551724138,
      "grad_norm": 0.42135539650917053,
      "learning_rate": 1.7921130457565835e-05,
      "loss": 0.3856,
      "step": 610
    },
    {
      "epoch": 0.42758620689655175,
      "grad_norm": 0.4264330565929413,
      "learning_rate": 1.785442882305179e-05,
      "loss": 0.3881,
      "step": 620
    },
    {
      "epoch": 0.43448275862068964,
      "grad_norm": 0.4577576518058777,
      "learning_rate": 1.7786802249827454e-05,
      "loss": 0.3768,
      "step": 630
    },
    {
      "epoch": 0.4413793103448276,
      "grad_norm": 0.4607911705970764,
      "learning_rate": 1.771825870160819e-05,
      "loss": 0.3945,
      "step": 640
    },
    {
      "epoch": 0.4482758620689655,
      "grad_norm": 0.5085627436637878,
      "learning_rate": 1.764880625009245e-05,
      "loss": 0.3829,
      "step": 650
    },
    {
      "epoch": 0.45517241379310347,
      "grad_norm": 0.49145862460136414,
      "learning_rate": 1.7578453074011302e-05,
      "loss": 0.3787,
      "step": 660
    },
    {
      "epoch": 0.46206896551724136,
      "grad_norm": 0.5938476920127869,
      "learning_rate": 1.7507207458165257e-05,
      "loss": 0.3708,
      "step": 670
    },
    {
      "epoch": 0.4689655172413793,
      "grad_norm": 0.4699800908565521,
      "learning_rate": 1.7435077792448666e-05,
      "loss": 0.3825,
      "step": 680
    },
    {
      "epoch": 0.47586206896551725,
      "grad_norm": 0.3884252905845642,
      "learning_rate": 1.736207257086173e-05,
      "loss": 0.3833,
      "step": 690
    },
    {
      "epoch": 0.4827586206896552,
      "grad_norm": 0.49611642956733704,
      "learning_rate": 1.7288200390510227e-05,
      "loss": 0.367,
      "step": 700
    },
    {
      "epoch": 0.4896551724137931,
      "grad_norm": 0.4932497441768646,
      "learning_rate": 1.7213469950593156e-05,
      "loss": 0.3739,
      "step": 710
    },
    {
      "epoch": 0.496551724137931,
      "grad_norm": 0.5233703255653381,
      "learning_rate": 1.7137890051378264e-05,
      "loss": 0.3795,
      "step": 720
    },
    {
      "epoch": 0.503448275862069,
      "grad_norm": 0.43705323338508606,
      "learning_rate": 1.706146959316576e-05,
      "loss": 0.3769,
      "step": 730
    },
    {
      "epoch": 0.5103448275862069,
      "grad_norm": 0.495534747838974,
      "learning_rate": 1.6984217575240212e-05,
      "loss": 0.3762,
      "step": 740
    },
    {
      "epoch": 0.5172413793103449,
      "grad_norm": 0.5722330212593079,
      "learning_rate": 1.6906143094810774e-05,
      "loss": 0.3778,
      "step": 750
    },
    {
      "epoch": 0.5241379310344828,
      "grad_norm": 0.48170068860054016,
      "learning_rate": 1.6827255345939915e-05,
      "loss": 0.3905,
      "step": 760
    },
    {
      "epoch": 0.5310344827586206,
      "grad_norm": 0.4593237638473511,
      "learning_rate": 1.674756361846071e-05,
      "loss": 0.3852,
      "step": 770
    },
    {
      "epoch": 0.5379310344827586,
      "grad_norm": 0.49725160002708435,
      "learning_rate": 1.666707729688289e-05,
      "loss": 0.3864,
      "step": 780
    },
    {
      "epoch": 0.5448275862068965,
      "grad_norm": 0.46600109338760376,
      "learning_rate": 1.658580585928768e-05,
      "loss": 0.378,
      "step": 790
    },
    {
      "epoch": 0.5517241379310345,
      "grad_norm": 0.4578360617160797,
      "learning_rate": 1.650375887621171e-05,
      "loss": 0.3825,
      "step": 800
    },
    {
      "epoch": 0.5586206896551724,
      "grad_norm": 0.4953911006450653,
      "learning_rate": 1.642094600951994e-05,
      "loss": 0.3781,
      "step": 810
    },
    {
      "epoch": 0.5655172413793104,
      "grad_norm": 0.4881383180618286,
      "learning_rate": 1.6337377011267924e-05,
      "loss": 0.3782,
      "step": 820
    },
    {
      "epoch": 0.5724137931034483,
      "grad_norm": 0.4408045709133148,
      "learning_rate": 1.6253061722553353e-05,
      "loss": 0.386,
      "step": 830
    },
    {
      "epoch": 0.5793103448275863,
      "grad_norm": 0.48442211747169495,
      "learning_rate": 1.6168010072357216e-05,
      "loss": 0.3778,
      "step": 840
    },
    {
      "epoch": 0.5862068965517241,
      "grad_norm": 0.515523374080658,
      "learning_rate": 1.6082232076374532e-05,
      "loss": 0.3751,
      "step": 850
    },
    {
      "epoch": 0.593103448275862,
      "grad_norm": 0.4976244568824768,
      "learning_rate": 1.5995737835834905e-05,
      "loss": 0.375,
      "step": 860
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.49944084882736206,
      "learning_rate": 1.590853753631301e-05,
      "loss": 0.3754,
      "step": 870
    },
    {
      "epoch": 0.6068965517241379,
      "grad_norm": 0.5322442650794983,
      "learning_rate": 1.5820641446529127e-05,
      "loss": 0.3712,
      "step": 880
    },
    {
      "epoch": 0.6137931034482759,
      "grad_norm": 0.4798501133918762,
      "learning_rate": 1.5732059917139912e-05,
      "loss": 0.3717,
      "step": 890
    },
    {
      "epoch": 0.6206896551724138,
      "grad_norm": 0.49069833755493164,
      "learning_rate": 1.564280337951948e-05,
      "loss": 0.3679,
      "step": 900
    },
    {
      "epoch": 0.6275862068965518,
      "grad_norm": 0.4662247896194458,
      "learning_rate": 1.5552882344531023e-05,
      "loss": 0.3726,
      "step": 910
    },
    {
      "epoch": 0.6344827586206897,
      "grad_norm": 0.4949148893356323,
      "learning_rate": 1.546230740128904e-05,
      "loss": 0.3826,
      "step": 920
    },
    {
      "epoch": 0.6413793103448275,
      "grad_norm": 0.471737802028656,
      "learning_rate": 1.5371089215912363e-05,
      "loss": 0.3632,
      "step": 930
    },
    {
      "epoch": 0.6482758620689655,
      "grad_norm": 0.4977237284183502,
      "learning_rate": 1.5279238530268112e-05,
      "loss": 0.3652,
      "step": 940
    },
    {
      "epoch": 0.6551724137931034,
      "grad_norm": 0.5197159647941589,
      "learning_rate": 1.5186766160706738e-05,
      "loss": 0.3749,
      "step": 950
    },
    {
      "epoch": 0.6620689655172414,
      "grad_norm": 0.588226854801178,
      "learning_rate": 1.5093682996788274e-05,
      "loss": 0.3705,
      "step": 960
    },
    {
      "epoch": 0.6689655172413793,
      "grad_norm": 0.5243914723396301,
      "learning_rate": 1.5000000000000002e-05,
      "loss": 0.3889,
      "step": 970
    },
    {
      "epoch": 0.6758620689655173,
      "grad_norm": 0.4872022569179535,
      "learning_rate": 1.4905728202465596e-05,
      "loss": 0.3576,
      "step": 980
    },
    {
      "epoch": 0.6827586206896552,
      "grad_norm": 0.543184757232666,
      "learning_rate": 1.4810878705646005e-05,
      "loss": 0.3783,
      "step": 990
    },
    {
      "epoch": 0.6896551724137931,
      "grad_norm": 0.525056779384613,
      "learning_rate": 1.4715462679032134e-05,
      "loss": 0.364,
      "step": 1000
    },
    {
      "epoch": 0.696551724137931,
      "grad_norm": 0.4782387614250183,
      "learning_rate": 1.4619491358829502e-05,
      "loss": 0.3815,
      "step": 1010
    },
    {
      "epoch": 0.7034482758620689,
      "grad_norm": 0.5568661689758301,
      "learning_rate": 1.452297604663511e-05,
      "loss": 0.3676,
      "step": 1020
    },
    {
      "epoch": 0.7103448275862069,
      "grad_norm": 0.5265858173370361,
      "learning_rate": 1.4425928108106519e-05,
      "loss": 0.3759,
      "step": 1030
    },
    {
      "epoch": 0.7172413793103448,
      "grad_norm": 0.5447681546211243,
      "learning_rate": 1.4328358971623455e-05,
      "loss": 0.3867,
      "step": 1040
    },
    {
      "epoch": 0.7241379310344828,
      "grad_norm": 0.5286260843276978,
      "learning_rate": 1.4230280126941987e-05,
      "loss": 0.38,
      "step": 1050
    },
    {
      "epoch": 0.7310344827586207,
      "grad_norm": 0.49883782863616943,
      "learning_rate": 1.4131703123841503e-05,
      "loss": 0.3735,
      "step": 1060
    },
    {
      "epoch": 0.7379310344827587,
      "grad_norm": 0.461875319480896,
      "learning_rate": 1.4032639570764595e-05,
      "loss": 0.3764,
      "step": 1070
    },
    {
      "epoch": 0.7448275862068966,
      "grad_norm": 0.4909176528453827,
      "learning_rate": 1.393310113345006e-05,
      "loss": 0.3769,
      "step": 1080
    },
    {
      "epoch": 0.7517241379310344,
      "grad_norm": 0.5240637063980103,
      "learning_rate": 1.3833099533559129e-05,
      "loss": 0.3768,
      "step": 1090
    },
    {
      "epoch": 0.7586206896551724,
      "grad_norm": 0.4926857054233551,
      "learning_rate": 1.3732646547295128e-05,
      "loss": 0.3699,
      "step": 1100
    },
    {
      "epoch": 0.7655172413793103,
      "grad_norm": 0.540525496006012,
      "learning_rate": 1.3631754004016708e-05,
      "loss": 0.3786,
      "step": 1110
    },
    {
      "epoch": 0.7724137931034483,
      "grad_norm": 0.5390640497207642,
      "learning_rate": 1.353043378484482e-05,
      "loss": 0.378,
      "step": 1120
    },
    {
      "epoch": 0.7793103448275862,
      "grad_norm": 0.46272531151771545,
      "learning_rate": 1.34286978212636e-05,
      "loss": 0.3592,
      "step": 1130
    },
    {
      "epoch": 0.7862068965517242,
      "grad_norm": 0.48496875166893005,
      "learning_rate": 1.3326558093715294e-05,
      "loss": 0.3635,
      "step": 1140
    },
    {
      "epoch": 0.7931034482758621,
      "grad_norm": 0.5636981725692749,
      "learning_rate": 1.3224026630189465e-05,
      "loss": 0.3818,
      "step": 1150
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.5590898990631104,
      "learning_rate": 1.3121115504806554e-05,
      "loss": 0.3676,
      "step": 1160
    },
    {
      "epoch": 0.8068965517241379,
      "grad_norm": 0.4795348048210144,
      "learning_rate": 1.3017836836396046e-05,
      "loss": 0.384,
      "step": 1170
    },
    {
      "epoch": 0.8137931034482758,
      "grad_norm": 0.5403013229370117,
      "learning_rate": 1.2914202787069345e-05,
      "loss": 0.3806,
      "step": 1180
    },
    {
      "epoch": 0.8206896551724138,
      "grad_norm": 0.5438832640647888,
      "learning_rate": 1.2810225560787561e-05,
      "loss": 0.3694,
      "step": 1190
    },
    {
      "epoch": 0.8275862068965517,
      "grad_norm": 0.5782322287559509,
      "learning_rate": 1.2705917401924382e-05,
      "loss": 0.3658,
      "step": 1200
    },
    {
      "epoch": 0.8344827586206897,
      "grad_norm": 0.47441431879997253,
      "learning_rate": 1.2601290593824155e-05,
      "loss": 0.3737,
      "step": 1210
    },
    {
      "epoch": 0.8413793103448276,
      "grad_norm": 0.491339772939682,
      "learning_rate": 1.2496357457355423e-05,
      "loss": 0.3686,
      "step": 1220
    },
    {
      "epoch": 0.8482758620689655,
      "grad_norm": 0.5241875648498535,
      "learning_rate": 1.239113034945999e-05,
      "loss": 0.3669,
      "step": 1230
    },
    {
      "epoch": 0.8551724137931035,
      "grad_norm": 0.5159114599227905,
      "learning_rate": 1.2285621661697787e-05,
      "loss": 0.3728,
      "step": 1240
    },
    {
      "epoch": 0.8620689655172413,
      "grad_norm": 0.5520225167274475,
      "learning_rate": 1.2179843818787625e-05,
      "loss": 0.3714,
      "step": 1250
    },
    {
      "epoch": 0.8689655172413793,
      "grad_norm": 0.5603857040405273,
      "learning_rate": 1.207380927714407e-05,
      "loss": 0.3702,
      "step": 1260
    },
    {
      "epoch": 0.8758620689655172,
      "grad_norm": 0.5240195989608765,
      "learning_rate": 1.1967530523410578e-05,
      "loss": 0.3632,
      "step": 1270
    },
    {
      "epoch": 0.8827586206896552,
      "grad_norm": 0.5211437344551086,
      "learning_rate": 1.186102007298904e-05,
      "loss": 0.3597,
      "step": 1280
    },
    {
      "epoch": 0.8896551724137931,
      "grad_norm": 0.5144228935241699,
      "learning_rate": 1.1754290468565995e-05,
      "loss": 0.3697,
      "step": 1290
    },
    {
      "epoch": 0.896551724137931,
      "grad_norm": 0.5438558459281921,
      "learning_rate": 1.1647354278635583e-05,
      "loss": 0.3506,
      "step": 1300
    },
    {
      "epoch": 0.903448275862069,
      "grad_norm": 0.572540819644928,
      "learning_rate": 1.1540224096019495e-05,
      "loss": 0.3689,
      "step": 1310
    },
    {
      "epoch": 0.9103448275862069,
      "grad_norm": 0.5948452353477478,
      "learning_rate": 1.1432912536384013e-05,
      "loss": 0.3594,
      "step": 1320
    },
    {
      "epoch": 0.9172413793103448,
      "grad_norm": 0.5209461450576782,
      "learning_rate": 1.1325432236754424e-05,
      "loss": 0.3487,
      "step": 1330
    },
    {
      "epoch": 0.9241379310344827,
      "grad_norm": 0.5224103331565857,
      "learning_rate": 1.121779585402684e-05,
      "loss": 0.3698,
      "step": 1340
    },
    {
      "epoch": 0.9310344827586207,
      "grad_norm": 1.0061657428741455,
      "learning_rate": 1.1110016063477763e-05,
      "loss": 0.3769,
      "step": 1350
    },
    {
      "epoch": 0.9379310344827586,
      "grad_norm": 0.4738755524158478,
      "learning_rate": 1.1002105557271405e-05,
      "loss": 0.3672,
      "step": 1360
    },
    {
      "epoch": 0.9448275862068966,
      "grad_norm": 0.5022487640380859,
      "learning_rate": 1.0894077042965084e-05,
      "loss": 0.3558,
      "step": 1370
    },
    {
      "epoch": 0.9517241379310345,
      "grad_norm": 0.5192900896072388,
      "learning_rate": 1.0785943242012763e-05,
      "loss": 0.3605,
      "step": 1380
    },
    {
      "epoch": 0.9586206896551724,
      "grad_norm": 0.4750974178314209,
      "learning_rate": 1.0677716888266979e-05,
      "loss": 0.377,
      "step": 1390
    },
    {
      "epoch": 0.9655172413793104,
      "grad_norm": 0.5336914658546448,
      "learning_rate": 1.0569410726479301e-05,
      "loss": 0.3681,
      "step": 1400
    },
    {
      "epoch": 0.9724137931034482,
      "grad_norm": 0.5112169981002808,
      "learning_rate": 1.0461037510799499e-05,
      "loss": 0.3618,
      "step": 1410
    },
    {
      "epoch": 0.9793103448275862,
      "grad_norm": 0.5275059342384338,
      "learning_rate": 1.035261000327363e-05,
      "loss": 0.3711,
      "step": 1420
    },
    {
      "epoch": 0.9862068965517241,
      "grad_norm": 0.5168517231941223,
      "learning_rate": 1.0244140972341155e-05,
      "loss": 0.3698,
      "step": 1430
    },
    {
      "epoch": 0.993103448275862,
      "grad_norm": 0.5439256429672241,
      "learning_rate": 1.0135643191331344e-05,
      "loss": 0.3564,
      "step": 1440
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.5611457824707031,
      "learning_rate": 1.0027129436959082e-05,
      "loss": 0.367,
      "step": 1450
    },
    {
      "epoch": 1.006896551724138,
      "grad_norm": 0.5467981696128845,
      "learning_rate": 9.918612487820274e-06,
      "loss": 0.3494,
      "step": 1460
    },
    {
      "epoch": 1.013793103448276,
      "grad_norm": 0.531217098236084,
      "learning_rate": 9.810105122887049e-06,
      "loss": 0.3524,
      "step": 1470
    },
    {
      "epoch": 1.0206896551724138,
      "grad_norm": 0.6330583095550537,
      "learning_rate": 9.701620120002885e-06,
      "loss": 0.356,
      "step": 1480
    },
    {
      "epoch": 1.0275862068965518,
      "grad_norm": 0.5453007817268372,
      "learning_rate": 9.593170254377915e-06,
      "loss": 0.3503,
      "step": 1490
    },
    {
      "epoch": 1.0344827586206897,
      "grad_norm": 0.5705875158309937,
      "learning_rate": 9.484768297084504e-06,
      "loss": 0.3653,
      "step": 1500
    },
    {
      "epoch": 1.0413793103448277,
      "grad_norm": 0.5435858368873596,
      "learning_rate": 9.376427013553311e-06,
      "loss": 0.3552,
      "step": 1510
    },
    {
      "epoch": 1.0482758620689656,
      "grad_norm": 0.5598796606063843,
      "learning_rate": 9.268159162070058e-06,
      "loss": 0.3695,
      "step": 1520
    },
    {
      "epoch": 1.0551724137931036,
      "grad_norm": 0.5569705963134766,
      "learning_rate": 9.159977492273086e-06,
      "loss": 0.3526,
      "step": 1530
    },
    {
      "epoch": 1.0620689655172413,
      "grad_norm": 0.555047869682312,
      "learning_rate": 9.05189474365198e-06,
      "loss": 0.3579,
      "step": 1540
    },
    {
      "epoch": 1.0689655172413792,
      "grad_norm": 0.49369803071022034,
      "learning_rate": 8.943923644047343e-06,
      "loss": 0.3622,
      "step": 1550
    },
    {
      "epoch": 1.0758620689655172,
      "grad_norm": 0.5573495030403137,
      "learning_rate": 8.836076908151981e-06,
      "loss": 0.3531,
      "step": 1560
    },
    {
      "epoch": 1.0827586206896551,
      "grad_norm": 0.5377380847930908,
      "learning_rate": 8.728367236013595e-06,
      "loss": 0.3626,
      "step": 1570
    },
    {
      "epoch": 1.089655172413793,
      "grad_norm": 0.5995965003967285,
      "learning_rate": 8.620807311539258e-06,
      "loss": 0.3605,
      "step": 1580
    },
    {
      "epoch": 1.096551724137931,
      "grad_norm": 0.5702494978904724,
      "learning_rate": 8.513409801001731e-06,
      "loss": 0.3664,
      "step": 1590
    },
    {
      "epoch": 1.103448275862069,
      "grad_norm": 0.5444394946098328,
      "learning_rate": 8.406187351547872e-06,
      "loss": 0.3749,
      "step": 1600
    },
    {
      "epoch": 1.110344827586207,
      "grad_norm": 0.5576950311660767,
      "learning_rate": 8.299152589709336e-06,
      "loss": 0.3484,
      "step": 1610
    },
    {
      "epoch": 1.1172413793103448,
      "grad_norm": 0.5595077872276306,
      "learning_rate": 8.192318119915644e-06,
      "loss": 0.3594,
      "step": 1620
    },
    {
      "epoch": 1.1241379310344828,
      "grad_norm": 0.5395258665084839,
      "learning_rate": 8.085696523009907e-06,
      "loss": 0.3511,
      "step": 1630
    },
    {
      "epoch": 1.1310344827586207,
      "grad_norm": 0.5560798048973083,
      "learning_rate": 7.979300354767282e-06,
      "loss": 0.3514,
      "step": 1640
    },
    {
      "epoch": 1.1379310344827587,
      "grad_norm": 0.5756102800369263,
      "learning_rate": 7.873142144416423e-06,
      "loss": 0.3677,
      "step": 1650
    },
    {
      "epoch": 1.1448275862068966,
      "grad_norm": 0.6073386073112488,
      "learning_rate": 7.767234393164017e-06,
      "loss": 0.3405,
      "step": 1660
    },
    {
      "epoch": 1.1517241379310346,
      "grad_norm": 0.530852198600769,
      "learning_rate": 7.66158957272266e-06,
      "loss": 0.3438,
      "step": 1670
    },
    {
      "epoch": 1.1586206896551725,
      "grad_norm": 0.5536336302757263,
      "learning_rate": 7.556220123842173e-06,
      "loss": 0.3493,
      "step": 1680
    },
    {
      "epoch": 1.1655172413793102,
      "grad_norm": 0.5857017636299133,
      "learning_rate": 7.451138454844575e-06,
      "loss": 0.3511,
      "step": 1690
    },
    {
      "epoch": 1.1724137931034484,
      "grad_norm": 0.5485498905181885,
      "learning_rate": 7.346356940162895e-06,
      "loss": 0.3509,
      "step": 1700
    },
    {
      "epoch": 1.1793103448275861,
      "grad_norm": 0.5437812209129333,
      "learning_rate": 7.241887918883932e-06,
      "loss": 0.3597,
      "step": 1710
    },
    {
      "epoch": 1.186206896551724,
      "grad_norm": 0.5670866966247559,
      "learning_rate": 7.137743693295225e-06,
      "loss": 0.358,
      "step": 1720
    },
    {
      "epoch": 1.193103448275862,
      "grad_norm": 0.6242367625236511,
      "learning_rate": 7.033936527436318e-06,
      "loss": 0.3746,
      "step": 1730
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.576315701007843,
      "learning_rate": 6.930478645654554e-06,
      "loss": 0.3547,
      "step": 1740
    },
    {
      "epoch": 1.206896551724138,
      "grad_norm": 0.6141243577003479,
      "learning_rate": 6.827382231165531e-06,
      "loss": 0.357,
      "step": 1750
    },
    {
      "epoch": 1.2137931034482758,
      "grad_norm": 0.5759338140487671,
      "learning_rate": 6.724659424618401e-06,
      "loss": 0.3513,
      "step": 1760
    },
    {
      "epoch": 1.2206896551724138,
      "grad_norm": 0.5242029428482056,
      "learning_rate": 6.6223223226661994e-06,
      "loss": 0.341,
      "step": 1770
    },
    {
      "epoch": 1.2275862068965517,
      "grad_norm": 0.5234516263008118,
      "learning_rate": 6.520382976541313e-06,
      "loss": 0.3607,
      "step": 1780
    },
    {
      "epoch": 1.2344827586206897,
      "grad_norm": 0.5576380491256714,
      "learning_rate": 6.418853390636363e-06,
      "loss": 0.3598,
      "step": 1790
    },
    {
      "epoch": 1.2413793103448276,
      "grad_norm": 0.5742271542549133,
      "learning_rate": 6.31774552109053e-06,
      "loss": 0.3744,
      "step": 1800
    },
    {
      "epoch": 1.2482758620689656,
      "grad_norm": 0.6218357682228088,
      "learning_rate": 6.217071274381623e-06,
      "loss": 0.3596,
      "step": 1810
    },
    {
      "epoch": 1.2551724137931035,
      "grad_norm": 0.6271440386772156,
      "learning_rate": 6.116842505923955e-06,
      "loss": 0.3539,
      "step": 1820
    },
    {
      "epoch": 1.2620689655172415,
      "grad_norm": 0.6428937911987305,
      "learning_rate": 6.0170710186722605e-06,
      "loss": 0.3545,
      "step": 1830
    },
    {
      "epoch": 1.2689655172413792,
      "grad_norm": 0.581305980682373,
      "learning_rate": 5.917768561731763e-06,
      "loss": 0.3519,
      "step": 1840
    },
    {
      "epoch": 1.2758620689655173,
      "grad_norm": 0.5959593057632446,
      "learning_rate": 5.8189468289746075e-06,
      "loss": 0.3582,
      "step": 1850
    },
    {
      "epoch": 1.282758620689655,
      "grad_norm": 0.5636540055274963,
      "learning_rate": 5.720617457662801e-06,
      "loss": 0.3572,
      "step": 1860
    },
    {
      "epoch": 1.2896551724137932,
      "grad_norm": 0.5546914935112,
      "learning_rate": 5.622792027077773e-06,
      "loss": 0.3578,
      "step": 1870
    },
    {
      "epoch": 1.296551724137931,
      "grad_norm": 0.7034135460853577,
      "learning_rate": 5.525482057156833e-06,
      "loss": 0.3594,
      "step": 1880
    },
    {
      "epoch": 1.303448275862069,
      "grad_norm": 0.6199041604995728,
      "learning_rate": 5.4286990071365516e-06,
      "loss": 0.3587,
      "step": 1890
    },
    {
      "epoch": 1.3103448275862069,
      "grad_norm": 0.565278947353363,
      "learning_rate": 5.332454274203349e-06,
      "loss": 0.3632,
      "step": 1900
    },
    {
      "epoch": 1.3172413793103448,
      "grad_norm": 0.5609441995620728,
      "learning_rate": 5.236759192151336e-06,
      "loss": 0.3572,
      "step": 1910
    },
    {
      "epoch": 1.3241379310344827,
      "grad_norm": 0.5818240642547607,
      "learning_rate": 5.141625030047659e-06,
      "loss": 0.3559,
      "step": 1920
    },
    {
      "epoch": 1.3310344827586207,
      "grad_norm": 0.6150051951408386,
      "learning_rate": 5.047062990905436e-06,
      "loss": 0.3558,
      "step": 1930
    },
    {
      "epoch": 1.3379310344827586,
      "grad_norm": 0.6055352091789246,
      "learning_rate": 4.953084210364508e-06,
      "loss": 0.3394,
      "step": 1940
    },
    {
      "epoch": 1.3448275862068966,
      "grad_norm": 0.6251350045204163,
      "learning_rate": 4.859699755380106e-06,
      "loss": 0.3503,
      "step": 1950
    },
    {
      "epoch": 1.3517241379310345,
      "grad_norm": 0.5982210636138916,
      "learning_rate": 4.766920622919575e-06,
      "loss": 0.3444,
      "step": 1960
    },
    {
      "epoch": 1.3586206896551725,
      "grad_norm": 0.6282998919487,
      "learning_rate": 4.674757738667405e-06,
      "loss": 0.349,
      "step": 1970
    },
    {
      "epoch": 1.3655172413793104,
      "grad_norm": 0.6283583045005798,
      "learning_rate": 4.5832219557385896e-06,
      "loss": 0.3619,
      "step": 1980
    },
    {
      "epoch": 1.3724137931034484,
      "grad_norm": 0.5779064893722534,
      "learning_rate": 4.492324053400592e-06,
      "loss": 0.3422,
      "step": 1990
    },
    {
      "epoch": 1.3793103448275863,
      "grad_norm": 0.5711416006088257,
      "learning_rate": 4.402074735803955e-06,
      "loss": 0.3615,
      "step": 2000
    },
    {
      "epoch": 1.386206896551724,
      "grad_norm": 0.5833852291107178,
      "learning_rate": 4.312484630721786e-06,
      "loss": 0.3553,
      "step": 2010
    },
    {
      "epoch": 1.3931034482758622,
      "grad_norm": 0.5541110634803772,
      "learning_rate": 4.223564288298233e-06,
      "loss": 0.3518,
      "step": 2020
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.6056526303291321,
      "learning_rate": 4.135324179806079e-06,
      "loss": 0.3666,
      "step": 2030
    },
    {
      "epoch": 1.4068965517241379,
      "grad_norm": 0.6085194945335388,
      "learning_rate": 4.047774696413679e-06,
      "loss": 0.361,
      "step": 2040
    },
    {
      "epoch": 1.4137931034482758,
      "grad_norm": 0.606195330619812,
      "learning_rate": 3.960926147961253e-06,
      "loss": 0.3611,
      "step": 2050
    },
    {
      "epoch": 1.4206896551724137,
      "grad_norm": 0.597926914691925,
      "learning_rate": 3.874788761746836e-06,
      "loss": 0.3634,
      "step": 2060
    },
    {
      "epoch": 1.4275862068965517,
      "grad_norm": 0.5916698575019836,
      "learning_rate": 3.7893726813218734e-06,
      "loss": 0.3482,
      "step": 2070
    },
    {
      "epoch": 1.4344827586206896,
      "grad_norm": 0.5501697659492493,
      "learning_rate": 3.704687965296746e-06,
      "loss": 0.3519,
      "step": 2080
    },
    {
      "epoch": 1.4413793103448276,
      "grad_norm": 0.6508001685142517,
      "learning_rate": 3.6207445861562497e-06,
      "loss": 0.3468,
      "step": 2090
    },
    {
      "epoch": 1.4482758620689655,
      "grad_norm": 0.6329786777496338,
      "learning_rate": 3.5375524290852394e-06,
      "loss": 0.3586,
      "step": 2100
    },
    {
      "epoch": 1.4551724137931035,
      "grad_norm": 0.5048168897628784,
      "learning_rate": 3.4551212908045497e-06,
      "loss": 0.35,
      "step": 2110
    },
    {
      "epoch": 1.4620689655172414,
      "grad_norm": 0.5647140741348267,
      "learning_rate": 3.373460878417315e-06,
      "loss": 0.34,
      "step": 2120
    },
    {
      "epoch": 1.4689655172413794,
      "grad_norm": 0.5493628978729248,
      "learning_rate": 3.292580808265897e-06,
      "loss": 0.3589,
      "step": 2130
    },
    {
      "epoch": 1.4758620689655173,
      "grad_norm": 0.5762659311294556,
      "learning_rate": 3.2124906047994165e-06,
      "loss": 0.3413,
      "step": 2140
    },
    {
      "epoch": 1.4827586206896552,
      "grad_norm": 0.6093803644180298,
      "learning_rate": 3.1331996994521917e-06,
      "loss": 0.3443,
      "step": 2150
    },
    {
      "epoch": 1.489655172413793,
      "grad_norm": 0.6109194159507751,
      "learning_rate": 3.054717429533063e-06,
      "loss": 0.3409,
      "step": 2160
    },
    {
      "epoch": 1.4965517241379311,
      "grad_norm": 0.5717043280601501,
      "learning_rate": 2.977053037125849e-06,
      "loss": 0.3552,
      "step": 2170
    },
    {
      "epoch": 1.5034482758620689,
      "grad_norm": 0.6204915642738342,
      "learning_rate": 2.900215668000991e-06,
      "loss": 0.359,
      "step": 2180
    },
    {
      "epoch": 1.510344827586207,
      "grad_norm": 0.5847519636154175,
      "learning_rate": 2.8242143705385417e-06,
      "loss": 0.3496,
      "step": 2190
    },
    {
      "epoch": 1.5172413793103448,
      "grad_norm": 0.5609863996505737,
      "learning_rate": 2.7490580946626355e-06,
      "loss": 0.361,
      "step": 2200
    },
    {
      "epoch": 1.524137931034483,
      "grad_norm": 0.6411466002464294,
      "learning_rate": 2.674755690787526e-06,
      "loss": 0.349,
      "step": 2210
    },
    {
      "epoch": 1.5310344827586206,
      "grad_norm": 0.6075790524482727,
      "learning_rate": 2.6013159087753927e-06,
      "loss": 0.3472,
      "step": 2220
    },
    {
      "epoch": 1.5379310344827586,
      "grad_norm": 0.6324548125267029,
      "learning_rate": 2.5287473969059174e-06,
      "loss": 0.3681,
      "step": 2230
    },
    {
      "epoch": 1.5448275862068965,
      "grad_norm": 0.6215609908103943,
      "learning_rate": 2.4570587008578896e-06,
      "loss": 0.353,
      "step": 2240
    },
    {
      "epoch": 1.5517241379310345,
      "grad_norm": 0.605498194694519,
      "learning_rate": 2.386258262702851e-06,
      "loss": 0.3484,
      "step": 2250
    },
    {
      "epoch": 1.5586206896551724,
      "grad_norm": 0.5326859354972839,
      "learning_rate": 2.3163544199109656e-06,
      "loss": 0.3425,
      "step": 2260
    },
    {
      "epoch": 1.5655172413793104,
      "grad_norm": 0.5353089570999146,
      "learning_rate": 2.2473554043691915e-06,
      "loss": 0.3511,
      "step": 2270
    },
    {
      "epoch": 1.5724137931034483,
      "grad_norm": 0.5907561182975769,
      "learning_rate": 2.179269341411896e-06,
      "loss": 0.3481,
      "step": 2280
    },
    {
      "epoch": 1.5793103448275863,
      "grad_norm": 0.6039158701896667,
      "learning_rate": 2.1121042488640166e-06,
      "loss": 0.3567,
      "step": 2290
    },
    {
      "epoch": 1.5862068965517242,
      "grad_norm": 0.6103189587593079,
      "learning_rate": 2.045868036096864e-06,
      "loss": 0.3572,
      "step": 2300
    },
    {
      "epoch": 1.593103448275862,
      "grad_norm": 0.6490064263343811,
      "learning_rate": 1.9805685030967527e-06,
      "loss": 0.3429,
      "step": 2310
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.5791690349578857,
      "learning_rate": 1.916213339546421e-06,
      "loss": 0.3404,
      "step": 2320
    },
    {
      "epoch": 1.6068965517241378,
      "grad_norm": 0.5828709602355957,
      "learning_rate": 1.8528101239195394e-06,
      "loss": 0.3537,
      "step": 2330
    },
    {
      "epoch": 1.613793103448276,
      "grad_norm": 0.5707712769508362,
      "learning_rate": 1.790366322588236e-06,
      "loss": 0.3534,
      "step": 2340
    },
    {
      "epoch": 1.6206896551724137,
      "grad_norm": 0.5967758893966675,
      "learning_rate": 1.728889288943877e-06,
      "loss": 0.3406,
      "step": 2350
    },
    {
      "epoch": 1.6275862068965519,
      "grad_norm": 0.5805639624595642,
      "learning_rate": 1.6683862625311165e-06,
      "loss": 0.3514,
      "step": 2360
    },
    {
      "epoch": 1.6344827586206896,
      "grad_norm": 2.164482593536377,
      "learning_rate": 1.6088643681953752e-06,
      "loss": 0.3525,
      "step": 2370
    },
    {
      "epoch": 1.6413793103448275,
      "grad_norm": 0.5704832077026367,
      "learning_rate": 1.5503306152438146e-06,
      "loss": 0.3598,
      "step": 2380
    },
    {
      "epoch": 1.6482758620689655,
      "grad_norm": 0.5947082042694092,
      "learning_rate": 1.4927918966199095e-06,
      "loss": 0.3484,
      "step": 2390
    },
    {
      "epoch": 1.6551724137931034,
      "grad_norm": 0.5692640542984009,
      "learning_rate": 1.4362549880917609e-06,
      "loss": 0.3487,
      "step": 2400
    },
    {
      "epoch": 1.6620689655172414,
      "grad_norm": 0.5425660014152527,
      "learning_rate": 1.3807265474541465e-06,
      "loss": 0.3567,
      "step": 2410
    },
    {
      "epoch": 1.6689655172413793,
      "grad_norm": 0.6042482852935791,
      "learning_rate": 1.3262131137445266e-06,
      "loss": 0.3501,
      "step": 2420
    },
    {
      "epoch": 1.6758620689655173,
      "grad_norm": 0.6380706429481506,
      "learning_rate": 1.2727211064729862e-06,
      "loss": 0.3477,
      "step": 2430
    },
    {
      "epoch": 1.6827586206896552,
      "grad_norm": 0.6413455605506897,
      "learning_rate": 1.220256824866285e-06,
      "loss": 0.35,
      "step": 2440
    },
    {
      "epoch": 1.6896551724137931,
      "grad_norm": 0.6083069443702698,
      "learning_rate": 1.1688264471260546e-06,
      "loss": 0.3442,
      "step": 2450
    },
    {
      "epoch": 1.6965517241379309,
      "grad_norm": 0.6268501281738281,
      "learning_rate": 1.1184360297012532e-06,
      "loss": 0.3599,
      "step": 2460
    },
    {
      "epoch": 1.703448275862069,
      "grad_norm": 0.6361726522445679,
      "learning_rate": 1.0690915065749564e-06,
      "loss": 0.3587,
      "step": 2470
    },
    {
      "epoch": 1.7103448275862068,
      "grad_norm": 0.6323502063751221,
      "learning_rate": 1.0207986885655664e-06,
      "loss": 0.3626,
      "step": 2480
    },
    {
      "epoch": 1.717241379310345,
      "grad_norm": 0.6030704975128174,
      "learning_rate": 9.735632626425463e-07,
      "loss": 0.3547,
      "step": 2490
    },
    {
      "epoch": 1.7241379310344827,
      "grad_norm": 0.6529298424720764,
      "learning_rate": 9.273907912566959e-07,
      "loss": 0.3494,
      "step": 2500
    },
    {
      "epoch": 1.7310344827586208,
      "grad_norm": 0.6102371215820312,
      "learning_rate": 8.822867116851397e-07,
      "loss": 0.3617,
      "step": 2510
    },
    {
      "epoch": 1.7379310344827585,
      "grad_norm": 0.6257445812225342,
      "learning_rate": 8.382563353910122e-07,
      "loss": 0.3508,
      "step": 2520
    },
    {
      "epoch": 1.7448275862068967,
      "grad_norm": 0.6488436460494995,
      "learning_rate": 7.953048473980041e-07,
      "loss": 0.3618,
      "step": 2530
    },
    {
      "epoch": 1.7517241379310344,
      "grad_norm": 0.5354781150817871,
      "learning_rate": 7.534373056797451e-07,
      "loss": 0.354,
      "step": 2540
    },
    {
      "epoch": 1.7586206896551724,
      "grad_norm": 0.6236584186553955,
      "learning_rate": 7.126586405641989e-07,
      "loss": 0.3501,
      "step": 2550
    },
    {
      "epoch": 1.7655172413793103,
      "grad_norm": 0.581493079662323,
      "learning_rate": 6.729736541530551e-07,
      "loss": 0.3545,
      "step": 2560
    },
    {
      "epoch": 1.7724137931034483,
      "grad_norm": 0.5795840620994568,
      "learning_rate": 6.343870197562307e-07,
      "loss": 0.3486,
      "step": 2570
    },
    {
      "epoch": 1.7793103448275862,
      "grad_norm": 0.6014911532402039,
      "learning_rate": 5.969032813415577e-07,
      "loss": 0.3504,
      "step": 2580
    },
    {
      "epoch": 1.7862068965517242,
      "grad_norm": 0.5760930180549622,
      "learning_rate": 5.605268529996588e-07,
      "loss": 0.3655,
      "step": 2590
    },
    {
      "epoch": 1.793103448275862,
      "grad_norm": 0.6096722483634949,
      "learning_rate": 5.252620184241697e-07,
      "loss": 0.3545,
      "step": 2600
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.713768482208252,
      "learning_rate": 4.911129304072648e-07,
      "loss": 0.3488,
      "step": 2610
    },
    {
      "epoch": 1.806896551724138,
      "grad_norm": 0.6343590617179871,
      "learning_rate": 4.5808361035065364e-07,
      "loss": 0.3656,
      "step": 2620
    },
    {
      "epoch": 1.8137931034482757,
      "grad_norm": 0.5647720098495483,
      "learning_rate": 4.261779477919892e-07,
      "loss": 0.3498,
      "step": 2630
    },
    {
      "epoch": 1.8206896551724139,
      "grad_norm": 0.6378956437110901,
      "learning_rate": 3.9539969994685676e-07,
      "loss": 0.3569,
      "step": 2640
    },
    {
      "epoch": 1.8275862068965516,
      "grad_norm": 0.5871820449829102,
      "learning_rate": 3.6575249126631683e-07,
      "loss": 0.3493,
      "step": 2650
    },
    {
      "epoch": 1.8344827586206898,
      "grad_norm": 0.5957027673721313,
      "learning_rate": 3.372398130100851e-07,
      "loss": 0.3467,
      "step": 2660
    },
    {
      "epoch": 1.8413793103448275,
      "grad_norm": 0.6087645888328552,
      "learning_rate": 3.0986502283541055e-07,
      "loss": 0.3506,
      "step": 2670
    },
    {
      "epoch": 1.8482758620689657,
      "grad_norm": 0.6108496785163879,
      "learning_rate": 2.8363134440166806e-07,
      "loss": 0.3614,
      "step": 2680
    },
    {
      "epoch": 1.8551724137931034,
      "grad_norm": 0.5509876012802124,
      "learning_rate": 2.585418669907458e-07,
      "loss": 0.3683,
      "step": 2690
    },
    {
      "epoch": 1.8620689655172413,
      "grad_norm": 0.838077962398529,
      "learning_rate": 2.345995451432448e-07,
      "loss": 0.3566,
      "step": 2700
    },
    {
      "epoch": 1.8689655172413793,
      "grad_norm": 0.6109474897384644,
      "learning_rate": 2.1180719831056184e-07,
      "loss": 0.379,
      "step": 2710
    },
    {
      "epoch": 1.8758620689655172,
      "grad_norm": 0.5857101082801819,
      "learning_rate": 1.9016751052285952e-07,
      "loss": 0.3379,
      "step": 2720
    },
    {
      "epoch": 1.8827586206896552,
      "grad_norm": 0.5570117831230164,
      "learning_rate": 1.6968303007300124e-07,
      "loss": 0.3517,
      "step": 2730
    },
    {
      "epoch": 1.889655172413793,
      "grad_norm": 0.5651447176933289,
      "learning_rate": 1.5035616921646234e-07,
      "loss": 0.3595,
      "step": 2740
    },
    {
      "epoch": 1.896551724137931,
      "grad_norm": 0.6035347580909729,
      "learning_rate": 1.3218920388725853e-07,
      "loss": 0.3445,
      "step": 2750
    },
    {
      "epoch": 1.903448275862069,
      "grad_norm": 0.6173581480979919,
      "learning_rate": 1.1518427342994243e-07,
      "loss": 0.3435,
      "step": 2760
    },
    {
      "epoch": 1.910344827586207,
      "grad_norm": 0.5841214060783386,
      "learning_rate": 9.934338034765956e-08,
      "loss": 0.3481,
      "step": 2770
    },
    {
      "epoch": 1.9172413793103447,
      "grad_norm": 0.5992394685745239,
      "learning_rate": 8.466839006634364e-08,
      "loss": 0.3616,
      "step": 2780
    },
    {
      "epoch": 1.9241379310344828,
      "grad_norm": 0.5765228271484375,
      "learning_rate": 7.116103071503788e-08,
      "loss": 0.3462,
      "step": 2790
    },
    {
      "epoch": 1.9310344827586206,
      "grad_norm": 0.5659219026565552,
      "learning_rate": 5.8822892922399956e-08,
      "loss": 0.349,
      "step": 2800
    },
    {
      "epoch": 1.9379310344827587,
      "grad_norm": 0.624601423740387,
      "learning_rate": 4.7655429629372975e-08,
      "loss": 0.3523,
      "step": 2810
    },
    {
      "epoch": 1.9448275862068964,
      "grad_norm": 0.5576800107955933,
      "learning_rate": 3.7659955918103455e-08,
      "loss": 0.3475,
      "step": 2820
    },
    {
      "epoch": 1.9517241379310346,
      "grad_norm": 0.6183381676673889,
      "learning_rate": 2.8837648857066304e-08,
      "loss": 0.3473,
      "step": 2830
    },
    {
      "epoch": 1.9586206896551723,
      "grad_norm": 0.5673449635505676,
      "learning_rate": 2.118954736245682e-08,
      "loss": 0.355,
      "step": 2840
    },
    {
      "epoch": 1.9655172413793105,
      "grad_norm": 0.6095294952392578,
      "learning_rate": 1.4716552075849655e-08,
      "loss": 0.3526,
      "step": 2850
    },
    {
      "epoch": 1.9724137931034482,
      "grad_norm": 0.6659214496612549,
      "learning_rate": 9.419425258135884e-09,
      "loss": 0.3542,
      "step": 2860
    },
    {
      "epoch": 1.9793103448275862,
      "grad_norm": 0.6166888475418091,
      "learning_rate": 5.2987906997581385e-09,
      "loss": 0.3559,
      "step": 2870
    },
    {
      "epoch": 1.986206896551724,
      "grad_norm": 0.5806084275245667,
      "learning_rate": 2.3551336472582563e-09,
      "loss": 0.3572,
      "step": 2880
    },
    {
      "epoch": 1.993103448275862,
      "grad_norm": 0.5572490692138672,
      "learning_rate": 5.888007461307688e-10,
      "loss": 0.3596,
      "step": 2890
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.5565065145492554,
      "learning_rate": 0.0,
      "loss": 0.361,
      "step": 2900
    },
    {
      "epoch": 2.0,
      "step": 2900,
      "total_flos": 9.459753183409603e+18,
      "train_loss": 0.37360921662429286,
      "train_runtime": 27835.595,
      "train_samples_per_second": 6.667,
      "train_steps_per_second": 0.104
    }
  ],
  "logging_steps": 10,
  "max_steps": 2900,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 9.459753183409603e+18,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
