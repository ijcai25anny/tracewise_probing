{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 2900,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006896551724137931,
      "grad_norm": 0.27030205726623535,
      "learning_rate": 1.999985279873006e-05,
      "loss": 0.7141,
      "step": 10
    },
    {
      "epoch": 0.013793103448275862,
      "grad_norm": 0.249463751912117,
      "learning_rate": 1.999867521457224e-05,
      "loss": 0.6494,
      "step": 20
    },
    {
      "epoch": 0.020689655172413793,
      "grad_norm": 0.24875222146511078,
      "learning_rate": 1.9996320184929093e-05,
      "loss": 0.5816,
      "step": 30
    },
    {
      "epoch": 0.027586206896551724,
      "grad_norm": 0.22489885985851288,
      "learning_rate": 1.9992787987129253e-05,
      "loss": 0.5212,
      "step": 40
    },
    {
      "epoch": 0.034482758620689655,
      "grad_norm": 0.23767152428627014,
      "learning_rate": 1.9988079037124866e-05,
      "loss": 0.5131,
      "step": 50
    },
    {
      "epoch": 0.041379310344827586,
      "grad_norm": 0.22986601293087006,
      "learning_rate": 1.9982193889442583e-05,
      "loss": 0.4839,
      "step": 60
    },
    {
      "epoch": 0.04827586206896552,
      "grad_norm": 0.23976296186447144,
      "learning_rate": 1.9975133237118276e-05,
      "loss": 0.4654,
      "step": 70
    },
    {
      "epoch": 0.05517241379310345,
      "grad_norm": 0.25005531311035156,
      "learning_rate": 1.9966897911615417e-05,
      "loss": 0.4698,
      "step": 80
    },
    {
      "epoch": 0.06206896551724138,
      "grad_norm": 0.24500833451747894,
      "learning_rate": 1.9957488882727163e-05,
      "loss": 0.4764,
      "step": 90
    },
    {
      "epoch": 0.06896551724137931,
      "grad_norm": 0.23685133457183838,
      "learning_rate": 1.994690725846216e-05,
      "loss": 0.4651,
      "step": 100
    },
    {
      "epoch": 0.07586206896551724,
      "grad_norm": 0.27289503812789917,
      "learning_rate": 1.9935154284914063e-05,
      "loss": 0.4596,
      "step": 110
    },
    {
      "epoch": 0.08275862068965517,
      "grad_norm": 0.29017624258995056,
      "learning_rate": 1.9922231346114795e-05,
      "loss": 0.4546,
      "step": 120
    },
    {
      "epoch": 0.0896551724137931,
      "grad_norm": 0.3048036992549896,
      "learning_rate": 1.9908139963871547e-05,
      "loss": 0.4491,
      "step": 130
    },
    {
      "epoch": 0.09655172413793103,
      "grad_norm": 0.2685094177722931,
      "learning_rate": 1.98928817975876e-05,
      "loss": 0.4324,
      "step": 140
    },
    {
      "epoch": 0.10344827586206896,
      "grad_norm": 0.32345789670944214,
      "learning_rate": 1.9876458644066896e-05,
      "loss": 0.4437,
      "step": 150
    },
    {
      "epoch": 0.1103448275862069,
      "grad_norm": 0.3904353380203247,
      "learning_rate": 1.985887243730244e-05,
      "loss": 0.4399,
      "step": 160
    },
    {
      "epoch": 0.11724137931034483,
      "grad_norm": 0.30181509256362915,
      "learning_rate": 1.9840125248248564e-05,
      "loss": 0.4325,
      "step": 170
    },
    {
      "epoch": 0.12413793103448276,
      "grad_norm": 0.34943845868110657,
      "learning_rate": 1.9820219284577052e-05,
      "loss": 0.4304,
      "step": 180
    },
    {
      "epoch": 0.1310344827586207,
      "grad_norm": 0.34927597641944885,
      "learning_rate": 1.9799156890417156e-05,
      "loss": 0.4403,
      "step": 190
    },
    {
      "epoch": 0.13793103448275862,
      "grad_norm": 0.3589450418949127,
      "learning_rate": 1.9776940546079552e-05,
      "loss": 0.4267,
      "step": 200
    },
    {
      "epoch": 0.14482758620689656,
      "grad_norm": 0.30832868814468384,
      "learning_rate": 1.975357286776427e-05,
      "loss": 0.4136,
      "step": 210
    },
    {
      "epoch": 0.15172413793103448,
      "grad_norm": 0.31846049427986145,
      "learning_rate": 1.972905660725259e-05,
      "loss": 0.4332,
      "step": 220
    },
    {
      "epoch": 0.15862068965517243,
      "grad_norm": 0.3311781883239746,
      "learning_rate": 1.970339465158301e-05,
      "loss": 0.4258,
      "step": 230
    },
    {
      "epoch": 0.16551724137931034,
      "grad_norm": 0.38109394907951355,
      "learning_rate": 1.967659002271126e-05,
      "loss": 0.4268,
      "step": 240
    },
    {
      "epoch": 0.1724137931034483,
      "grad_norm": 0.34347960352897644,
      "learning_rate": 1.9648645877154435e-05,
      "loss": 0.4127,
      "step": 250
    },
    {
      "epoch": 0.1793103448275862,
      "grad_norm": 0.3717537224292755,
      "learning_rate": 1.9619565505619288e-05,
      "loss": 0.4282,
      "step": 260
    },
    {
      "epoch": 0.18620689655172415,
      "grad_norm": 0.37608805298805237,
      "learning_rate": 1.9589352332614708e-05,
      "loss": 0.4128,
      "step": 270
    },
    {
      "epoch": 0.19310344827586207,
      "grad_norm": 0.3710666000843048,
      "learning_rate": 1.955800991604846e-05,
      "loss": 0.4139,
      "step": 280
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.38425976037979126,
      "learning_rate": 1.9525541946808187e-05,
      "loss": 0.4046,
      "step": 290
    },
    {
      "epoch": 0.20689655172413793,
      "grad_norm": 0.4309394657611847,
      "learning_rate": 1.9491952248326805e-05,
      "loss": 0.416,
      "step": 300
    },
    {
      "epoch": 0.21379310344827587,
      "grad_norm": 0.3885430693626404,
      "learning_rate": 1.9457244776132208e-05,
      "loss": 0.4202,
      "step": 310
    },
    {
      "epoch": 0.2206896551724138,
      "grad_norm": 0.42407310009002686,
      "learning_rate": 1.942142361738151e-05,
      "loss": 0.4085,
      "step": 320
    },
    {
      "epoch": 0.22758620689655173,
      "grad_norm": 0.393219918012619,
      "learning_rate": 1.9384492990379703e-05,
      "loss": 0.413,
      "step": 330
    },
    {
      "epoch": 0.23448275862068965,
      "grad_norm": 0.42887505888938904,
      "learning_rate": 1.934645724408294e-05,
      "loss": 0.4176,
      "step": 340
    },
    {
      "epoch": 0.2413793103448276,
      "grad_norm": 0.38558489084243774,
      "learning_rate": 1.9307320857586377e-05,
      "loss": 0.4189,
      "step": 350
    },
    {
      "epoch": 0.2482758620689655,
      "grad_norm": 0.4005776345729828,
      "learning_rate": 1.9267088439596728e-05,
      "loss": 0.4128,
      "step": 360
    },
    {
      "epoch": 0.25517241379310346,
      "grad_norm": 0.47223830223083496,
      "learning_rate": 1.9225764727889543e-05,
      "loss": 0.4021,
      "step": 370
    },
    {
      "epoch": 0.2620689655172414,
      "grad_norm": 0.40581369400024414,
      "learning_rate": 1.9183354588751274e-05,
      "loss": 0.4039,
      "step": 380
    },
    {
      "epoch": 0.2689655172413793,
      "grad_norm": 0.3958593010902405,
      "learning_rate": 1.9139863016406237e-05,
      "loss": 0.3986,
      "step": 390
    },
    {
      "epoch": 0.27586206896551724,
      "grad_norm": 0.41968703269958496,
      "learning_rate": 1.9095295132428485e-05,
      "loss": 0.4234,
      "step": 400
    },
    {
      "epoch": 0.2827586206896552,
      "grad_norm": 0.47377029061317444,
      "learning_rate": 1.904965618513868e-05,
      "loss": 0.4079,
      "step": 410
    },
    {
      "epoch": 0.2896551724137931,
      "grad_norm": 0.6475369930267334,
      "learning_rate": 1.900295154898607e-05,
      "loss": 0.4027,
      "step": 420
    },
    {
      "epoch": 0.296551724137931,
      "grad_norm": 0.43697822093963623,
      "learning_rate": 1.8955186723915573e-05,
      "loss": 0.4118,
      "step": 430
    },
    {
      "epoch": 0.30344827586206896,
      "grad_norm": 0.40391993522644043,
      "learning_rate": 1.8906367334720125e-05,
      "loss": 0.4042,
      "step": 440
    },
    {
      "epoch": 0.3103448275862069,
      "grad_norm": 0.43887221813201904,
      "learning_rate": 1.885649913037827e-05,
      "loss": 0.3939,
      "step": 450
    },
    {
      "epoch": 0.31724137931034485,
      "grad_norm": 0.4852277636528015,
      "learning_rate": 1.8805587983377208e-05,
      "loss": 0.4049,
      "step": 460
    },
    {
      "epoch": 0.32413793103448274,
      "grad_norm": 0.45472657680511475,
      "learning_rate": 1.8753639889021197e-05,
      "loss": 0.3958,
      "step": 470
    },
    {
      "epoch": 0.3310344827586207,
      "grad_norm": 0.46925386786460876,
      "learning_rate": 1.8700660964725583e-05,
      "loss": 0.3956,
      "step": 480
    },
    {
      "epoch": 0.33793103448275863,
      "grad_norm": 0.43906915187835693,
      "learning_rate": 1.8646657449296394e-05,
      "loss": 0.3919,
      "step": 490
    },
    {
      "epoch": 0.3448275862068966,
      "grad_norm": 0.39974847435951233,
      "learning_rate": 1.8591635702195672e-05,
      "loss": 0.3897,
      "step": 500
    },
    {
      "epoch": 0.35172413793103446,
      "grad_norm": 0.450857013463974,
      "learning_rate": 1.8535602202792567e-05,
      "loss": 0.3921,
      "step": 510
    },
    {
      "epoch": 0.3586206896551724,
      "grad_norm": 0.4377804398536682,
      "learning_rate": 1.8478563549600318e-05,
      "loss": 0.388,
      "step": 520
    },
    {
      "epoch": 0.36551724137931035,
      "grad_norm": 0.47317764163017273,
      "learning_rate": 1.8420526459499252e-05,
      "loss": 0.405,
      "step": 530
    },
    {
      "epoch": 0.3724137931034483,
      "grad_norm": 0.44584882259368896,
      "learning_rate": 1.8361497766945747e-05,
      "loss": 0.403,
      "step": 540
    },
    {
      "epoch": 0.3793103448275862,
      "grad_norm": 0.44853565096855164,
      "learning_rate": 1.8301484423167456e-05,
      "loss": 0.3886,
      "step": 550
    },
    {
      "epoch": 0.38620689655172413,
      "grad_norm": 0.47133705019950867,
      "learning_rate": 1.8240493495344695e-05,
      "loss": 0.3976,
      "step": 560
    },
    {
      "epoch": 0.3931034482758621,
      "grad_norm": 0.4720723032951355,
      "learning_rate": 1.8178532165778225e-05,
      "loss": 0.3983,
      "step": 570
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.4486541450023651,
      "learning_rate": 1.811560773104346e-05,
      "loss": 0.3992,
      "step": 580
    },
    {
      "epoch": 0.4068965517241379,
      "grad_norm": 0.4543686807155609,
      "learning_rate": 1.8051727601131228e-05,
      "loss": 0.3915,
      "step": 590
    },
    {
      "epoch": 0.41379310344827586,
      "grad_norm": 0.49205052852630615,
      "learning_rate": 1.798689929857516e-05,
      "loss": 0.3997,
      "step": 600
    },
    {
      "epoch": 0.4206896551724138,
      "grad_norm": 0.4300761818885803,
      "learning_rate": 1.7921130457565835e-05,
      "loss": 0.3951,
      "step": 610
    },
    {
      "epoch": 0.42758620689655175,
      "grad_norm": 0.48335185647010803,
      "learning_rate": 1.785442882305179e-05,
      "loss": 0.4021,
      "step": 620
    },
    {
      "epoch": 0.43448275862068964,
      "grad_norm": 0.4756185710430145,
      "learning_rate": 1.7786802249827454e-05,
      "loss": 0.3888,
      "step": 630
    },
    {
      "epoch": 0.4413793103448276,
      "grad_norm": 0.48084935545921326,
      "learning_rate": 1.771825870160819e-05,
      "loss": 0.4012,
      "step": 640
    },
    {
      "epoch": 0.4482758620689655,
      "grad_norm": 0.5247610807418823,
      "learning_rate": 1.764880625009245e-05,
      "loss": 0.3904,
      "step": 650
    },
    {
      "epoch": 0.45517241379310347,
      "grad_norm": 0.5136967301368713,
      "learning_rate": 1.7578453074011302e-05,
      "loss": 0.3918,
      "step": 660
    },
    {
      "epoch": 0.46206896551724136,
      "grad_norm": 0.5406396985054016,
      "learning_rate": 1.7507207458165257e-05,
      "loss": 0.382,
      "step": 670
    },
    {
      "epoch": 0.4689655172413793,
      "grad_norm": 0.43374311923980713,
      "learning_rate": 1.7435077792448666e-05,
      "loss": 0.3978,
      "step": 680
    },
    {
      "epoch": 0.47586206896551725,
      "grad_norm": 0.3957706689834595,
      "learning_rate": 1.736207257086173e-05,
      "loss": 0.3951,
      "step": 690
    },
    {
      "epoch": 0.4827586206896552,
      "grad_norm": 0.5039812922477722,
      "learning_rate": 1.7288200390510227e-05,
      "loss": 0.3808,
      "step": 700
    },
    {
      "epoch": 0.4896551724137931,
      "grad_norm": 0.5026034712791443,
      "learning_rate": 1.7213469950593156e-05,
      "loss": 0.3865,
      "step": 710
    },
    {
      "epoch": 0.496551724137931,
      "grad_norm": 0.5703016519546509,
      "learning_rate": 1.7137890051378264e-05,
      "loss": 0.392,
      "step": 720
    },
    {
      "epoch": 0.503448275862069,
      "grad_norm": 0.5200687050819397,
      "learning_rate": 1.706146959316576e-05,
      "loss": 0.3868,
      "step": 730
    },
    {
      "epoch": 0.5103448275862069,
      "grad_norm": 0.49389949440956116,
      "learning_rate": 1.6984217575240212e-05,
      "loss": 0.386,
      "step": 740
    },
    {
      "epoch": 0.5172413793103449,
      "grad_norm": 0.5214979648590088,
      "learning_rate": 1.6906143094810774e-05,
      "loss": 0.3877,
      "step": 750
    },
    {
      "epoch": 0.5241379310344828,
      "grad_norm": 0.49405843019485474,
      "learning_rate": 1.6827255345939915e-05,
      "loss": 0.4016,
      "step": 760
    },
    {
      "epoch": 0.5310344827586206,
      "grad_norm": 0.49633297324180603,
      "learning_rate": 1.674756361846071e-05,
      "loss": 0.3953,
      "step": 770
    },
    {
      "epoch": 0.5379310344827586,
      "grad_norm": 0.5275456309318542,
      "learning_rate": 1.666707729688289e-05,
      "loss": 0.4005,
      "step": 780
    },
    {
      "epoch": 0.5448275862068965,
      "grad_norm": 0.5177935361862183,
      "learning_rate": 1.658580585928768e-05,
      "loss": 0.3865,
      "step": 790
    },
    {
      "epoch": 0.5517241379310345,
      "grad_norm": 0.46515530347824097,
      "learning_rate": 1.650375887621171e-05,
      "loss": 0.3946,
      "step": 800
    },
    {
      "epoch": 0.5586206896551724,
      "grad_norm": 0.48340511322021484,
      "learning_rate": 1.642094600951994e-05,
      "loss": 0.3862,
      "step": 810
    },
    {
      "epoch": 0.5655172413793104,
      "grad_norm": 0.5283677577972412,
      "learning_rate": 1.6337377011267924e-05,
      "loss": 0.3904,
      "step": 820
    },
    {
      "epoch": 0.5724137931034483,
      "grad_norm": 0.46187344193458557,
      "learning_rate": 1.6253061722553353e-05,
      "loss": 0.3918,
      "step": 830
    },
    {
      "epoch": 0.5793103448275863,
      "grad_norm": 0.5187177062034607,
      "learning_rate": 1.6168010072357216e-05,
      "loss": 0.3918,
      "step": 840
    },
    {
      "epoch": 0.5862068965517241,
      "grad_norm": 0.5123558044433594,
      "learning_rate": 1.6082232076374532e-05,
      "loss": 0.38,
      "step": 850
    },
    {
      "epoch": 0.593103448275862,
      "grad_norm": 0.5220574140548706,
      "learning_rate": 1.5995737835834905e-05,
      "loss": 0.3869,
      "step": 860
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5170587301254272,
      "learning_rate": 1.590853753631301e-05,
      "loss": 0.3864,
      "step": 870
    },
    {
      "epoch": 0.6068965517241379,
      "grad_norm": 0.5520206689834595,
      "learning_rate": 1.5820641446529127e-05,
      "loss": 0.3825,
      "step": 880
    },
    {
      "epoch": 0.6137931034482759,
      "grad_norm": 0.5375969409942627,
      "learning_rate": 1.5732059917139912e-05,
      "loss": 0.383,
      "step": 890
    },
    {
      "epoch": 0.6206896551724138,
      "grad_norm": 0.45803311467170715,
      "learning_rate": 1.564280337951948e-05,
      "loss": 0.3808,
      "step": 900
    },
    {
      "epoch": 0.6275862068965518,
      "grad_norm": 0.4729999303817749,
      "learning_rate": 1.5552882344531023e-05,
      "loss": 0.3852,
      "step": 910
    },
    {
      "epoch": 0.6344827586206897,
      "grad_norm": 0.5122116804122925,
      "learning_rate": 1.546230740128904e-05,
      "loss": 0.3961,
      "step": 920
    },
    {
      "epoch": 0.6413793103448275,
      "grad_norm": 0.4871150553226471,
      "learning_rate": 1.5371089215912363e-05,
      "loss": 0.3743,
      "step": 930
    },
    {
      "epoch": 0.6482758620689655,
      "grad_norm": 0.4997677803039551,
      "learning_rate": 1.5279238530268112e-05,
      "loss": 0.3758,
      "step": 940
    },
    {
      "epoch": 0.6551724137931034,
      "grad_norm": 0.4739261269569397,
      "learning_rate": 1.5186766160706738e-05,
      "loss": 0.3863,
      "step": 950
    },
    {
      "epoch": 0.6620689655172414,
      "grad_norm": 0.5990634560585022,
      "learning_rate": 1.5093682996788274e-05,
      "loss": 0.3767,
      "step": 960
    },
    {
      "epoch": 0.6689655172413793,
      "grad_norm": 0.560804009437561,
      "learning_rate": 1.5000000000000002e-05,
      "loss": 0.395,
      "step": 970
    },
    {
      "epoch": 0.6758620689655173,
      "grad_norm": 0.47921261191368103,
      "learning_rate": 1.4905728202465596e-05,
      "loss": 0.3693,
      "step": 980
    },
    {
      "epoch": 0.6827586206896552,
      "grad_norm": 0.518720805644989,
      "learning_rate": 1.4810878705646005e-05,
      "loss": 0.3849,
      "step": 990
    },
    {
      "epoch": 0.6896551724137931,
      "grad_norm": 0.5511009693145752,
      "learning_rate": 1.4715462679032134e-05,
      "loss": 0.3726,
      "step": 1000
    },
    {
      "epoch": 0.696551724137931,
      "grad_norm": 0.4738219678401947,
      "learning_rate": 1.4619491358829502e-05,
      "loss": 0.3907,
      "step": 1010
    },
    {
      "epoch": 0.7034482758620689,
      "grad_norm": 0.5431658625602722,
      "learning_rate": 1.452297604663511e-05,
      "loss": 0.3764,
      "step": 1020
    },
    {
      "epoch": 0.7103448275862069,
      "grad_norm": 0.5169060230255127,
      "learning_rate": 1.4425928108106519e-05,
      "loss": 0.3829,
      "step": 1030
    },
    {
      "epoch": 0.7172413793103448,
      "grad_norm": 0.5425994396209717,
      "learning_rate": 1.4328358971623455e-05,
      "loss": 0.3944,
      "step": 1040
    },
    {
      "epoch": 0.7241379310344828,
      "grad_norm": 0.52488112449646,
      "learning_rate": 1.4230280126941987e-05,
      "loss": 0.3925,
      "step": 1050
    },
    {
      "epoch": 0.7310344827586207,
      "grad_norm": 0.5327610969543457,
      "learning_rate": 1.4131703123841503e-05,
      "loss": 0.3841,
      "step": 1060
    },
    {
      "epoch": 0.7379310344827587,
      "grad_norm": 0.53463214635849,
      "learning_rate": 1.4032639570764595e-05,
      "loss": 0.3842,
      "step": 1070
    },
    {
      "epoch": 0.7448275862068966,
      "grad_norm": 0.5307437777519226,
      "learning_rate": 1.393310113345006e-05,
      "loss": 0.3858,
      "step": 1080
    },
    {
      "epoch": 0.7517241379310344,
      "grad_norm": 0.5583715438842773,
      "learning_rate": 1.3833099533559129e-05,
      "loss": 0.387,
      "step": 1090
    },
    {
      "epoch": 0.7586206896551724,
      "grad_norm": 0.5125726461410522,
      "learning_rate": 1.3732646547295128e-05,
      "loss": 0.38,
      "step": 1100
    },
    {
      "epoch": 0.7655172413793103,
      "grad_norm": 0.570163369178772,
      "learning_rate": 1.3631754004016708e-05,
      "loss": 0.3877,
      "step": 1110
    },
    {
      "epoch": 0.7724137931034483,
      "grad_norm": 0.5437893271446228,
      "learning_rate": 1.353043378484482e-05,
      "loss": 0.39,
      "step": 1120
    },
    {
      "epoch": 0.7793103448275862,
      "grad_norm": 0.5314199924468994,
      "learning_rate": 1.34286978212636e-05,
      "loss": 0.3767,
      "step": 1130
    },
    {
      "epoch": 0.7862068965517242,
      "grad_norm": 0.48890936374664307,
      "learning_rate": 1.3326558093715294e-05,
      "loss": 0.3738,
      "step": 1140
    },
    {
      "epoch": 0.7931034482758621,
      "grad_norm": 0.5933512449264526,
      "learning_rate": 1.3224026630189465e-05,
      "loss": 0.3923,
      "step": 1150
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.608622133731842,
      "learning_rate": 1.3121115504806554e-05,
      "loss": 0.3813,
      "step": 1160
    },
    {
      "epoch": 0.8068965517241379,
      "grad_norm": 0.49882274866104126,
      "learning_rate": 1.3017836836396046e-05,
      "loss": 0.3985,
      "step": 1170
    },
    {
      "epoch": 0.8137931034482758,
      "grad_norm": 0.5734289884567261,
      "learning_rate": 1.2914202787069345e-05,
      "loss": 0.3956,
      "step": 1180
    },
    {
      "epoch": 0.8206896551724138,
      "grad_norm": 0.5586027503013611,
      "learning_rate": 1.2810225560787561e-05,
      "loss": 0.3815,
      "step": 1190
    },
    {
      "epoch": 0.8275862068965517,
      "grad_norm": 0.5869660377502441,
      "learning_rate": 1.2705917401924382e-05,
      "loss": 0.3724,
      "step": 1200
    },
    {
      "epoch": 0.8344827586206897,
      "grad_norm": 0.5423249006271362,
      "learning_rate": 1.2601290593824155e-05,
      "loss": 0.3799,
      "step": 1210
    },
    {
      "epoch": 0.8413793103448276,
      "grad_norm": 0.5205754041671753,
      "learning_rate": 1.2496357457355423e-05,
      "loss": 0.3801,
      "step": 1220
    },
    {
      "epoch": 0.8482758620689655,
      "grad_norm": 0.537416934967041,
      "learning_rate": 1.239113034945999e-05,
      "loss": 0.3758,
      "step": 1230
    },
    {
      "epoch": 0.8551724137931035,
      "grad_norm": 0.5121710896492004,
      "learning_rate": 1.2285621661697787e-05,
      "loss": 0.3799,
      "step": 1240
    },
    {
      "epoch": 0.8620689655172413,
      "grad_norm": 0.5340225696563721,
      "learning_rate": 1.2179843818787625e-05,
      "loss": 0.3814,
      "step": 1250
    },
    {
      "epoch": 0.8689655172413793,
      "grad_norm": 0.559118926525116,
      "learning_rate": 1.207380927714407e-05,
      "loss": 0.3821,
      "step": 1260
    },
    {
      "epoch": 0.8758620689655172,
      "grad_norm": 0.5698034167289734,
      "learning_rate": 1.1967530523410578e-05,
      "loss": 0.3715,
      "step": 1270
    },
    {
      "epoch": 0.8827586206896552,
      "grad_norm": 0.5272619724273682,
      "learning_rate": 1.186102007298904e-05,
      "loss": 0.3699,
      "step": 1280
    },
    {
      "epoch": 0.8896551724137931,
      "grad_norm": 0.5126026272773743,
      "learning_rate": 1.1754290468565995e-05,
      "loss": 0.3797,
      "step": 1290
    },
    {
      "epoch": 0.896551724137931,
      "grad_norm": 0.5836812257766724,
      "learning_rate": 1.1647354278635583e-05,
      "loss": 0.3584,
      "step": 1300
    },
    {
      "epoch": 0.903448275862069,
      "grad_norm": 0.6095579862594604,
      "learning_rate": 1.1540224096019495e-05,
      "loss": 0.3773,
      "step": 1310
    },
    {
      "epoch": 0.9103448275862069,
      "grad_norm": 0.6490018963813782,
      "learning_rate": 1.1432912536384013e-05,
      "loss": 0.3672,
      "step": 1320
    },
    {
      "epoch": 0.9172413793103448,
      "grad_norm": 0.5279791951179504,
      "learning_rate": 1.1325432236754424e-05,
      "loss": 0.3619,
      "step": 1330
    },
    {
      "epoch": 0.9241379310344827,
      "grad_norm": 0.5366325378417969,
      "learning_rate": 1.121779585402684e-05,
      "loss": 0.3852,
      "step": 1340
    },
    {
      "epoch": 0.9310344827586207,
      "grad_norm": 0.5948015451431274,
      "learning_rate": 1.1110016063477763e-05,
      "loss": 0.3861,
      "step": 1350
    },
    {
      "epoch": 0.9379310344827586,
      "grad_norm": 0.4968872666358948,
      "learning_rate": 1.1002105557271405e-05,
      "loss": 0.3769,
      "step": 1360
    },
    {
      "epoch": 0.9448275862068966,
      "grad_norm": 0.5373899340629578,
      "learning_rate": 1.0894077042965084e-05,
      "loss": 0.3699,
      "step": 1370
    },
    {
      "epoch": 0.9517241379310345,
      "grad_norm": 0.5074461698532104,
      "learning_rate": 1.0785943242012763e-05,
      "loss": 0.3696,
      "step": 1380
    },
    {
      "epoch": 0.9586206896551724,
      "grad_norm": 0.5330944657325745,
      "learning_rate": 1.0677716888266979e-05,
      "loss": 0.3878,
      "step": 1390
    },
    {
      "epoch": 0.9655172413793104,
      "grad_norm": 0.551895260810852,
      "learning_rate": 1.0569410726479301e-05,
      "loss": 0.3783,
      "step": 1400
    },
    {
      "epoch": 0.9724137931034482,
      "grad_norm": 0.6951437592506409,
      "learning_rate": 1.0461037510799499e-05,
      "loss": 0.3722,
      "step": 1410
    },
    {
      "epoch": 0.9793103448275862,
      "grad_norm": 0.5204595923423767,
      "learning_rate": 1.035261000327363e-05,
      "loss": 0.3791,
      "step": 1420
    },
    {
      "epoch": 0.9862068965517241,
      "grad_norm": 0.5243987441062927,
      "learning_rate": 1.0244140972341155e-05,
      "loss": 0.3796,
      "step": 1430
    },
    {
      "epoch": 0.993103448275862,
      "grad_norm": 0.5421714186668396,
      "learning_rate": 1.0135643191331344e-05,
      "loss": 0.3641,
      "step": 1440
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.6126372814178467,
      "learning_rate": 1.0027129436959082e-05,
      "loss": 0.3777,
      "step": 1450
    },
    {
      "epoch": 1.006896551724138,
      "grad_norm": 0.5814149379730225,
      "learning_rate": 9.918612487820274e-06,
      "loss": 0.3608,
      "step": 1460
    },
    {
      "epoch": 1.013793103448276,
      "grad_norm": 0.530812680721283,
      "learning_rate": 9.810105122887049e-06,
      "loss": 0.3625,
      "step": 1470
    },
    {
      "epoch": 1.0206896551724138,
      "grad_norm": 0.5961387157440186,
      "learning_rate": 9.701620120002885e-06,
      "loss": 0.3685,
      "step": 1480
    },
    {
      "epoch": 1.0275862068965518,
      "grad_norm": 0.5545381903648376,
      "learning_rate": 9.593170254377915e-06,
      "loss": 0.3621,
      "step": 1490
    },
    {
      "epoch": 1.0344827586206897,
      "grad_norm": 0.5608804225921631,
      "learning_rate": 9.484768297084504e-06,
      "loss": 0.3787,
      "step": 1500
    },
    {
      "epoch": 1.0413793103448277,
      "grad_norm": 0.6065059304237366,
      "learning_rate": 9.376427013553311e-06,
      "loss": 0.3671,
      "step": 1510
    },
    {
      "epoch": 1.0482758620689656,
      "grad_norm": 0.5661258101463318,
      "learning_rate": 9.268159162070058e-06,
      "loss": 0.3776,
      "step": 1520
    },
    {
      "epoch": 1.0551724137931036,
      "grad_norm": 0.5906373262405396,
      "learning_rate": 9.159977492273086e-06,
      "loss": 0.3642,
      "step": 1530
    },
    {
      "epoch": 1.0620689655172413,
      "grad_norm": 0.5645368099212646,
      "learning_rate": 9.05189474365198e-06,
      "loss": 0.3673,
      "step": 1540
    },
    {
      "epoch": 1.0689655172413792,
      "grad_norm": 0.517909586429596,
      "learning_rate": 8.943923644047343e-06,
      "loss": 0.371,
      "step": 1550
    },
    {
      "epoch": 1.0758620689655172,
      "grad_norm": 0.590607225894928,
      "learning_rate": 8.836076908151981e-06,
      "loss": 0.3638,
      "step": 1560
    },
    {
      "epoch": 1.0827586206896551,
      "grad_norm": 0.5350254774093628,
      "learning_rate": 8.728367236013595e-06,
      "loss": 0.3724,
      "step": 1570
    },
    {
      "epoch": 1.089655172413793,
      "grad_norm": 0.6460756659507751,
      "learning_rate": 8.620807311539258e-06,
      "loss": 0.3693,
      "step": 1580
    },
    {
      "epoch": 1.096551724137931,
      "grad_norm": 0.5984008312225342,
      "learning_rate": 8.513409801001731e-06,
      "loss": 0.3804,
      "step": 1590
    },
    {
      "epoch": 1.103448275862069,
      "grad_norm": 0.5808286666870117,
      "learning_rate": 8.406187351547872e-06,
      "loss": 0.3813,
      "step": 1600
    },
    {
      "epoch": 1.110344827586207,
      "grad_norm": 0.5806639194488525,
      "learning_rate": 8.299152589709336e-06,
      "loss": 0.3618,
      "step": 1610
    },
    {
      "epoch": 1.1172413793103448,
      "grad_norm": 0.564863920211792,
      "learning_rate": 8.192318119915644e-06,
      "loss": 0.3724,
      "step": 1620
    },
    {
      "epoch": 1.1241379310344828,
      "grad_norm": 0.5764048099517822,
      "learning_rate": 8.085696523009907e-06,
      "loss": 0.3649,
      "step": 1630
    },
    {
      "epoch": 1.1310344827586207,
      "grad_norm": 0.5575372576713562,
      "learning_rate": 7.979300354767282e-06,
      "loss": 0.3564,
      "step": 1640
    },
    {
      "epoch": 1.1379310344827587,
      "grad_norm": 0.6052477955818176,
      "learning_rate": 7.873142144416423e-06,
      "loss": 0.3792,
      "step": 1650
    },
    {
      "epoch": 1.1448275862068966,
      "grad_norm": 0.6150074601173401,
      "learning_rate": 7.767234393164017e-06,
      "loss": 0.3539,
      "step": 1660
    },
    {
      "epoch": 1.1517241379310346,
      "grad_norm": 0.5792039632797241,
      "learning_rate": 7.66158957272266e-06,
      "loss": 0.3585,
      "step": 1670
    },
    {
      "epoch": 1.1586206896551725,
      "grad_norm": 0.6241140961647034,
      "learning_rate": 7.556220123842173e-06,
      "loss": 0.3599,
      "step": 1680
    },
    {
      "epoch": 1.1655172413793102,
      "grad_norm": 0.5868257880210876,
      "learning_rate": 7.451138454844575e-06,
      "loss": 0.3611,
      "step": 1690
    },
    {
      "epoch": 1.1724137931034484,
      "grad_norm": 0.5601841807365417,
      "learning_rate": 7.346356940162895e-06,
      "loss": 0.3625,
      "step": 1700
    },
    {
      "epoch": 1.1793103448275861,
      "grad_norm": 0.5562251210212708,
      "learning_rate": 7.241887918883932e-06,
      "loss": 0.3687,
      "step": 1710
    },
    {
      "epoch": 1.186206896551724,
      "grad_norm": 0.5635692477226257,
      "learning_rate": 7.137743693295225e-06,
      "loss": 0.3652,
      "step": 1720
    },
    {
      "epoch": 1.193103448275862,
      "grad_norm": 0.6872945427894592,
      "learning_rate": 7.033936527436318e-06,
      "loss": 0.3833,
      "step": 1730
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.5849244594573975,
      "learning_rate": 6.930478645654554e-06,
      "loss": 0.371,
      "step": 1740
    },
    {
      "epoch": 1.206896551724138,
      "grad_norm": 0.6297496557235718,
      "learning_rate": 6.827382231165531e-06,
      "loss": 0.3656,
      "step": 1750
    },
    {
      "epoch": 1.2137931034482758,
      "grad_norm": 0.565464973449707,
      "learning_rate": 6.724659424618401e-06,
      "loss": 0.3583,
      "step": 1760
    },
    {
      "epoch": 1.2206896551724138,
      "grad_norm": 0.549291729927063,
      "learning_rate": 6.6223223226661994e-06,
      "loss": 0.3532,
      "step": 1770
    },
    {
      "epoch": 1.2275862068965517,
      "grad_norm": 0.6054584383964539,
      "learning_rate": 6.520382976541313e-06,
      "loss": 0.372,
      "step": 1780
    },
    {
      "epoch": 1.2344827586206897,
      "grad_norm": 0.5624730587005615,
      "learning_rate": 6.418853390636363e-06,
      "loss": 0.3712,
      "step": 1790
    },
    {
      "epoch": 1.2413793103448276,
      "grad_norm": 0.5863443613052368,
      "learning_rate": 6.31774552109053e-06,
      "loss": 0.3783,
      "step": 1800
    },
    {
      "epoch": 1.2482758620689656,
      "grad_norm": 0.5688451528549194,
      "learning_rate": 6.217071274381623e-06,
      "loss": 0.37,
      "step": 1810
    },
    {
      "epoch": 1.2551724137931035,
      "grad_norm": 0.5989335179328918,
      "learning_rate": 6.116842505923955e-06,
      "loss": 0.3638,
      "step": 1820
    },
    {
      "epoch": 1.2620689655172415,
      "grad_norm": 0.629689633846283,
      "learning_rate": 6.0170710186722605e-06,
      "loss": 0.3618,
      "step": 1830
    },
    {
      "epoch": 1.2689655172413792,
      "grad_norm": 0.6051912307739258,
      "learning_rate": 5.917768561731763e-06,
      "loss": 0.3632,
      "step": 1840
    },
    {
      "epoch": 1.2758620689655173,
      "grad_norm": 0.5829393267631531,
      "learning_rate": 5.8189468289746075e-06,
      "loss": 0.3677,
      "step": 1850
    },
    {
      "epoch": 1.282758620689655,
      "grad_norm": 0.5890729427337646,
      "learning_rate": 5.720617457662801e-06,
      "loss": 0.3641,
      "step": 1860
    },
    {
      "epoch": 1.2896551724137932,
      "grad_norm": 0.5746995210647583,
      "learning_rate": 5.622792027077773e-06,
      "loss": 0.3656,
      "step": 1870
    },
    {
      "epoch": 1.296551724137931,
      "grad_norm": 0.6407134532928467,
      "learning_rate": 5.525482057156833e-06,
      "loss": 0.3732,
      "step": 1880
    },
    {
      "epoch": 1.303448275862069,
      "grad_norm": 0.620975911617279,
      "learning_rate": 5.4286990071365516e-06,
      "loss": 0.3688,
      "step": 1890
    },
    {
      "epoch": 1.3103448275862069,
      "grad_norm": 0.6820688843727112,
      "learning_rate": 5.332454274203349e-06,
      "loss": 0.3741,
      "step": 1900
    },
    {
      "epoch": 1.3172413793103448,
      "grad_norm": 0.5733755826950073,
      "learning_rate": 5.236759192151336e-06,
      "loss": 0.3653,
      "step": 1910
    },
    {
      "epoch": 1.3241379310344827,
      "grad_norm": 0.5711227059364319,
      "learning_rate": 5.141625030047659e-06,
      "loss": 0.3694,
      "step": 1920
    },
    {
      "epoch": 1.3310344827586207,
      "grad_norm": 0.6298938989639282,
      "learning_rate": 5.047062990905436e-06,
      "loss": 0.3657,
      "step": 1930
    },
    {
      "epoch": 1.3379310344827586,
      "grad_norm": 0.6289086937904358,
      "learning_rate": 4.953084210364508e-06,
      "loss": 0.3508,
      "step": 1940
    },
    {
      "epoch": 1.3448275862068966,
      "grad_norm": 0.6304900050163269,
      "learning_rate": 4.859699755380106e-06,
      "loss": 0.3615,
      "step": 1950
    },
    {
      "epoch": 1.3517241379310345,
      "grad_norm": 0.6369972825050354,
      "learning_rate": 4.766920622919575e-06,
      "loss": 0.3557,
      "step": 1960
    },
    {
      "epoch": 1.3586206896551725,
      "grad_norm": 0.7651987671852112,
      "learning_rate": 4.674757738667405e-06,
      "loss": 0.3633,
      "step": 1970
    },
    {
      "epoch": 1.3655172413793104,
      "grad_norm": 0.6036922931671143,
      "learning_rate": 4.5832219557385896e-06,
      "loss": 0.3696,
      "step": 1980
    },
    {
      "epoch": 1.3724137931034484,
      "grad_norm": 0.5712924599647522,
      "learning_rate": 4.492324053400592e-06,
      "loss": 0.3546,
      "step": 1990
    },
    {
      "epoch": 1.3793103448275863,
      "grad_norm": 0.6125373244285583,
      "learning_rate": 4.402074735803955e-06,
      "loss": 0.3724,
      "step": 2000
    },
    {
      "epoch": 1.386206896551724,
      "grad_norm": 0.6190192103385925,
      "learning_rate": 4.312484630721786e-06,
      "loss": 0.3633,
      "step": 2010
    },
    {
      "epoch": 1.3931034482758622,
      "grad_norm": 0.5779513716697693,
      "learning_rate": 4.223564288298233e-06,
      "loss": 0.3624,
      "step": 2020
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.6085249781608582,
      "learning_rate": 4.135324179806079e-06,
      "loss": 0.376,
      "step": 2030
    },
    {
      "epoch": 1.4068965517241379,
      "grad_norm": 0.6059250235557556,
      "learning_rate": 4.047774696413679e-06,
      "loss": 0.3689,
      "step": 2040
    },
    {
      "epoch": 1.4137931034482758,
      "grad_norm": 0.644146740436554,
      "learning_rate": 3.960926147961253e-06,
      "loss": 0.3702,
      "step": 2050
    },
    {
      "epoch": 1.4206896551724137,
      "grad_norm": 0.6041257381439209,
      "learning_rate": 3.874788761746836e-06,
      "loss": 0.372,
      "step": 2060
    },
    {
      "epoch": 1.4275862068965517,
      "grad_norm": 0.6096383929252625,
      "learning_rate": 3.7893726813218734e-06,
      "loss": 0.3572,
      "step": 2070
    },
    {
      "epoch": 1.4344827586206896,
      "grad_norm": 0.5594887137413025,
      "learning_rate": 3.704687965296746e-06,
      "loss": 0.3604,
      "step": 2080
    },
    {
      "epoch": 1.4413793103448276,
      "grad_norm": 0.6723203063011169,
      "learning_rate": 3.6207445861562497e-06,
      "loss": 0.3564,
      "step": 2090
    },
    {
      "epoch": 1.4482758620689655,
      "grad_norm": 0.6520217061042786,
      "learning_rate": 3.5375524290852394e-06,
      "loss": 0.3653,
      "step": 2100
    },
    {
      "epoch": 1.4551724137931035,
      "grad_norm": 0.6263514757156372,
      "learning_rate": 3.4551212908045497e-06,
      "loss": 0.3606,
      "step": 2110
    },
    {
      "epoch": 1.4620689655172414,
      "grad_norm": 0.6070846319198608,
      "learning_rate": 3.373460878417315e-06,
      "loss": 0.352,
      "step": 2120
    },
    {
      "epoch": 1.4689655172413794,
      "grad_norm": 0.5742945671081543,
      "learning_rate": 3.292580808265897e-06,
      "loss": 0.3711,
      "step": 2130
    },
    {
      "epoch": 1.4758620689655173,
      "grad_norm": 0.6885097622871399,
      "learning_rate": 3.2124906047994165e-06,
      "loss": 0.3581,
      "step": 2140
    },
    {
      "epoch": 1.4827586206896552,
      "grad_norm": 0.5836352705955505,
      "learning_rate": 3.1331996994521917e-06,
      "loss": 0.3514,
      "step": 2150
    },
    {
      "epoch": 1.489655172413793,
      "grad_norm": 0.6217833161354065,
      "learning_rate": 3.054717429533063e-06,
      "loss": 0.3493,
      "step": 2160
    },
    {
      "epoch": 1.4965517241379311,
      "grad_norm": 0.6293639540672302,
      "learning_rate": 2.977053037125849e-06,
      "loss": 0.3709,
      "step": 2170
    },
    {
      "epoch": 1.5034482758620689,
      "grad_norm": 0.6427120566368103,
      "learning_rate": 2.900215668000991e-06,
      "loss": 0.3688,
      "step": 2180
    },
    {
      "epoch": 1.510344827586207,
      "grad_norm": 0.6003249883651733,
      "learning_rate": 2.8242143705385417e-06,
      "loss": 0.3616,
      "step": 2190
    },
    {
      "epoch": 1.5172413793103448,
      "grad_norm": 0.6321126222610474,
      "learning_rate": 2.7490580946626355e-06,
      "loss": 0.3703,
      "step": 2200
    },
    {
      "epoch": 1.524137931034483,
      "grad_norm": 0.6831912994384766,
      "learning_rate": 2.674755690787526e-06,
      "loss": 0.3599,
      "step": 2210
    },
    {
      "epoch": 1.5310344827586206,
      "grad_norm": 0.6429759860038757,
      "learning_rate": 2.6013159087753927e-06,
      "loss": 0.3594,
      "step": 2220
    },
    {
      "epoch": 1.5379310344827586,
      "grad_norm": 0.6587126851081848,
      "learning_rate": 2.5287473969059174e-06,
      "loss": 0.3794,
      "step": 2230
    },
    {
      "epoch": 1.5448275862068965,
      "grad_norm": 0.5880160331726074,
      "learning_rate": 2.4570587008578896e-06,
      "loss": 0.3648,
      "step": 2240
    },
    {
      "epoch": 1.5517241379310345,
      "grad_norm": 0.6028459072113037,
      "learning_rate": 2.386258262702851e-06,
      "loss": 0.3603,
      "step": 2250
    },
    {
      "epoch": 1.5586206896551724,
      "grad_norm": 0.5480204820632935,
      "learning_rate": 2.3163544199109656e-06,
      "loss": 0.355,
      "step": 2260
    },
    {
      "epoch": 1.5655172413793104,
      "grad_norm": 0.5620679259300232,
      "learning_rate": 2.2473554043691915e-06,
      "loss": 0.3589,
      "step": 2270
    },
    {
      "epoch": 1.5724137931034483,
      "grad_norm": 0.6086380481719971,
      "learning_rate": 2.179269341411896e-06,
      "loss": 0.3609,
      "step": 2280
    },
    {
      "epoch": 1.5793103448275863,
      "grad_norm": 0.6237168908119202,
      "learning_rate": 2.1121042488640166e-06,
      "loss": 0.3667,
      "step": 2290
    },
    {
      "epoch": 1.5862068965517242,
      "grad_norm": 0.6456289887428284,
      "learning_rate": 2.045868036096864e-06,
      "loss": 0.3662,
      "step": 2300
    },
    {
      "epoch": 1.593103448275862,
      "grad_norm": 0.636499285697937,
      "learning_rate": 1.9805685030967527e-06,
      "loss": 0.3529,
      "step": 2310
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.5841997861862183,
      "learning_rate": 1.916213339546421e-06,
      "loss": 0.3536,
      "step": 2320
    },
    {
      "epoch": 1.6068965517241378,
      "grad_norm": 0.6079597473144531,
      "learning_rate": 1.8528101239195394e-06,
      "loss": 0.3612,
      "step": 2330
    },
    {
      "epoch": 1.613793103448276,
      "grad_norm": 0.5640206336975098,
      "learning_rate": 1.790366322588236e-06,
      "loss": 0.3652,
      "step": 2340
    },
    {
      "epoch": 1.6206896551724137,
      "grad_norm": 0.5985589027404785,
      "learning_rate": 1.728889288943877e-06,
      "loss": 0.3542,
      "step": 2350
    },
    {
      "epoch": 1.6275862068965519,
      "grad_norm": 0.5926607847213745,
      "learning_rate": 1.6683862625311165e-06,
      "loss": 0.3612,
      "step": 2360
    },
    {
      "epoch": 1.6344827586206896,
      "grad_norm": 0.5946317315101624,
      "learning_rate": 1.6088643681953752e-06,
      "loss": 0.3616,
      "step": 2370
    },
    {
      "epoch": 1.6413793103448275,
      "grad_norm": 0.5645017027854919,
      "learning_rate": 1.5503306152438146e-06,
      "loss": 0.3682,
      "step": 2380
    },
    {
      "epoch": 1.6482758620689655,
      "grad_norm": 0.6092444658279419,
      "learning_rate": 1.4927918966199095e-06,
      "loss": 0.3556,
      "step": 2390
    },
    {
      "epoch": 1.6551724137931034,
      "grad_norm": 0.6232284307479858,
      "learning_rate": 1.4362549880917609e-06,
      "loss": 0.3584,
      "step": 2400
    },
    {
      "epoch": 1.6620689655172414,
      "grad_norm": 0.5708993673324585,
      "learning_rate": 1.3807265474541465e-06,
      "loss": 0.3667,
      "step": 2410
    },
    {
      "epoch": 1.6689655172413793,
      "grad_norm": 0.5969080328941345,
      "learning_rate": 1.3262131137445266e-06,
      "loss": 0.3561,
      "step": 2420
    },
    {
      "epoch": 1.6758620689655173,
      "grad_norm": 0.6042928099632263,
      "learning_rate": 1.2727211064729862e-06,
      "loss": 0.3599,
      "step": 2430
    },
    {
      "epoch": 1.6827586206896552,
      "grad_norm": 0.685116171836853,
      "learning_rate": 1.220256824866285e-06,
      "loss": 0.3598,
      "step": 2440
    },
    {
      "epoch": 1.6896551724137931,
      "grad_norm": 0.653220534324646,
      "learning_rate": 1.1688264471260546e-06,
      "loss": 0.3551,
      "step": 2450
    },
    {
      "epoch": 1.6965517241379309,
      "grad_norm": 1.595963954925537,
      "learning_rate": 1.1184360297012532e-06,
      "loss": 0.3683,
      "step": 2460
    },
    {
      "epoch": 1.703448275862069,
      "grad_norm": 0.6365551948547363,
      "learning_rate": 1.0690915065749564e-06,
      "loss": 0.3697,
      "step": 2470
    },
    {
      "epoch": 1.7103448275862068,
      "grad_norm": 0.636306881904602,
      "learning_rate": 1.0207986885655664e-06,
      "loss": 0.3715,
      "step": 2480
    },
    {
      "epoch": 1.717241379310345,
      "grad_norm": 0.6333518028259277,
      "learning_rate": 9.735632626425463e-07,
      "loss": 0.3608,
      "step": 2490
    },
    {
      "epoch": 1.7241379310344827,
      "grad_norm": 0.6524247527122498,
      "learning_rate": 9.273907912566959e-07,
      "loss": 0.3618,
      "step": 2500
    },
    {
      "epoch": 1.7310344827586208,
      "grad_norm": 0.6242671012878418,
      "learning_rate": 8.822867116851397e-07,
      "loss": 0.3724,
      "step": 2510
    },
    {
      "epoch": 1.7379310344827585,
      "grad_norm": 0.6305345296859741,
      "learning_rate": 8.382563353910122e-07,
      "loss": 0.3614,
      "step": 2520
    },
    {
      "epoch": 1.7448275862068967,
      "grad_norm": 0.6819213032722473,
      "learning_rate": 7.953048473980041e-07,
      "loss": 0.3708,
      "step": 2530
    },
    {
      "epoch": 1.7517241379310344,
      "grad_norm": 0.5791518688201904,
      "learning_rate": 7.534373056797451e-07,
      "loss": 0.37,
      "step": 2540
    },
    {
      "epoch": 1.7586206896551724,
      "grad_norm": 0.6458057165145874,
      "learning_rate": 7.126586405641989e-07,
      "loss": 0.3604,
      "step": 2550
    },
    {
      "epoch": 1.7655172413793103,
      "grad_norm": 0.5907102227210999,
      "learning_rate": 6.729736541530551e-07,
      "loss": 0.3631,
      "step": 2560
    },
    {
      "epoch": 1.7724137931034483,
      "grad_norm": 0.587627112865448,
      "learning_rate": 6.343870197562307e-07,
      "loss": 0.3582,
      "step": 2570
    },
    {
      "epoch": 1.7793103448275862,
      "grad_norm": 0.6028695702552795,
      "learning_rate": 5.969032813415577e-07,
      "loss": 0.3584,
      "step": 2580
    },
    {
      "epoch": 1.7862068965517242,
      "grad_norm": 0.6550725102424622,
      "learning_rate": 5.605268529996588e-07,
      "loss": 0.3773,
      "step": 2590
    },
    {
      "epoch": 1.793103448275862,
      "grad_norm": 0.6734073162078857,
      "learning_rate": 5.252620184241697e-07,
      "loss": 0.3635,
      "step": 2600
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.6923109889030457,
      "learning_rate": 4.911129304072648e-07,
      "loss": 0.3604,
      "step": 2610
    },
    {
      "epoch": 1.806896551724138,
      "grad_norm": 0.6247045397758484,
      "learning_rate": 4.5808361035065364e-07,
      "loss": 0.3708,
      "step": 2620
    },
    {
      "epoch": 1.8137931034482757,
      "grad_norm": 0.5950784683227539,
      "learning_rate": 4.261779477919892e-07,
      "loss": 0.3589,
      "step": 2630
    },
    {
      "epoch": 1.8206896551724139,
      "grad_norm": 0.6280540227890015,
      "learning_rate": 3.9539969994685676e-07,
      "loss": 0.3657,
      "step": 2640
    },
    {
      "epoch": 1.8275862068965516,
      "grad_norm": 0.6107203960418701,
      "learning_rate": 3.6575249126631683e-07,
      "loss": 0.3541,
      "step": 2650
    },
    {
      "epoch": 1.8344827586206898,
      "grad_norm": 0.6459006071090698,
      "learning_rate": 3.372398130100851e-07,
      "loss": 0.3545,
      "step": 2660
    },
    {
      "epoch": 1.8413793103448275,
      "grad_norm": 0.6212177276611328,
      "learning_rate": 3.0986502283541055e-07,
      "loss": 0.3632,
      "step": 2670
    },
    {
      "epoch": 1.8482758620689657,
      "grad_norm": 0.5923064947128296,
      "learning_rate": 2.8363134440166806e-07,
      "loss": 0.3727,
      "step": 2680
    },
    {
      "epoch": 1.8551724137931034,
      "grad_norm": 0.5521053671836853,
      "learning_rate": 2.585418669907458e-07,
      "loss": 0.3773,
      "step": 2690
    },
    {
      "epoch": 1.8620689655172413,
      "grad_norm": 0.6975143551826477,
      "learning_rate": 2.345995451432448e-07,
      "loss": 0.3695,
      "step": 2700
    },
    {
      "epoch": 1.8689655172413793,
      "grad_norm": 0.6182802319526672,
      "learning_rate": 2.1180719831056184e-07,
      "loss": 0.3827,
      "step": 2710
    },
    {
      "epoch": 1.8758620689655172,
      "grad_norm": 0.6173275709152222,
      "learning_rate": 1.9016751052285952e-07,
      "loss": 0.3475,
      "step": 2720
    },
    {
      "epoch": 1.8827586206896552,
      "grad_norm": 0.60797119140625,
      "learning_rate": 1.6968303007300124e-07,
      "loss": 0.3591,
      "step": 2730
    },
    {
      "epoch": 1.889655172413793,
      "grad_norm": 0.578216016292572,
      "learning_rate": 1.5035616921646234e-07,
      "loss": 0.3688,
      "step": 2740
    },
    {
      "epoch": 1.896551724137931,
      "grad_norm": 0.5683987736701965,
      "learning_rate": 1.3218920388725853e-07,
      "loss": 0.3541,
      "step": 2750
    },
    {
      "epoch": 1.903448275862069,
      "grad_norm": 0.6693254113197327,
      "learning_rate": 1.1518427342994243e-07,
      "loss": 0.3551,
      "step": 2760
    },
    {
      "epoch": 1.910344827586207,
      "grad_norm": 0.602641761302948,
      "learning_rate": 9.934338034765956e-08,
      "loss": 0.3644,
      "step": 2770
    },
    {
      "epoch": 1.9172413793103447,
      "grad_norm": 0.6195281744003296,
      "learning_rate": 8.466839006634364e-08,
      "loss": 0.3731,
      "step": 2780
    },
    {
      "epoch": 1.9241379310344828,
      "grad_norm": 0.5910245180130005,
      "learning_rate": 7.116103071503788e-08,
      "loss": 0.3567,
      "step": 2790
    },
    {
      "epoch": 1.9310344827586206,
      "grad_norm": 0.565031886100769,
      "learning_rate": 5.8822892922399956e-08,
      "loss": 0.3557,
      "step": 2800
    },
    {
      "epoch": 1.9379310344827587,
      "grad_norm": 0.5984101295471191,
      "learning_rate": 4.7655429629372975e-08,
      "loss": 0.3632,
      "step": 2810
    },
    {
      "epoch": 1.9448275862068964,
      "grad_norm": 0.5765489935874939,
      "learning_rate": 3.7659955918103455e-08,
      "loss": 0.3572,
      "step": 2820
    },
    {
      "epoch": 1.9517241379310346,
      "grad_norm": 0.6335320472717285,
      "learning_rate": 2.8837648857066304e-08,
      "loss": 0.3573,
      "step": 2830
    },
    {
      "epoch": 1.9586206896551723,
      "grad_norm": 0.5981742143630981,
      "learning_rate": 2.118954736245682e-08,
      "loss": 0.3639,
      "step": 2840
    },
    {
      "epoch": 1.9655172413793105,
      "grad_norm": 0.6046855449676514,
      "learning_rate": 1.4716552075849655e-08,
      "loss": 0.3584,
      "step": 2850
    },
    {
      "epoch": 1.9724137931034482,
      "grad_norm": 0.6828759908676147,
      "learning_rate": 9.419425258135884e-09,
      "loss": 0.3659,
      "step": 2860
    },
    {
      "epoch": 1.9793103448275862,
      "grad_norm": 0.6191723942756653,
      "learning_rate": 5.2987906997581385e-09,
      "loss": 0.3609,
      "step": 2870
    },
    {
      "epoch": 1.986206896551724,
      "grad_norm": 0.6295857429504395,
      "learning_rate": 2.3551336472582563e-09,
      "loss": 0.3668,
      "step": 2880
    },
    {
      "epoch": 1.993103448275862,
      "grad_norm": 0.5786184072494507,
      "learning_rate": 5.888007461307688e-10,
      "loss": 0.3748,
      "step": 2890
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.564755380153656,
      "learning_rate": 0.0,
      "loss": 0.3685,
      "step": 2900
    },
    {
      "epoch": 2.0,
      "step": 2900,
      "total_flos": 9.613064585808445e+18,
      "train_loss": 0.3844035202059253,
      "train_runtime": 28142.8939,
      "train_samples_per_second": 6.594,
      "train_steps_per_second": 0.103
    }
  ],
  "logging_steps": 10,
  "max_steps": 2900,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 9.613064585808445e+18,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
