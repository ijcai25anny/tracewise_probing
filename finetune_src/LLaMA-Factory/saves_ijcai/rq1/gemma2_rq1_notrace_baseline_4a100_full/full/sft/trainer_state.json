{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.9977843426883308,
  "eval_steps": 500,
  "global_step": 676,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.029542097488921712,
      "grad_norm": 1.7486348055468615,
      "learning_rate": 1.999726003582451e-05,
      "loss": 0.6383,
      "step": 10
    },
    {
      "epoch": 0.059084194977843424,
      "grad_norm": 1.0016270055724215,
      "learning_rate": 1.9975349330482202e-05,
      "loss": 0.5004,
      "step": 20
    },
    {
      "epoch": 0.08862629246676514,
      "grad_norm": 0.8469622442005316,
      "learning_rate": 1.993157594085604e-05,
      "loss": 0.4749,
      "step": 30
    },
    {
      "epoch": 0.11816838995568685,
      "grad_norm": 0.824632516004238,
      "learning_rate": 1.9866035803816583e-05,
      "loss": 0.4674,
      "step": 40
    },
    {
      "epoch": 0.14771048744460857,
      "grad_norm": 0.9226628032899026,
      "learning_rate": 1.977887256178441e-05,
      "loss": 0.4695,
      "step": 50
    },
    {
      "epoch": 0.17725258493353027,
      "grad_norm": 0.7673587339182607,
      "learning_rate": 1.9670277247913205e-05,
      "loss": 0.4528,
      "step": 60
    },
    {
      "epoch": 0.206794682422452,
      "grad_norm": 0.8044926136956201,
      "learning_rate": 1.9540487867407923e-05,
      "loss": 0.4611,
      "step": 70
    },
    {
      "epoch": 0.2363367799113737,
      "grad_norm": 0.7187659556710965,
      "learning_rate": 1.9389788875895672e-05,
      "loss": 0.4463,
      "step": 80
    },
    {
      "epoch": 0.2658788774002954,
      "grad_norm": 0.7440366824603853,
      "learning_rate": 1.921851055599254e-05,
      "loss": 0.4417,
      "step": 90
    },
    {
      "epoch": 0.29542097488921715,
      "grad_norm": 0.6721425247007748,
      "learning_rate": 1.9027028293432768e-05,
      "loss": 0.4356,
      "step": 100
    },
    {
      "epoch": 0.3249630723781389,
      "grad_norm": 0.6758453346834996,
      "learning_rate": 1.8815761754346696e-05,
      "loss": 0.4227,
      "step": 110
    },
    {
      "epoch": 0.35450516986706054,
      "grad_norm": 0.6901765980134237,
      "learning_rate": 1.8585173965490653e-05,
      "loss": 0.4292,
      "step": 120
    },
    {
      "epoch": 0.38404726735598227,
      "grad_norm": 0.6769507845239419,
      "learning_rate": 1.8335770299444635e-05,
      "loss": 0.4173,
      "step": 130
    },
    {
      "epoch": 0.413589364844904,
      "grad_norm": 0.7210085856610459,
      "learning_rate": 1.806809736700184e-05,
      "loss": 0.4289,
      "step": 140
    },
    {
      "epoch": 0.4431314623338257,
      "grad_norm": 0.7031080811655916,
      "learning_rate": 1.778274181917764e-05,
      "loss": 0.419,
      "step": 150
    },
    {
      "epoch": 0.4726735598227474,
      "grad_norm": 0.7224192553482637,
      "learning_rate": 1.7480329061463504e-05,
      "loss": 0.4291,
      "step": 160
    },
    {
      "epoch": 0.5022156573116692,
      "grad_norm": 0.6292191594424583,
      "learning_rate": 1.7161521883143936e-05,
      "loss": 0.4218,
      "step": 170
    },
    {
      "epoch": 0.5317577548005908,
      "grad_norm": 0.6354088587528811,
      "learning_rate": 1.6827019004680347e-05,
      "loss": 0.4224,
      "step": 180
    },
    {
      "epoch": 0.5612998522895125,
      "grad_norm": 0.6678692718941517,
      "learning_rate": 1.647755354634569e-05,
      "loss": 0.4181,
      "step": 190
    },
    {
      "epoch": 0.5908419497784343,
      "grad_norm": 0.6396357338917766,
      "learning_rate": 1.6113891421465956e-05,
      "loss": 0.4128,
      "step": 200
    },
    {
      "epoch": 0.620384047267356,
      "grad_norm": 0.617963332922269,
      "learning_rate": 1.573682965779013e-05,
      "loss": 0.4122,
      "step": 210
    },
    {
      "epoch": 0.6499261447562777,
      "grad_norm": 0.7079687334412785,
      "learning_rate": 1.5347194650667564e-05,
      "loss": 0.4065,
      "step": 220
    },
    {
      "epoch": 0.6794682422451994,
      "grad_norm": 0.6478809270367721,
      "learning_rate": 1.494584035186118e-05,
      "loss": 0.4095,
      "step": 230
    },
    {
      "epoch": 0.7090103397341211,
      "grad_norm": 0.6042549436830332,
      "learning_rate": 1.4533646397966164e-05,
      "loss": 0.41,
      "step": 240
    },
    {
      "epoch": 0.7385524372230429,
      "grad_norm": 0.6135363165257995,
      "learning_rate": 1.4111516182535879e-05,
      "loss": 0.413,
      "step": 250
    },
    {
      "epoch": 0.7680945347119645,
      "grad_norm": 0.7319712561925569,
      "learning_rate": 1.3680374876140378e-05,
      "loss": 0.4073,
      "step": 260
    },
    {
      "epoch": 0.7976366322008862,
      "grad_norm": 0.5845613237683974,
      "learning_rate": 1.3241167398696874e-05,
      "loss": 0.3955,
      "step": 270
    },
    {
      "epoch": 0.827178729689808,
      "grad_norm": 0.6245615618702652,
      "learning_rate": 1.2794856348516095e-05,
      "loss": 0.4035,
      "step": 280
    },
    {
      "epoch": 0.8567208271787297,
      "grad_norm": 0.5845249304092484,
      "learning_rate": 1.2342419892603448e-05,
      "loss": 0.3983,
      "step": 290
    },
    {
      "epoch": 0.8862629246676514,
      "grad_norm": 0.6077911207138829,
      "learning_rate": 1.1884849622838716e-05,
      "loss": 0.3945,
      "step": 300
    },
    {
      "epoch": 0.9158050221565731,
      "grad_norm": 0.6021111660935502,
      "learning_rate": 1.1423148382732854e-05,
      "loss": 0.4023,
      "step": 310
    },
    {
      "epoch": 0.9453471196454948,
      "grad_norm": 0.6296032492581545,
      "learning_rate": 1.095832806952489e-05,
      "loss": 0.396,
      "step": 320
    },
    {
      "epoch": 0.9748892171344166,
      "grad_norm": 0.6144473816607421,
      "learning_rate": 1.049140741643606e-05,
      "loss": 0.3835,
      "step": 330
    },
    {
      "epoch": 1.0051698670605613,
      "grad_norm": 0.7779197070157067,
      "learning_rate": 1.00234097599417e-05,
      "loss": 0.4016,
      "step": 340
    },
    {
      "epoch": 1.034711964549483,
      "grad_norm": 0.6725180853191546,
      "learning_rate": 9.55536079695432e-06,
      "loss": 0.2945,
      "step": 350
    },
    {
      "epoch": 1.0642540620384047,
      "grad_norm": 0.6791658240533087,
      "learning_rate": 9.088286336833394e-06,
      "loss": 0.2834,
      "step": 360
    },
    {
      "epoch": 1.0937961595273265,
      "grad_norm": 0.5982382382348964,
      "learning_rate": 8.623210053148676e-06,
      "loss": 0.273,
      "step": 370
    },
    {
      "epoch": 1.1233382570162482,
      "grad_norm": 0.6602755253399683,
      "learning_rate": 8.161151240124476e-06,
      "loss": 0.2856,
      "step": 380
    },
    {
      "epoch": 1.1528803545051698,
      "grad_norm": 0.6412618608501929,
      "learning_rate": 7.703122578682047e-06,
      "loss": 0.2824,
      "step": 390
    },
    {
      "epoch": 1.1824224519940916,
      "grad_norm": 0.623657184290792,
      "learning_rate": 7.250127916976097e-06,
      "loss": 0.2772,
      "step": 400
    },
    {
      "epoch": 1.2119645494830134,
      "grad_norm": 0.5978758864756689,
      "learning_rate": 6.803160070289893e-06,
      "loss": 0.2742,
      "step": 410
    },
    {
      "epoch": 1.241506646971935,
      "grad_norm": 0.5784154689332792,
      "learning_rate": 6.3631986451107195e-06,
      "loss": 0.2748,
      "step": 420
    },
    {
      "epoch": 1.2710487444608567,
      "grad_norm": 0.6261851745474064,
      "learning_rate": 5.931207892154729e-06,
      "loss": 0.2723,
      "step": 430
    },
    {
      "epoch": 1.3005908419497785,
      "grad_norm": 0.6113218450844597,
      "learning_rate": 5.508134593046562e-06,
      "loss": 0.2678,
      "step": 440
    },
    {
      "epoch": 1.3301329394387,
      "grad_norm": 0.6331695372079681,
      "learning_rate": 5.094905985285456e-06,
      "loss": 0.2704,
      "step": 450
    },
    {
      "epoch": 1.3596750369276218,
      "grad_norm": 0.6139620941644299,
      "learning_rate": 4.69242773004571e-06,
      "loss": 0.2688,
      "step": 460
    },
    {
      "epoch": 1.3892171344165436,
      "grad_norm": 0.6295111713023945,
      "learning_rate": 4.301581927265255e-06,
      "loss": 0.2714,
      "step": 470
    },
    {
      "epoch": 1.4187592319054652,
      "grad_norm": 0.6474158169823983,
      "learning_rate": 3.923225182372825e-06,
      "loss": 0.2642,
      "step": 480
    },
    {
      "epoch": 1.448301329394387,
      "grad_norm": 0.6250545518161112,
      "learning_rate": 3.5581867288905825e-06,
      "loss": 0.2753,
      "step": 490
    },
    {
      "epoch": 1.4778434268833087,
      "grad_norm": 0.6356568789528099,
      "learning_rate": 3.207266611027069e-06,
      "loss": 0.2605,
      "step": 500
    },
    {
      "epoch": 1.5073855243722303,
      "grad_norm": 0.6565027951475477,
      "learning_rate": 2.8712339302434476e-06,
      "loss": 0.2667,
      "step": 510
    },
    {
      "epoch": 1.5369276218611523,
      "grad_norm": 0.6264642737234892,
      "learning_rate": 2.5508251596361113e-06,
      "loss": 0.2668,
      "step": 520
    },
    {
      "epoch": 1.5664697193500738,
      "grad_norm": 0.6141348352262084,
      "learning_rate": 2.246742529829923e-06,
      "loss": 0.2663,
      "step": 530
    },
    {
      "epoch": 1.5960118168389956,
      "grad_norm": 0.622110021757582,
      "learning_rate": 1.9596524899196846e-06,
      "loss": 0.2705,
      "step": 540
    },
    {
      "epoch": 1.6255539143279174,
      "grad_norm": 0.6490023859789223,
      "learning_rate": 1.6901842468329588e-06,
      "loss": 0.2648,
      "step": 550
    },
    {
      "epoch": 1.655096011816839,
      "grad_norm": 0.6145378856076665,
      "learning_rate": 1.4389283863154702e-06,
      "loss": 0.2684,
      "step": 560
    },
    {
      "epoch": 1.6846381093057607,
      "grad_norm": 0.6279247907021155,
      "learning_rate": 1.2064355785614002e-06,
      "loss": 0.2636,
      "step": 570
    },
    {
      "epoch": 1.7141802067946825,
      "grad_norm": 0.6462694977240143,
      "learning_rate": 9.932153713255055e-07,
      "loss": 0.2702,
      "step": 580
    },
    {
      "epoch": 1.743722304283604,
      "grad_norm": 0.6513210551627334,
      "learning_rate": 7.997350731620335e-07,
      "loss": 0.2666,
      "step": 590
    },
    {
      "epoch": 1.7732644017725259,
      "grad_norm": 0.647364925420569,
      "learning_rate": 6.264187292380985e-07,
      "loss": 0.2693,
      "step": 600
    },
    {
      "epoch": 1.8028064992614476,
      "grad_norm": 0.6634405306048052,
      "learning_rate": 4.73646191966175e-07,
      "loss": 0.2575,
      "step": 610
    },
    {
      "epoch": 1.8323485967503692,
      "grad_norm": 0.6161133083164942,
      "learning_rate": 3.4175228849255505e-07,
      "loss": 0.2608,
      "step": 620
    },
    {
      "epoch": 1.861890694239291,
      "grad_norm": 0.6243538373880787,
      "learning_rate": 2.3102608686639828e-07,
      "loss": 0.2561,
      "step": 630
    },
    {
      "epoch": 1.8914327917282128,
      "grad_norm": 0.6178646487743182,
      "learning_rate": 1.4171026249764407e-07,
      "loss": 0.2653,
      "step": 640
    },
    {
      "epoch": 1.9209748892171343,
      "grad_norm": 0.6415151565786381,
      "learning_rate": 7.400056629235819e-08,
      "loss": 0.2584,
      "step": 650
    },
    {
      "epoch": 1.950516986706056,
      "grad_norm": 0.6256148582122419,
      "learning_rate": 2.8045395631124405e-08,
      "loss": 0.2648,
      "step": 660
    },
    {
      "epoch": 1.980059084194978,
      "grad_norm": 0.6418991229314807,
      "learning_rate": 3.94546913081717e-09,
      "loss": 0.259,
      "step": 670
    },
    {
      "epoch": 1.9977843426883308,
      "step": 676,
      "total_flos": 455587628187648.0,
      "train_loss": 0.35048048718441166,
      "train_runtime": 14632.6722,
      "train_samples_per_second": 8.881,
      "train_steps_per_second": 0.046
    }
  ],
  "logging_steps": 10,
  "max_steps": 676,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 455587628187648.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
