{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.9983379501385041,
  "eval_steps": 500,
  "global_step": 1352,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.014773776546629732,
      "grad_norm": 0.49220821261405945,
      "learning_rate": 1.9999320061480424e-05,
      "loss": 0.6739,
      "step": 10
    },
    {
      "epoch": 0.029547553093259463,
      "grad_norm": 0.3221990168094635,
      "learning_rate": 1.999388110809091e-05,
      "loss": 0.5367,
      "step": 20
    },
    {
      "epoch": 0.0443213296398892,
      "grad_norm": 0.2750207185745239,
      "learning_rate": 1.9983006159734433e-05,
      "loss": 0.5074,
      "step": 30
    },
    {
      "epoch": 0.05909510618651893,
      "grad_norm": 0.27214565873146057,
      "learning_rate": 1.9966701131646914e-05,
      "loss": 0.4838,
      "step": 40
    },
    {
      "epoch": 0.07386888273314866,
      "grad_norm": 0.2828085124492645,
      "learning_rate": 1.9944974892660158e-05,
      "loss": 0.4595,
      "step": 50
    },
    {
      "epoch": 0.0886426592797784,
      "grad_norm": 0.3026560842990875,
      "learning_rate": 1.991783926037781e-05,
      "loss": 0.4725,
      "step": 60
    },
    {
      "epoch": 0.10341643582640812,
      "grad_norm": 0.29974186420440674,
      "learning_rate": 1.988530899474737e-05,
      "loss": 0.4585,
      "step": 70
    },
    {
      "epoch": 0.11819021237303785,
      "grad_norm": 0.3764980435371399,
      "learning_rate": 1.9847401790031792e-05,
      "loss": 0.4585,
      "step": 80
    },
    {
      "epoch": 0.1329639889196676,
      "grad_norm": 0.32721877098083496,
      "learning_rate": 1.9804138265184995e-05,
      "loss": 0.4618,
      "step": 90
    },
    {
      "epoch": 0.14773776546629733,
      "grad_norm": 0.325971394777298,
      "learning_rate": 1.9755541952636553e-05,
      "loss": 0.4599,
      "step": 100
    },
    {
      "epoch": 0.16251154201292706,
      "grad_norm": 0.3368642330169678,
      "learning_rate": 1.9701639285491633e-05,
      "loss": 0.4383,
      "step": 110
    },
    {
      "epoch": 0.1772853185595568,
      "grad_norm": 0.3257763385772705,
      "learning_rate": 1.96424595831532e-05,
      "loss": 0.446,
      "step": 120
    },
    {
      "epoch": 0.19205909510618652,
      "grad_norm": 0.34420347213745117,
      "learning_rate": 1.9578035035374214e-05,
      "loss": 0.4405,
      "step": 130
    },
    {
      "epoch": 0.20683287165281625,
      "grad_norm": 0.37033534049987793,
      "learning_rate": 1.9508400684748615e-05,
      "loss": 0.4674,
      "step": 140
    },
    {
      "epoch": 0.22160664819944598,
      "grad_norm": 0.34298861026763916,
      "learning_rate": 1.9433594407650493e-05,
      "loss": 0.4378,
      "step": 150
    },
    {
      "epoch": 0.2363804247460757,
      "grad_norm": 0.34426653385162354,
      "learning_rate": 1.9353656893631923e-05,
      "loss": 0.4363,
      "step": 160
    },
    {
      "epoch": 0.25115420129270544,
      "grad_norm": 0.3639380931854248,
      "learning_rate": 1.926863162329061e-05,
      "loss": 0.4336,
      "step": 170
    },
    {
      "epoch": 0.2659279778393352,
      "grad_norm": 0.3359854817390442,
      "learning_rate": 1.9178564844619362e-05,
      "loss": 0.4373,
      "step": 180
    },
    {
      "epoch": 0.2807017543859649,
      "grad_norm": 0.30585208535194397,
      "learning_rate": 1.908350554785032e-05,
      "loss": 0.4314,
      "step": 190
    },
    {
      "epoch": 0.29547553093259465,
      "grad_norm": 0.313551664352417,
      "learning_rate": 1.898350543880761e-05,
      "loss": 0.4255,
      "step": 200
    },
    {
      "epoch": 0.31024930747922436,
      "grad_norm": 0.3332642912864685,
      "learning_rate": 1.8878618910782834e-05,
      "loss": 0.4194,
      "step": 210
    },
    {
      "epoch": 0.3250230840258541,
      "grad_norm": 0.329291433095932,
      "learning_rate": 1.8768903014948838e-05,
      "loss": 0.4134,
      "step": 220
    },
    {
      "epoch": 0.3397968605724838,
      "grad_norm": 0.3531269431114197,
      "learning_rate": 1.865441742932771e-05,
      "loss": 0.4202,
      "step": 230
    },
    {
      "epoch": 0.3545706371191136,
      "grad_norm": 0.3385829031467438,
      "learning_rate": 1.8535224426329992e-05,
      "loss": 0.43,
      "step": 240
    },
    {
      "epoch": 0.36934441366574333,
      "grad_norm": 0.3337353765964508,
      "learning_rate": 1.841138883888269e-05,
      "loss": 0.414,
      "step": 250
    },
    {
      "epoch": 0.38411819021237303,
      "grad_norm": 0.3452983796596527,
      "learning_rate": 1.8282978025164553e-05,
      "loss": 0.4116,
      "step": 260
    },
    {
      "epoch": 0.3988919667590028,
      "grad_norm": 0.3413853049278259,
      "learning_rate": 1.8150061831967786e-05,
      "loss": 0.4158,
      "step": 270
    },
    {
      "epoch": 0.4136657433056325,
      "grad_norm": 0.3549627959728241,
      "learning_rate": 1.8012712556706117e-05,
      "loss": 0.4226,
      "step": 280
    },
    {
      "epoch": 0.42843951985226225,
      "grad_norm": 0.3578721284866333,
      "learning_rate": 1.787100490808991e-05,
      "loss": 0.4145,
      "step": 290
    },
    {
      "epoch": 0.44321329639889195,
      "grad_norm": 0.35732710361480713,
      "learning_rate": 1.7725015965489656e-05,
      "loss": 0.4142,
      "step": 300
    },
    {
      "epoch": 0.4579870729455217,
      "grad_norm": 0.33321669697761536,
      "learning_rate": 1.757482513701004e-05,
      "loss": 0.4251,
      "step": 310
    },
    {
      "epoch": 0.4727608494921514,
      "grad_norm": 0.3608396351337433,
      "learning_rate": 1.7420514116297294e-05,
      "loss": 0.4274,
      "step": 320
    },
    {
      "epoch": 0.48753462603878117,
      "grad_norm": 0.34669774770736694,
      "learning_rate": 1.7262166838103373e-05,
      "loss": 0.4268,
      "step": 330
    },
    {
      "epoch": 0.5023084025854109,
      "grad_norm": 0.3591899275779724,
      "learning_rate": 1.7099869432631152e-05,
      "loss": 0.4161,
      "step": 340
    },
    {
      "epoch": 0.5170821791320406,
      "grad_norm": 0.3507000207901001,
      "learning_rate": 1.6933710178685406e-05,
      "loss": 0.4243,
      "step": 350
    },
    {
      "epoch": 0.5318559556786704,
      "grad_norm": 0.3406296968460083,
      "learning_rate": 1.6763779455655122e-05,
      "loss": 0.4215,
      "step": 360
    },
    {
      "epoch": 0.5466297322253001,
      "grad_norm": 0.3398430645465851,
      "learning_rate": 1.6590169694353227e-05,
      "loss": 0.4118,
      "step": 370
    },
    {
      "epoch": 0.5614035087719298,
      "grad_norm": 0.35167932510375977,
      "learning_rate": 1.6412975326740485e-05,
      "loss": 0.4219,
      "step": 380
    },
    {
      "epoch": 0.5761772853185596,
      "grad_norm": 0.36340567469596863,
      "learning_rate": 1.623229273456089e-05,
      "loss": 0.418,
      "step": 390
    },
    {
      "epoch": 0.5909510618651893,
      "grad_norm": 0.34869349002838135,
      "learning_rate": 1.6048220196916537e-05,
      "loss": 0.4104,
      "step": 400
    },
    {
      "epoch": 0.605724838411819,
      "grad_norm": 0.38476744294166565,
      "learning_rate": 1.5860857836810427e-05,
      "loss": 0.4093,
      "step": 410
    },
    {
      "epoch": 0.6204986149584487,
      "grad_norm": 0.3019987642765045,
      "learning_rate": 1.567030756668634e-05,
      "loss": 0.4197,
      "step": 420
    },
    {
      "epoch": 0.6352723915050785,
      "grad_norm": 0.30485981702804565,
      "learning_rate": 1.5476673032995345e-05,
      "loss": 0.3984,
      "step": 430
    },
    {
      "epoch": 0.6500461680517082,
      "grad_norm": 0.3566289246082306,
      "learning_rate": 1.5280059559819177e-05,
      "loss": 0.419,
      "step": 440
    },
    {
      "epoch": 0.6648199445983379,
      "grad_norm": 0.31576576828956604,
      "learning_rate": 1.5080574091581031e-05,
      "loss": 0.4111,
      "step": 450
    },
    {
      "epoch": 0.6795937211449676,
      "grad_norm": 0.3397660553455353,
      "learning_rate": 1.4878325134875046e-05,
      "loss": 0.4129,
      "step": 460
    },
    {
      "epoch": 0.6943674976915974,
      "grad_norm": 0.3304082155227661,
      "learning_rate": 1.4673422699446078e-05,
      "loss": 0.4115,
      "step": 470
    },
    {
      "epoch": 0.7091412742382271,
      "grad_norm": 0.35178902745246887,
      "learning_rate": 1.4465978238351812e-05,
      "loss": 0.4141,
      "step": 480
    },
    {
      "epoch": 0.7239150507848569,
      "grad_norm": 0.3342973589897156,
      "learning_rate": 1.4256104587339869e-05,
      "loss": 0.4249,
      "step": 490
    },
    {
      "epoch": 0.7386888273314867,
      "grad_norm": 0.329885870218277,
      "learning_rate": 1.4043915903472777e-05,
      "loss": 0.4067,
      "step": 500
    },
    {
      "epoch": 0.7534626038781164,
      "grad_norm": 0.324582576751709,
      "learning_rate": 1.382952760303428e-05,
      "loss": 0.409,
      "step": 510
    },
    {
      "epoch": 0.7682363804247461,
      "grad_norm": 0.3330662250518799,
      "learning_rate": 1.3613056298750641e-05,
      "loss": 0.4137,
      "step": 520
    },
    {
      "epoch": 0.7830101569713758,
      "grad_norm": 0.3243190050125122,
      "learning_rate": 1.3394619736361278e-05,
      "loss": 0.4037,
      "step": 530
    },
    {
      "epoch": 0.7977839335180056,
      "grad_norm": 0.3810044229030609,
      "learning_rate": 1.3174336730572997e-05,
      "loss": 0.4032,
      "step": 540
    },
    {
      "epoch": 0.8125577100646353,
      "grad_norm": 0.3602611720561981,
      "learning_rate": 1.2952327100432853e-05,
      "loss": 0.4162,
      "step": 550
    },
    {
      "epoch": 0.827331486611265,
      "grad_norm": 0.3394809067249298,
      "learning_rate": 1.2728711604154702e-05,
      "loss": 0.4061,
      "step": 560
    },
    {
      "epoch": 0.8421052631578947,
      "grad_norm": 0.3012942373752594,
      "learning_rate": 1.2503611873434886e-05,
      "loss": 0.4052,
      "step": 570
    },
    {
      "epoch": 0.8568790397045245,
      "grad_norm": 0.3394811153411865,
      "learning_rate": 1.2277150347292854e-05,
      "loss": 0.4078,
      "step": 580
    },
    {
      "epoch": 0.8716528162511542,
      "grad_norm": 0.3274345397949219,
      "learning_rate": 1.2049450205472585e-05,
      "loss": 0.4152,
      "step": 590
    },
    {
      "epoch": 0.8864265927977839,
      "grad_norm": 0.335054486989975,
      "learning_rate": 1.1820635301441168e-05,
      "loss": 0.3855,
      "step": 600
    },
    {
      "epoch": 0.9012003693444137,
      "grad_norm": 0.33365723490715027,
      "learning_rate": 1.1590830095020896e-05,
      "loss": 0.4132,
      "step": 610
    },
    {
      "epoch": 0.9159741458910434,
      "grad_norm": 0.33950141072273254,
      "learning_rate": 1.1360159584691529e-05,
      "loss": 0.4135,
      "step": 620
    },
    {
      "epoch": 0.9307479224376731,
      "grad_norm": 0.33602890372276306,
      "learning_rate": 1.1128749239599603e-05,
      "loss": 0.4037,
      "step": 630
    },
    {
      "epoch": 0.9455216989843028,
      "grad_norm": 0.34430307149887085,
      "learning_rate": 1.0896724931311693e-05,
      "loss": 0.4032,
      "step": 640
    },
    {
      "epoch": 0.9602954755309326,
      "grad_norm": 0.352756530046463,
      "learning_rate": 1.0664212865348798e-05,
      "loss": 0.3988,
      "step": 650
    },
    {
      "epoch": 0.9750692520775623,
      "grad_norm": 0.3187510073184967,
      "learning_rate": 1.0431339512539082e-05,
      "loss": 0.3913,
      "step": 660
    },
    {
      "epoch": 0.989843028624192,
      "grad_norm": 0.3518616855144501,
      "learning_rate": 1.0198231540226307e-05,
      "loss": 0.4058,
      "step": 670
    },
    {
      "epoch": 1.005540166204986,
      "grad_norm": 0.3264964520931244,
      "learning_rate": 9.965015743371368e-06,
      "loss": 0.4246,
      "step": 680
    },
    {
      "epoch": 1.020313942751616,
      "grad_norm": 0.3401574194431305,
      "learning_rate": 9.7318189755844e-06,
      "loss": 0.4019,
      "step": 690
    },
    {
      "epoch": 1.0350877192982457,
      "grad_norm": 0.3974000811576843,
      "learning_rate": 9.49876808012503e-06,
      "loss": 0.3898,
      "step": 700
    },
    {
      "epoch": 1.0498614958448753,
      "grad_norm": 0.37803834676742554,
      "learning_rate": 9.2659898209082e-06,
      "loss": 0.3941,
      "step": 710
    },
    {
      "epoch": 1.0646352723915051,
      "grad_norm": 0.3834475874900818,
      "learning_rate": 9.033610813553196e-06,
      "loss": 0.3871,
      "step": 720
    },
    {
      "epoch": 1.0794090489381347,
      "grad_norm": 0.33944693207740784,
      "learning_rate": 8.801757456513306e-06,
      "loss": 0.3739,
      "step": 730
    },
    {
      "epoch": 1.0941828254847645,
      "grad_norm": 0.35772705078125,
      "learning_rate": 8.570555862323612e-06,
      "loss": 0.3895,
      "step": 740
    },
    {
      "epoch": 1.1089566020313943,
      "grad_norm": 0.3213486075401306,
      "learning_rate": 8.340131789004334e-06,
      "loss": 0.3894,
      "step": 750
    },
    {
      "epoch": 1.123730378578024,
      "grad_norm": 0.4898945093154907,
      "learning_rate": 8.110610571656946e-06,
      "loss": 0.3984,
      "step": 760
    },
    {
      "epoch": 1.1385041551246537,
      "grad_norm": 0.35456016659736633,
      "learning_rate": 7.882117054290375e-06,
      "loss": 0.3896,
      "step": 770
    },
    {
      "epoch": 1.1532779316712836,
      "grad_norm": 0.38566654920578003,
      "learning_rate": 7.65477552191432e-06,
      "loss": 0.3959,
      "step": 780
    },
    {
      "epoch": 1.1680517082179132,
      "grad_norm": 0.35436519980430603,
      "learning_rate": 7.428709632936599e-06,
      "loss": 0.3935,
      "step": 790
    },
    {
      "epoch": 1.182825484764543,
      "grad_norm": 0.3337554335594177,
      "learning_rate": 7.204042351901359e-06,
      "loss": 0.3835,
      "step": 800
    },
    {
      "epoch": 1.1975992613111726,
      "grad_norm": 0.3420252203941345,
      "learning_rate": 6.98089588260467e-06,
      "loss": 0.3803,
      "step": 810
    },
    {
      "epoch": 1.2123730378578024,
      "grad_norm": 0.34830015897750854,
      "learning_rate": 6.75939160162395e-06,
      "loss": 0.3835,
      "step": 820
    },
    {
      "epoch": 1.2271468144044322,
      "grad_norm": 0.36455237865448,
      "learning_rate": 6.539649992297311e-06,
      "loss": 0.3953,
      "step": 830
    },
    {
      "epoch": 1.2419205909510618,
      "grad_norm": 0.34515273571014404,
      "learning_rate": 6.321790579188773e-06,
      "loss": 0.3739,
      "step": 840
    },
    {
      "epoch": 1.2566943674976916,
      "grad_norm": 0.38615626096725464,
      "learning_rate": 6.105931863074995e-06,
      "loss": 0.3802,
      "step": 850
    },
    {
      "epoch": 1.2714681440443214,
      "grad_norm": 0.3488732874393463,
      "learning_rate": 5.8921912564888775e-06,
      "loss": 0.3797,
      "step": 860
    },
    {
      "epoch": 1.286241920590951,
      "grad_norm": 0.3204494118690491,
      "learning_rate": 5.680685019855084e-06,
      "loss": 0.3694,
      "step": 870
    },
    {
      "epoch": 1.3010156971375808,
      "grad_norm": 0.3757022023200989,
      "learning_rate": 5.471528198252224e-06,
      "loss": 0.382,
      "step": 880
    },
    {
      "epoch": 1.3157894736842106,
      "grad_norm": 0.38587135076522827,
      "learning_rate": 5.264834558836156e-06,
      "loss": 0.3783,
      "step": 890
    },
    {
      "epoch": 1.3305632502308402,
      "grad_norm": 0.37706783413887024,
      "learning_rate": 5.060716528958316e-06,
      "loss": 0.3861,
      "step": 900
    },
    {
      "epoch": 1.34533702677747,
      "grad_norm": 0.38878539204597473,
      "learning_rate": 4.8592851350128615e-06,
      "loss": 0.3853,
      "step": 910
    },
    {
      "epoch": 1.3601108033240998,
      "grad_norm": 0.3666272759437561,
      "learning_rate": 4.660649942045826e-06,
      "loss": 0.3705,
      "step": 920
    },
    {
      "epoch": 1.3748845798707294,
      "grad_norm": 0.44389909505844116,
      "learning_rate": 4.464918994159154e-06,
      "loss": 0.3915,
      "step": 930
    },
    {
      "epoch": 1.3896583564173592,
      "grad_norm": 0.3629121780395508,
      "learning_rate": 4.272198755742011e-06,
      "loss": 0.371,
      "step": 940
    },
    {
      "epoch": 1.404432132963989,
      "grad_norm": 0.33556246757507324,
      "learning_rate": 4.082594053561369e-06,
      "loss": 0.3826,
      "step": 950
    },
    {
      "epoch": 1.4192059095106186,
      "grad_norm": 0.3622446656227112,
      "learning_rate": 3.89620801974334e-06,
      "loss": 0.3722,
      "step": 960
    },
    {
      "epoch": 1.4339796860572485,
      "grad_norm": 0.3683874011039734,
      "learning_rate": 3.7131420356762726e-06,
      "loss": 0.3975,
      "step": 970
    },
    {
      "epoch": 1.448753462603878,
      "grad_norm": 0.38729798793792725,
      "learning_rate": 3.533495676866141e-06,
      "loss": 0.3815,
      "step": 980
    },
    {
      "epoch": 1.4635272391505079,
      "grad_norm": 0.37408339977264404,
      "learning_rate": 3.3573666587742192e-06,
      "loss": 0.369,
      "step": 990
    },
    {
      "epoch": 1.4783010156971375,
      "grad_norm": 0.343373566865921,
      "learning_rate": 3.1848507836664634e-06,
      "loss": 0.3763,
      "step": 1000
    },
    {
      "epoch": 1.4930747922437673,
      "grad_norm": 0.38225361704826355,
      "learning_rate": 3.016041888503578e-06,
      "loss": 0.3799,
      "step": 1010
    },
    {
      "epoch": 1.507848568790397,
      "grad_norm": 0.3546753227710724,
      "learning_rate": 2.8510317939000474e-06,
      "loss": 0.3839,
      "step": 1020
    },
    {
      "epoch": 1.5226223453370267,
      "grad_norm": 0.3986034691333771,
      "learning_rate": 2.689910254179949e-06,
      "loss": 0.3712,
      "step": 1030
    },
    {
      "epoch": 1.5373961218836565,
      "grad_norm": 0.3580244779586792,
      "learning_rate": 2.532764908556675e-06,
      "loss": 0.3933,
      "step": 1040
    },
    {
      "epoch": 1.5521698984302863,
      "grad_norm": 0.35995423793792725,
      "learning_rate": 2.379681233463118e-06,
      "loss": 0.3815,
      "step": 1050
    },
    {
      "epoch": 1.566943674976916,
      "grad_norm": 0.35506582260131836,
      "learning_rate": 2.2307424960582836e-06,
      "loss": 0.3862,
      "step": 1060
    },
    {
      "epoch": 1.5817174515235457,
      "grad_norm": 0.3662227392196655,
      "learning_rate": 2.0860297089355943e-06,
      "loss": 0.3909,
      "step": 1070
    },
    {
      "epoch": 1.5964912280701755,
      "grad_norm": 0.3394310772418976,
      "learning_rate": 1.945621586057519e-06,
      "loss": 0.3902,
      "step": 1080
    },
    {
      "epoch": 1.611265004616805,
      "grad_norm": 0.39690592885017395,
      "learning_rate": 1.8095944999405025e-06,
      "loss": 0.3792,
      "step": 1090
    },
    {
      "epoch": 1.626038781163435,
      "grad_norm": 0.39332306385040283,
      "learning_rate": 1.6780224401134903e-06,
      "loss": 0.3823,
      "step": 1100
    },
    {
      "epoch": 1.6408125577100647,
      "grad_norm": 0.3663816750049591,
      "learning_rate": 1.5509769728726243e-06,
      "loss": 0.3822,
      "step": 1110
    },
    {
      "epoch": 1.6555863342566943,
      "grad_norm": 0.36826223134994507,
      "learning_rate": 1.4285272023540297e-06,
      "loss": 0.3949,
      "step": 1120
    },
    {
      "epoch": 1.6703601108033241,
      "grad_norm": 0.3680952489376068,
      "learning_rate": 1.3107397329458348e-06,
      "loss": 0.3802,
      "step": 1130
    },
    {
      "epoch": 1.685133887349954,
      "grad_norm": 0.37624391913414,
      "learning_rate": 1.1976786330598978e-06,
      "loss": 0.3868,
      "step": 1140
    },
    {
      "epoch": 1.6999076638965835,
      "grad_norm": 0.38218700885772705,
      "learning_rate": 1.0894054002829192e-06,
      "loss": 0.3854,
      "step": 1150
    },
    {
      "epoch": 1.7146814404432131,
      "grad_norm": 0.36962419748306274,
      "learning_rate": 9.859789279259225e-07,
      "loss": 0.3962,
      "step": 1160
    },
    {
      "epoch": 1.7294552169898432,
      "grad_norm": 0.377200186252594,
      "learning_rate": 8.874554729902796e-07,
      "loss": 0.3879,
      "step": 1170
    },
    {
      "epoch": 1.7442289935364728,
      "grad_norm": 0.42530199885368347,
      "learning_rate": 7.938886255676992e-07,
      "loss": 0.3907,
      "step": 1180
    },
    {
      "epoch": 1.7590027700831024,
      "grad_norm": 0.3434763550758362,
      "learning_rate": 7.053292796908629e-07,
      "loss": 0.3828,
      "step": 1190
    },
    {
      "epoch": 1.7737765466297324,
      "grad_norm": 0.3883095681667328,
      "learning_rate": 6.218256056504923e-07,
      "loss": 0.3985,
      "step": 1200
    },
    {
      "epoch": 1.788550323176362,
      "grad_norm": 0.37179863452911377,
      "learning_rate": 5.434230237939919e-07,
      "loss": 0.3761,
      "step": 1210
    },
    {
      "epoch": 1.8033240997229916,
      "grad_norm": 0.3730454444885254,
      "learning_rate": 4.701641798198353e-07,
      "loss": 0.3821,
      "step": 1220
    },
    {
      "epoch": 1.8180978762696214,
      "grad_norm": 0.3819945156574249,
      "learning_rate": 4.020889215812085e-07,
      "loss": 0.3761,
      "step": 1230
    },
    {
      "epoch": 1.8328716528162512,
      "grad_norm": 0.37307223677635193,
      "learning_rate": 3.392342774114643e-07,
      "loss": 0.3864,
      "step": 1240
    },
    {
      "epoch": 1.8476454293628808,
      "grad_norm": 0.39165136218070984,
      "learning_rate": 2.81634435983219e-07,
      "loss": 0.3697,
      "step": 1250
    },
    {
      "epoch": 1.8624192059095106,
      "grad_norm": 0.356090247631073,
      "learning_rate": 2.2932072771202464e-07,
      "loss": 0.375,
      "step": 1260
    },
    {
      "epoch": 1.8771929824561404,
      "grad_norm": 0.39605626463890076,
      "learning_rate": 1.8232160771474494e-07,
      "loss": 0.3907,
      "step": 1270
    },
    {
      "epoch": 1.89196675900277,
      "grad_norm": 0.43363359570503235,
      "learning_rate": 1.4066264033190002e-07,
      "loss": 0.3891,
      "step": 1280
    },
    {
      "epoch": 1.9067405355493998,
      "grad_norm": 0.35953640937805176,
      "learning_rate": 1.0436648522239245e-07,
      "loss": 0.3743,
      "step": 1290
    },
    {
      "epoch": 1.9215143120960296,
      "grad_norm": 0.3743695616722107,
      "learning_rate": 7.345288503818771e-08,
      "loss": 0.3811,
      "step": 1300
    },
    {
      "epoch": 1.9362880886426592,
      "grad_norm": 0.36256566643714905,
      "learning_rate": 4.79386546856464e-08,
      "loss": 0.385,
      "step": 1310
    },
    {
      "epoch": 1.951061865189289,
      "grad_norm": 0.37066614627838135,
      "learning_rate": 2.7837672179351625e-08,
      "loss": 0.39,
      "step": 1320
    },
    {
      "epoch": 1.9658356417359188,
      "grad_norm": 0.3880769908428192,
      "learning_rate": 1.3160871093416127e-08,
      "loss": 0.3931,
      "step": 1330
    },
    {
      "epoch": 1.9806094182825484,
      "grad_norm": 0.3853800594806671,
      "learning_rate": 3.916234614346204e-09,
      "loss": 0.3668,
      "step": 1340
    },
    {
      "epoch": 1.9953831948291783,
      "grad_norm": 0.3556610643863678,
      "learning_rate": 1.0879119873852262e-10,
      "loss": 0.3683,
      "step": 1350
    },
    {
      "epoch": 1.9983379501385041,
      "step": 1352,
      "total_flos": 5.400074130680709e+18,
      "train_loss": 0.40678354952285983,
      "train_runtime": 11026.6518,
      "train_samples_per_second": 11.786,
      "train_steps_per_second": 0.123
    }
  ],
  "logging_steps": 10,
  "max_steps": 1352,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.400074130680709e+18,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
