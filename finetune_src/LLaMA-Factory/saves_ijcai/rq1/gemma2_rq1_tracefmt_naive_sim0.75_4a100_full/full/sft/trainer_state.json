{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.9992242048099302,
  "eval_steps": 500,
  "global_step": 966,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02068787173519524,
      "grad_norm": 2.0149974168389626,
      "learning_rate": 1.999866416347573e-05,
      "loss": 0.6098,
      "step": 10
    },
    {
      "epoch": 0.04137574347039048,
      "grad_norm": 1.4396575827725304,
      "learning_rate": 1.998797961253727e-05,
      "loss": 0.4981,
      "step": 20
    },
    {
      "epoch": 0.062063615205585725,
      "grad_norm": 1.030118656975923,
      "learning_rate": 1.996662192814842e-05,
      "loss": 0.4802,
      "step": 30
    },
    {
      "epoch": 0.08275148694078097,
      "grad_norm": 0.9349211175670538,
      "learning_rate": 1.993461393308461e-05,
      "loss": 0.4727,
      "step": 40
    },
    {
      "epoch": 0.10343935867597621,
      "grad_norm": 1.0621862169750305,
      "learning_rate": 1.9891989831020252e-05,
      "loss": 0.4544,
      "step": 50
    },
    {
      "epoch": 0.12412723041117145,
      "grad_norm": 0.9346486886613422,
      "learning_rate": 1.9838795169978794e-05,
      "loss": 0.4498,
      "step": 60
    },
    {
      "epoch": 0.1448151021463667,
      "grad_norm": 0.8497739694173393,
      "learning_rate": 1.977508679366018e-05,
      "loss": 0.4379,
      "step": 70
    },
    {
      "epoch": 0.16550297388156193,
      "grad_norm": 0.8656646095939806,
      "learning_rate": 1.97009327806978e-05,
      "loss": 0.4381,
      "step": 80
    },
    {
      "epoch": 0.18619084561675717,
      "grad_norm": 0.8539297513335375,
      "learning_rate": 1.961641237190981e-05,
      "loss": 0.4243,
      "step": 90
    },
    {
      "epoch": 0.20687871735195243,
      "grad_norm": 0.8066408089505187,
      "learning_rate": 1.9521615885622566e-05,
      "loss": 0.4101,
      "step": 100
    },
    {
      "epoch": 0.22756658908714766,
      "grad_norm": 0.8335730486306686,
      "learning_rate": 1.9416644621156657e-05,
      "loss": 0.4158,
      "step": 110
    },
    {
      "epoch": 0.2482544608223429,
      "grad_norm": 0.7865743399569947,
      "learning_rate": 1.9301610750578662e-05,
      "loss": 0.4232,
      "step": 120
    },
    {
      "epoch": 0.26894233255753813,
      "grad_norm": 0.8244313087690902,
      "learning_rate": 1.9176637198834323e-05,
      "loss": 0.4013,
      "step": 130
    },
    {
      "epoch": 0.2896302042927334,
      "grad_norm": 0.742590237150799,
      "learning_rate": 1.9041857512391227e-05,
      "loss": 0.4135,
      "step": 140
    },
    {
      "epoch": 0.3103180760279286,
      "grad_norm": 0.7843895091531625,
      "learning_rate": 1.8897415716531324e-05,
      "loss": 0.4019,
      "step": 150
    },
    {
      "epoch": 0.33100594776312386,
      "grad_norm": 0.8011061022655869,
      "learning_rate": 1.8743466161445823e-05,
      "loss": 0.3926,
      "step": 160
    },
    {
      "epoch": 0.3516938194983191,
      "grad_norm": 0.7104927509405687,
      "learning_rate": 1.8580173357296923e-05,
      "loss": 0.3869,
      "step": 170
    },
    {
      "epoch": 0.37238169123351433,
      "grad_norm": 0.7183451039026773,
      "learning_rate": 1.8407711798422597e-05,
      "loss": 0.3909,
      "step": 180
    },
    {
      "epoch": 0.3930695629687096,
      "grad_norm": 0.7541051138107704,
      "learning_rate": 1.8226265776872317e-05,
      "loss": 0.3855,
      "step": 190
    },
    {
      "epoch": 0.41375743470390486,
      "grad_norm": 0.7411469688354442,
      "learning_rate": 1.8036029185472982e-05,
      "loss": 0.3873,
      "step": 200
    },
    {
      "epoch": 0.43444530643910007,
      "grad_norm": 0.6958435968608604,
      "learning_rate": 1.7837205310635452e-05,
      "loss": 0.3847,
      "step": 210
    },
    {
      "epoch": 0.4551331781742953,
      "grad_norm": 0.7354768912034167,
      "learning_rate": 1.7630006615123118e-05,
      "loss": 0.3911,
      "step": 220
    },
    {
      "epoch": 0.47582104990949053,
      "grad_norm": 0.7218727620387135,
      "learning_rate": 1.7414654511014684e-05,
      "loss": 0.3785,
      "step": 230
    },
    {
      "epoch": 0.4965089216446858,
      "grad_norm": 0.6510074635099974,
      "learning_rate": 1.719137912310366e-05,
      "loss": 0.3708,
      "step": 240
    },
    {
      "epoch": 0.517196793379881,
      "grad_norm": 0.7655210320536067,
      "learning_rate": 1.6960419042987525e-05,
      "loss": 0.368,
      "step": 250
    },
    {
      "epoch": 0.5378846651150763,
      "grad_norm": 0.7249266218098964,
      "learning_rate": 1.6722021074109265e-05,
      "loss": 0.3868,
      "step": 260
    },
    {
      "epoch": 0.5585725368502715,
      "grad_norm": 0.7074583039481107,
      "learning_rate": 1.6476439968023727e-05,
      "loss": 0.379,
      "step": 270
    },
    {
      "epoch": 0.5792604085854668,
      "grad_norm": 0.7202306919446134,
      "learning_rate": 1.6223938152170678e-05,
      "loss": 0.3708,
      "step": 280
    },
    {
      "epoch": 0.599948280320662,
      "grad_norm": 0.6871608474549488,
      "learning_rate": 1.5964785449445405e-05,
      "loss": 0.3743,
      "step": 290
    },
    {
      "epoch": 0.6206361520558572,
      "grad_norm": 0.7541793223928301,
      "learning_rate": 1.5699258789866537e-05,
      "loss": 0.369,
      "step": 300
    },
    {
      "epoch": 0.6413240237910525,
      "grad_norm": 0.6683934821983439,
      "learning_rate": 1.5427641914649246e-05,
      "loss": 0.364,
      "step": 310
    },
    {
      "epoch": 0.6620118955262477,
      "grad_norm": 0.7239406105134669,
      "learning_rate": 1.5150225072999969e-05,
      "loss": 0.3556,
      "step": 320
    },
    {
      "epoch": 0.682699767261443,
      "grad_norm": 0.6418018129079721,
      "learning_rate": 1.4867304711956776e-05,
      "loss": 0.3615,
      "step": 330
    },
    {
      "epoch": 0.7033876389966383,
      "grad_norm": 0.7005497234675652,
      "learning_rate": 1.457918315960666e-05,
      "loss": 0.3443,
      "step": 340
    },
    {
      "epoch": 0.7240755107318335,
      "grad_norm": 0.6542589679880805,
      "learning_rate": 1.4286168302018423e-05,
      "loss": 0.3585,
      "step": 350
    },
    {
      "epoch": 0.7447633824670287,
      "grad_norm": 0.655898306336687,
      "learning_rate": 1.3988573254236281e-05,
      "loss": 0.3582,
      "step": 360
    },
    {
      "epoch": 0.7654512542022239,
      "grad_norm": 0.7405753727105429,
      "learning_rate": 1.36867160256858e-05,
      "loss": 0.3571,
      "step": 370
    },
    {
      "epoch": 0.7861391259374192,
      "grad_norm": 0.6185539001018991,
      "learning_rate": 1.338091918034971e-05,
      "loss": 0.344,
      "step": 380
    },
    {
      "epoch": 0.8068269976726145,
      "grad_norm": 0.754765902647086,
      "learning_rate": 1.307150949207674e-05,
      "loss": 0.361,
      "step": 390
    },
    {
      "epoch": 0.8275148694078097,
      "grad_norm": 0.6193687848340773,
      "learning_rate": 1.275881759539178e-05,
      "loss": 0.3522,
      "step": 400
    },
    {
      "epoch": 0.8482027411430049,
      "grad_norm": 0.6606380736001326,
      "learning_rate": 1.2443177632180535e-05,
      "loss": 0.3552,
      "step": 410
    },
    {
      "epoch": 0.8688906128782001,
      "grad_norm": 0.6382695398101846,
      "learning_rate": 1.2124926894626244e-05,
      "loss": 0.3519,
      "step": 420
    },
    {
      "epoch": 0.8895784846133954,
      "grad_norm": 0.7079856674987951,
      "learning_rate": 1.180440546477997e-05,
      "loss": 0.3392,
      "step": 430
    },
    {
      "epoch": 0.9102663563485907,
      "grad_norm": 0.6087304225081065,
      "learning_rate": 1.148195585114966e-05,
      "loss": 0.3294,
      "step": 440
    },
    {
      "epoch": 0.9309542280837859,
      "grad_norm": 0.6080823485779665,
      "learning_rate": 1.1157922622696278e-05,
      "loss": 0.339,
      "step": 450
    },
    {
      "epoch": 0.9516420998189811,
      "grad_norm": 0.6242973134306619,
      "learning_rate": 1.0832652040628182e-05,
      "loss": 0.3349,
      "step": 460
    },
    {
      "epoch": 0.9723299715541763,
      "grad_norm": 0.6481595874753627,
      "learning_rate": 1.0506491688387128e-05,
      "loss": 0.3449,
      "step": 470
    },
    {
      "epoch": 0.9930178432893716,
      "grad_norm": 0.6431660513420289,
      "learning_rate": 1.0179790100221355e-05,
      "loss": 0.3407,
      "step": 480
    },
    {
      "epoch": 1.0144815102146367,
      "grad_norm": 0.6042042419541799,
      "learning_rate": 9.852896388742641e-06,
      "loss": 0.235,
      "step": 490
    },
    {
      "epoch": 1.035169381949832,
      "grad_norm": 0.6521525557274716,
      "learning_rate": 9.526159871865329e-06,
      "loss": 0.2409,
      "step": 500
    },
    {
      "epoch": 1.0558572536850273,
      "grad_norm": 0.609093760434094,
      "learning_rate": 9.199929699525947e-06,
      "loss": 0.2392,
      "step": 510
    },
    {
      "epoch": 1.0765451254202223,
      "grad_norm": 0.6079292454891851,
      "learning_rate": 8.874554480582334e-06,
      "loss": 0.2391,
      "step": 520
    },
    {
      "epoch": 1.0972329971554176,
      "grad_norm": 0.6487423747235991,
      "learning_rate": 8.55038191029099e-06,
      "loss": 0.2392,
      "step": 530
    },
    {
      "epoch": 1.1179208688906128,
      "grad_norm": 0.6326068019476007,
      "learning_rate": 8.227758398760653e-06,
      "loss": 0.2372,
      "step": 540
    },
    {
      "epoch": 1.138608740625808,
      "grad_norm": 0.6737764726463206,
      "learning_rate": 7.907028700779215e-06,
      "loss": 0.233,
      "step": 550
    },
    {
      "epoch": 1.1592966123610033,
      "grad_norm": 0.6505682220160764,
      "learning_rate": 7.588535547409502e-06,
      "loss": 0.2232,
      "step": 560
    },
    {
      "epoch": 1.1799844840961986,
      "grad_norm": 0.6080102795257251,
      "learning_rate": 7.27261927974759e-06,
      "loss": 0.2363,
      "step": 570
    },
    {
      "epoch": 1.2006723558313939,
      "grad_norm": 0.6205160170919966,
      "learning_rate": 6.9596174852350585e-06,
      "loss": 0.2404,
      "step": 580
    },
    {
      "epoch": 1.2213602275665891,
      "grad_norm": 0.6450159553837526,
      "learning_rate": 6.649864636913768e-06,
      "loss": 0.2297,
      "step": 590
    },
    {
      "epoch": 1.2420480993017844,
      "grad_norm": 0.6170299937900656,
      "learning_rate": 6.343691736008691e-06,
      "loss": 0.2392,
      "step": 600
    },
    {
      "epoch": 1.2627359710369794,
      "grad_norm": 0.6791111246697497,
      "learning_rate": 6.041425958220719e-06,
      "loss": 0.2324,
      "step": 610
    },
    {
      "epoch": 1.2834238427721747,
      "grad_norm": 0.6420998286313057,
      "learning_rate": 5.743390304107424e-06,
      "loss": 0.233,
      "step": 620
    },
    {
      "epoch": 1.30411171450737,
      "grad_norm": 0.6309847382973749,
      "learning_rate": 5.449903253925346e-06,
      "loss": 0.2366,
      "step": 630
    },
    {
      "epoch": 1.3247995862425652,
      "grad_norm": 0.592874640710929,
      "learning_rate": 5.16127842730268e-06,
      "loss": 0.2368,
      "step": 640
    },
    {
      "epoch": 1.3454874579777605,
      "grad_norm": 0.6030557807810629,
      "learning_rate": 4.8778242481060375e-06,
      "loss": 0.2261,
      "step": 650
    },
    {
      "epoch": 1.3661753297129557,
      "grad_norm": 0.6314005841014358,
      "learning_rate": 4.599843614859339e-06,
      "loss": 0.2268,
      "step": 660
    },
    {
      "epoch": 1.386863201448151,
      "grad_norm": 0.6286324851013746,
      "learning_rate": 4.327633577067125e-06,
      "loss": 0.2292,
      "step": 670
    },
    {
      "epoch": 1.4075510731833463,
      "grad_norm": 0.6450999329539505,
      "learning_rate": 4.061485017788088e-06,
      "loss": 0.2349,
      "step": 680
    },
    {
      "epoch": 1.4282389449185415,
      "grad_norm": 0.6212669722087074,
      "learning_rate": 3.8016823427980842e-06,
      "loss": 0.2289,
      "step": 690
    },
    {
      "epoch": 1.4489268166537368,
      "grad_norm": 0.6799998358608307,
      "learning_rate": 3.54850317667469e-06,
      "loss": 0.2244,
      "step": 700
    },
    {
      "epoch": 1.469614688388932,
      "grad_norm": 0.7042972768805714,
      "learning_rate": 3.3022180661282353e-06,
      "loss": 0.2228,
      "step": 710
    },
    {
      "epoch": 1.4903025601241273,
      "grad_norm": 0.6411887598231562,
      "learning_rate": 3.0630901908961297e-06,
      "loss": 0.2161,
      "step": 720
    },
    {
      "epoch": 1.5109904318593226,
      "grad_norm": 0.6410582502289813,
      "learning_rate": 2.8313750825095756e-06,
      "loss": 0.2269,
      "step": 730
    },
    {
      "epoch": 1.5316783035945178,
      "grad_norm": 0.6447597850113201,
      "learning_rate": 2.6073203512331393e-06,
      "loss": 0.228,
      "step": 740
    },
    {
      "epoch": 1.552366175329713,
      "grad_norm": 0.7581136390860588,
      "learning_rate": 2.3911654214689385e-06,
      "loss": 0.225,
      "step": 750
    },
    {
      "epoch": 1.5730540470649081,
      "grad_norm": 0.6456034524004205,
      "learning_rate": 2.183141275908247e-06,
      "loss": 0.2197,
      "step": 760
    },
    {
      "epoch": 1.5937419188001034,
      "grad_norm": 0.6140187582946923,
      "learning_rate": 1.9834702087039027e-06,
      "loss": 0.2265,
      "step": 770
    },
    {
      "epoch": 1.6144297905352987,
      "grad_norm": 0.6242472149392015,
      "learning_rate": 1.7923655879272395e-06,
      "loss": 0.2207,
      "step": 780
    },
    {
      "epoch": 1.635117662270494,
      "grad_norm": 0.6646139770365614,
      "learning_rate": 1.6100316275634265e-06,
      "loss": 0.2186,
      "step": 790
    },
    {
      "epoch": 1.6558055340056892,
      "grad_norm": 0.6350072242011006,
      "learning_rate": 1.4366631692888656e-06,
      "loss": 0.2202,
      "step": 800
    },
    {
      "epoch": 1.6764934057408845,
      "grad_norm": 0.6163667021129835,
      "learning_rate": 1.2724454742637714e-06,
      "loss": 0.221,
      "step": 810
    },
    {
      "epoch": 1.6971812774760795,
      "grad_norm": 0.6375282948003631,
      "learning_rate": 1.1175540251625106e-06,
      "loss": 0.2225,
      "step": 820
    },
    {
      "epoch": 1.7178691492112748,
      "grad_norm": 0.6173351864706422,
      "learning_rate": 9.721543386531907e-07,
      "loss": 0.2313,
      "step": 830
    },
    {
      "epoch": 1.73855702094647,
      "grad_norm": 0.6401100765470511,
      "learning_rate": 8.364017885269026e-07,
      "loss": 0.2265,
      "step": 840
    },
    {
      "epoch": 1.7592448926816653,
      "grad_norm": 0.6431335049770246,
      "learning_rate": 7.10441439665629e-07,
      "loss": 0.2239,
      "step": 850
    },
    {
      "epoch": 1.7799327644168605,
      "grad_norm": 0.6738697596710844,
      "learning_rate": 5.94407893026222e-07,
      "loss": 0.2172,
      "step": 860
    },
    {
      "epoch": 1.8006206361520558,
      "grad_norm": 0.6924311623255921,
      "learning_rate": 4.884251418061092e-07,
      "loss": 0.2258,
      "step": 870
    },
    {
      "epoch": 1.821308507887251,
      "grad_norm": 0.6456405849607663,
      "learning_rate": 3.9260643894443063e-07,
      "loss": 0.222,
      "step": 880
    },
    {
      "epoch": 1.8419963796224463,
      "grad_norm": 0.6039525723058804,
      "learning_rate": 3.0705417610019886e-07,
      "loss": 0.2181,
      "step": 890
    },
    {
      "epoch": 1.8626842513576416,
      "grad_norm": 0.6377654452893945,
      "learning_rate": 2.3185977423678453e-07,
      "loss": 0.2269,
      "step": 900
    },
    {
      "epoch": 1.8833721230928369,
      "grad_norm": 0.6168100693158893,
      "learning_rate": 1.671035859296788e-07,
      "loss": 0.2207,
      "step": 910
    },
    {
      "epoch": 1.9040599948280321,
      "grad_norm": 0.6670538626496877,
      "learning_rate": 1.1285480950189997e-07,
      "loss": 0.2199,
      "step": 920
    },
    {
      "epoch": 1.9247478665632274,
      "grad_norm": 0.6808496569911646,
      "learning_rate": 6.91714150788192e-08,
      "loss": 0.2207,
      "step": 930
    },
    {
      "epoch": 1.9454357382984226,
      "grad_norm": 0.6020619699313399,
      "learning_rate": 3.6100082641405964e-08,
      "loss": 0.2179,
      "step": 940
    },
    {
      "epoch": 1.966123610033618,
      "grad_norm": 0.6614802420097706,
      "learning_rate": 1.3676152144105336e-08,
      "loss": 0.2217,
      "step": 950
    },
    {
      "epoch": 1.9868114817688132,
      "grad_norm": 0.6492524080457378,
      "learning_rate": 1.9235857506316734e-09,
      "loss": 0.223,
      "step": 960
    },
    {
      "epoch": 1.9992242048099302,
      "step": 966,
      "total_flos": 614633357574144.0,
      "train_loss": 0.11389162303498072,
      "train_runtime": 10144.4343,
      "train_samples_per_second": 18.294,
      "train_steps_per_second": 0.095
    }
  ],
  "logging_steps": 10,
  "max_steps": 966,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 614633357574144.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
