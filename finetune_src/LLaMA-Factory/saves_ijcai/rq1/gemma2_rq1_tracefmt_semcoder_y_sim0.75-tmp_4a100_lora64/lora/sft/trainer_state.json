{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 2900,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006896551724137931,
      "grad_norm": 0.4549964964389801,
      "learning_rate": 1.999985279873006e-05,
      "loss": 0.6253,
      "step": 10
    },
    {
      "epoch": 0.013793103448275862,
      "grad_norm": 0.35276269912719727,
      "learning_rate": 1.999867521457224e-05,
      "loss": 0.4965,
      "step": 20
    },
    {
      "epoch": 0.020689655172413793,
      "grad_norm": 0.35926032066345215,
      "learning_rate": 1.9996320184929093e-05,
      "loss": 0.4668,
      "step": 30
    },
    {
      "epoch": 0.027586206896551724,
      "grad_norm": 0.33824414014816284,
      "learning_rate": 1.9992787987129253e-05,
      "loss": 0.4416,
      "step": 40
    },
    {
      "epoch": 0.034482758620689655,
      "grad_norm": 0.36426228284835815,
      "learning_rate": 1.9988079037124866e-05,
      "loss": 0.4465,
      "step": 50
    },
    {
      "epoch": 0.041379310344827586,
      "grad_norm": 0.35690879821777344,
      "learning_rate": 1.9982193889442583e-05,
      "loss": 0.4215,
      "step": 60
    },
    {
      "epoch": 0.04827586206896552,
      "grad_norm": 0.32415899634361267,
      "learning_rate": 1.9975133237118276e-05,
      "loss": 0.4078,
      "step": 70
    },
    {
      "epoch": 0.05517241379310345,
      "grad_norm": 0.33086109161376953,
      "learning_rate": 1.9966897911615417e-05,
      "loss": 0.4134,
      "step": 80
    },
    {
      "epoch": 0.06206896551724138,
      "grad_norm": 0.351264625787735,
      "learning_rate": 1.9957488882727163e-05,
      "loss": 0.4239,
      "step": 90
    },
    {
      "epoch": 0.06896551724137931,
      "grad_norm": 0.34244289994239807,
      "learning_rate": 1.994690725846216e-05,
      "loss": 0.4126,
      "step": 100
    },
    {
      "epoch": 0.07586206896551724,
      "grad_norm": 0.3687000274658203,
      "learning_rate": 1.9935154284914063e-05,
      "loss": 0.4049,
      "step": 110
    },
    {
      "epoch": 0.08275862068965517,
      "grad_norm": 0.3885352611541748,
      "learning_rate": 1.9922231346114795e-05,
      "loss": 0.4071,
      "step": 120
    },
    {
      "epoch": 0.0896551724137931,
      "grad_norm": 0.42031627893447876,
      "learning_rate": 1.9908139963871547e-05,
      "loss": 0.4048,
      "step": 130
    },
    {
      "epoch": 0.09655172413793103,
      "grad_norm": 0.3568692207336426,
      "learning_rate": 1.98928817975876e-05,
      "loss": 0.3899,
      "step": 140
    },
    {
      "epoch": 0.10344827586206896,
      "grad_norm": 0.40651899576187134,
      "learning_rate": 1.9876458644066896e-05,
      "loss": 0.4007,
      "step": 150
    },
    {
      "epoch": 0.1103448275862069,
      "grad_norm": 0.43556252121925354,
      "learning_rate": 1.985887243730244e-05,
      "loss": 0.3976,
      "step": 160
    },
    {
      "epoch": 0.11724137931034483,
      "grad_norm": 0.34041693806648254,
      "learning_rate": 1.9840125248248564e-05,
      "loss": 0.3904,
      "step": 170
    },
    {
      "epoch": 0.12413793103448276,
      "grad_norm": 0.38061705231666565,
      "learning_rate": 1.9820219284577052e-05,
      "loss": 0.3899,
      "step": 180
    },
    {
      "epoch": 0.1310344827586207,
      "grad_norm": 0.35487470030784607,
      "learning_rate": 1.9799156890417156e-05,
      "loss": 0.3979,
      "step": 190
    },
    {
      "epoch": 0.13793103448275862,
      "grad_norm": 0.35941994190216064,
      "learning_rate": 1.9776940546079552e-05,
      "loss": 0.3858,
      "step": 200
    },
    {
      "epoch": 0.14482758620689656,
      "grad_norm": 0.34762606024742126,
      "learning_rate": 1.975357286776427e-05,
      "loss": 0.38,
      "step": 210
    },
    {
      "epoch": 0.15172413793103448,
      "grad_norm": 0.3416067063808441,
      "learning_rate": 1.972905660725259e-05,
      "loss": 0.3909,
      "step": 220
    },
    {
      "epoch": 0.15862068965517243,
      "grad_norm": 0.35911282896995544,
      "learning_rate": 1.970339465158301e-05,
      "loss": 0.3875,
      "step": 230
    },
    {
      "epoch": 0.16551724137931034,
      "grad_norm": 0.4153353273868561,
      "learning_rate": 1.967659002271126e-05,
      "loss": 0.386,
      "step": 240
    },
    {
      "epoch": 0.1724137931034483,
      "grad_norm": 0.3534204661846161,
      "learning_rate": 1.9648645877154435e-05,
      "loss": 0.3764,
      "step": 250
    },
    {
      "epoch": 0.1793103448275862,
      "grad_norm": 0.37305012345314026,
      "learning_rate": 1.9619565505619288e-05,
      "loss": 0.3863,
      "step": 260
    },
    {
      "epoch": 0.18620689655172415,
      "grad_norm": 0.3570883572101593,
      "learning_rate": 1.9589352332614708e-05,
      "loss": 0.3699,
      "step": 270
    },
    {
      "epoch": 0.19310344827586207,
      "grad_norm": 0.3795333206653595,
      "learning_rate": 1.955800991604846e-05,
      "loss": 0.3755,
      "step": 280
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.38761812448501587,
      "learning_rate": 1.9525541946808187e-05,
      "loss": 0.3676,
      "step": 290
    },
    {
      "epoch": 0.20689655172413793,
      "grad_norm": 0.41633927822113037,
      "learning_rate": 1.9491952248326805e-05,
      "loss": 0.3746,
      "step": 300
    },
    {
      "epoch": 0.21379310344827587,
      "grad_norm": 0.37114188075065613,
      "learning_rate": 1.9457244776132208e-05,
      "loss": 0.38,
      "step": 310
    },
    {
      "epoch": 0.2206896551724138,
      "grad_norm": 0.38709715008735657,
      "learning_rate": 1.942142361738151e-05,
      "loss": 0.3665,
      "step": 320
    },
    {
      "epoch": 0.22758620689655173,
      "grad_norm": 0.4007170796394348,
      "learning_rate": 1.9384492990379703e-05,
      "loss": 0.3777,
      "step": 330
    },
    {
      "epoch": 0.23448275862068965,
      "grad_norm": 0.42539018392562866,
      "learning_rate": 1.934645724408294e-05,
      "loss": 0.3837,
      "step": 340
    },
    {
      "epoch": 0.2413793103448276,
      "grad_norm": 0.3391570448875427,
      "learning_rate": 1.9307320857586377e-05,
      "loss": 0.3826,
      "step": 350
    },
    {
      "epoch": 0.2482758620689655,
      "grad_norm": 0.3476925492286682,
      "learning_rate": 1.9267088439596728e-05,
      "loss": 0.3703,
      "step": 360
    },
    {
      "epoch": 0.25517241379310346,
      "grad_norm": 0.41747868061065674,
      "learning_rate": 1.9225764727889543e-05,
      "loss": 0.3645,
      "step": 370
    },
    {
      "epoch": 0.2620689655172414,
      "grad_norm": 0.3804997503757477,
      "learning_rate": 1.9183354588751274e-05,
      "loss": 0.3704,
      "step": 380
    },
    {
      "epoch": 0.2689655172413793,
      "grad_norm": 0.3872449994087219,
      "learning_rate": 1.9139863016406237e-05,
      "loss": 0.3613,
      "step": 390
    },
    {
      "epoch": 0.27586206896551724,
      "grad_norm": 0.3580368757247925,
      "learning_rate": 1.9095295132428485e-05,
      "loss": 0.3911,
      "step": 400
    },
    {
      "epoch": 0.2827586206896552,
      "grad_norm": 0.3655603229999542,
      "learning_rate": 1.904965618513868e-05,
      "loss": 0.365,
      "step": 410
    },
    {
      "epoch": 0.2896551724137931,
      "grad_norm": 0.3693603575229645,
      "learning_rate": 1.900295154898607e-05,
      "loss": 0.3671,
      "step": 420
    },
    {
      "epoch": 0.296551724137931,
      "grad_norm": 0.36060306429862976,
      "learning_rate": 1.8955186723915573e-05,
      "loss": 0.3701,
      "step": 430
    },
    {
      "epoch": 0.30344827586206896,
      "grad_norm": 0.34879395365715027,
      "learning_rate": 1.8906367334720125e-05,
      "loss": 0.3659,
      "step": 440
    },
    {
      "epoch": 0.3103448275862069,
      "grad_norm": 0.40567848086357117,
      "learning_rate": 1.885649913037827e-05,
      "loss": 0.3547,
      "step": 450
    },
    {
      "epoch": 0.31724137931034485,
      "grad_norm": 0.4105428159236908,
      "learning_rate": 1.8805587983377208e-05,
      "loss": 0.3724,
      "step": 460
    },
    {
      "epoch": 0.32413793103448274,
      "grad_norm": 0.40524154901504517,
      "learning_rate": 1.8753639889021197e-05,
      "loss": 0.3567,
      "step": 470
    },
    {
      "epoch": 0.3310344827586207,
      "grad_norm": 0.3954755961894989,
      "learning_rate": 1.8700660964725583e-05,
      "loss": 0.3591,
      "step": 480
    },
    {
      "epoch": 0.33793103448275863,
      "grad_norm": 0.3585079312324524,
      "learning_rate": 1.8646657449296394e-05,
      "loss": 0.3587,
      "step": 490
    },
    {
      "epoch": 0.3448275862068966,
      "grad_norm": 0.33646512031555176,
      "learning_rate": 1.8591635702195672e-05,
      "loss": 0.353,
      "step": 500
    },
    {
      "epoch": 0.35172413793103446,
      "grad_norm": 1.0394357442855835,
      "learning_rate": 1.8535602202792567e-05,
      "loss": 0.3577,
      "step": 510
    },
    {
      "epoch": 0.3586206896551724,
      "grad_norm": 0.33655357360839844,
      "learning_rate": 1.8478563549600318e-05,
      "loss": 0.3525,
      "step": 520
    },
    {
      "epoch": 0.36551724137931035,
      "grad_norm": 0.4009879231452942,
      "learning_rate": 1.8420526459499252e-05,
      "loss": 0.3705,
      "step": 530
    },
    {
      "epoch": 0.3724137931034483,
      "grad_norm": 0.34874898195266724,
      "learning_rate": 1.8361497766945747e-05,
      "loss": 0.3725,
      "step": 540
    },
    {
      "epoch": 0.3793103448275862,
      "grad_norm": 0.3287741541862488,
      "learning_rate": 1.8301484423167456e-05,
      "loss": 0.3536,
      "step": 550
    },
    {
      "epoch": 0.38620689655172413,
      "grad_norm": 0.3603534996509552,
      "learning_rate": 1.8240493495344695e-05,
      "loss": 0.3657,
      "step": 560
    },
    {
      "epoch": 0.3931034482758621,
      "grad_norm": 0.3898656964302063,
      "learning_rate": 1.8178532165778225e-05,
      "loss": 0.3636,
      "step": 570
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.3444974422454834,
      "learning_rate": 1.811560773104346e-05,
      "loss": 0.3649,
      "step": 580
    },
    {
      "epoch": 0.4068965517241379,
      "grad_norm": 0.3708930015563965,
      "learning_rate": 1.8051727601131228e-05,
      "loss": 0.3501,
      "step": 590
    },
    {
      "epoch": 0.41379310344827586,
      "grad_norm": 0.37675169110298157,
      "learning_rate": 1.798689929857516e-05,
      "loss": 0.3586,
      "step": 600
    },
    {
      "epoch": 0.4206896551724138,
      "grad_norm": 0.33822187781333923,
      "learning_rate": 1.7921130457565835e-05,
      "loss": 0.3604,
      "step": 610
    },
    {
      "epoch": 0.42758620689655175,
      "grad_norm": 0.3469635546207428,
      "learning_rate": 1.785442882305179e-05,
      "loss": 0.3616,
      "step": 620
    },
    {
      "epoch": 0.43448275862068964,
      "grad_norm": 0.37071365118026733,
      "learning_rate": 1.7786802249827454e-05,
      "loss": 0.3509,
      "step": 630
    },
    {
      "epoch": 0.4413793103448276,
      "grad_norm": 0.3731566071510315,
      "learning_rate": 1.771825870160819e-05,
      "loss": 0.3689,
      "step": 640
    },
    {
      "epoch": 0.4482758620689655,
      "grad_norm": 0.4006502628326416,
      "learning_rate": 1.764880625009245e-05,
      "loss": 0.3569,
      "step": 650
    },
    {
      "epoch": 0.45517241379310347,
      "grad_norm": 0.37693214416503906,
      "learning_rate": 1.7578453074011302e-05,
      "loss": 0.351,
      "step": 660
    },
    {
      "epoch": 0.46206896551724136,
      "grad_norm": 0.3701207935810089,
      "learning_rate": 1.7507207458165257e-05,
      "loss": 0.3451,
      "step": 670
    },
    {
      "epoch": 0.4689655172413793,
      "grad_norm": 0.35902345180511475,
      "learning_rate": 1.7435077792448666e-05,
      "loss": 0.3565,
      "step": 680
    },
    {
      "epoch": 0.47586206896551725,
      "grad_norm": 0.3665855824947357,
      "learning_rate": 1.736207257086173e-05,
      "loss": 0.3566,
      "step": 690
    },
    {
      "epoch": 0.4827586206896552,
      "grad_norm": 0.5883686542510986,
      "learning_rate": 1.7288200390510227e-05,
      "loss": 0.3394,
      "step": 700
    },
    {
      "epoch": 0.4896551724137931,
      "grad_norm": 0.3604334592819214,
      "learning_rate": 1.7213469950593156e-05,
      "loss": 0.3482,
      "step": 710
    },
    {
      "epoch": 0.496551724137931,
      "grad_norm": 0.39425766468048096,
      "learning_rate": 1.7137890051378264e-05,
      "loss": 0.3544,
      "step": 720
    },
    {
      "epoch": 0.503448275862069,
      "grad_norm": 0.35049840807914734,
      "learning_rate": 1.706146959316576e-05,
      "loss": 0.3486,
      "step": 730
    },
    {
      "epoch": 0.5103448275862069,
      "grad_norm": 0.36307233572006226,
      "learning_rate": 1.6984217575240212e-05,
      "loss": 0.3496,
      "step": 740
    },
    {
      "epoch": 0.5172413793103449,
      "grad_norm": 0.40852031111717224,
      "learning_rate": 1.6906143094810774e-05,
      "loss": 0.3507,
      "step": 750
    },
    {
      "epoch": 0.5241379310344828,
      "grad_norm": 0.3652969002723694,
      "learning_rate": 1.6827255345939915e-05,
      "loss": 0.364,
      "step": 760
    },
    {
      "epoch": 0.5310344827586206,
      "grad_norm": 0.34163346886634827,
      "learning_rate": 1.674756361846071e-05,
      "loss": 0.3587,
      "step": 770
    },
    {
      "epoch": 0.5379310344827586,
      "grad_norm": 0.37316960096359253,
      "learning_rate": 1.666707729688289e-05,
      "loss": 0.3594,
      "step": 780
    },
    {
      "epoch": 0.5448275862068965,
      "grad_norm": 0.3530835509300232,
      "learning_rate": 1.658580585928768e-05,
      "loss": 0.3511,
      "step": 790
    },
    {
      "epoch": 0.5517241379310345,
      "grad_norm": 0.3462326228618622,
      "learning_rate": 1.650375887621171e-05,
      "loss": 0.3557,
      "step": 800
    },
    {
      "epoch": 0.5586206896551724,
      "grad_norm": 0.3720504939556122,
      "learning_rate": 1.642094600951994e-05,
      "loss": 0.3496,
      "step": 810
    },
    {
      "epoch": 0.5655172413793104,
      "grad_norm": 0.3725490868091583,
      "learning_rate": 1.6337377011267924e-05,
      "loss": 0.3512,
      "step": 820
    },
    {
      "epoch": 0.5724137931034483,
      "grad_norm": 0.3490801453590393,
      "learning_rate": 1.6253061722553353e-05,
      "loss": 0.3558,
      "step": 830
    },
    {
      "epoch": 0.5793103448275863,
      "grad_norm": 0.3416250944137573,
      "learning_rate": 1.6168010072357216e-05,
      "loss": 0.3496,
      "step": 840
    },
    {
      "epoch": 0.5862068965517241,
      "grad_norm": 0.3692611753940582,
      "learning_rate": 1.6082232076374532e-05,
      "loss": 0.3476,
      "step": 850
    },
    {
      "epoch": 0.593103448275862,
      "grad_norm": 0.3537365794181824,
      "learning_rate": 1.5995737835834905e-05,
      "loss": 0.3475,
      "step": 860
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.44930458068847656,
      "learning_rate": 1.590853753631301e-05,
      "loss": 0.3495,
      "step": 870
    },
    {
      "epoch": 0.6068965517241379,
      "grad_norm": 0.3842509686946869,
      "learning_rate": 1.5820641446529127e-05,
      "loss": 0.3428,
      "step": 880
    },
    {
      "epoch": 0.6137931034482759,
      "grad_norm": 0.3734526038169861,
      "learning_rate": 1.5732059917139912e-05,
      "loss": 0.3437,
      "step": 890
    },
    {
      "epoch": 0.6206896551724138,
      "grad_norm": 0.34841248393058777,
      "learning_rate": 1.564280337951948e-05,
      "loss": 0.3409,
      "step": 900
    },
    {
      "epoch": 0.6275862068965518,
      "grad_norm": 0.34559381008148193,
      "learning_rate": 1.5552882344531023e-05,
      "loss": 0.3439,
      "step": 910
    },
    {
      "epoch": 0.6344827586206897,
      "grad_norm": 0.3677878677845001,
      "learning_rate": 1.546230740128904e-05,
      "loss": 0.3529,
      "step": 920
    },
    {
      "epoch": 0.6413793103448275,
      "grad_norm": 0.3535381257534027,
      "learning_rate": 1.5371089215912363e-05,
      "loss": 0.3331,
      "step": 930
    },
    {
      "epoch": 0.6482758620689655,
      "grad_norm": 0.3545258641242981,
      "learning_rate": 1.5279238530268112e-05,
      "loss": 0.3371,
      "step": 940
    },
    {
      "epoch": 0.6551724137931034,
      "grad_norm": 0.3613755404949188,
      "learning_rate": 1.5186766160706738e-05,
      "loss": 0.3438,
      "step": 950
    },
    {
      "epoch": 0.6620689655172414,
      "grad_norm": 0.42843592166900635,
      "learning_rate": 1.5093682996788274e-05,
      "loss": 0.3407,
      "step": 960
    },
    {
      "epoch": 0.6689655172413793,
      "grad_norm": 0.3790969252586365,
      "learning_rate": 1.5000000000000002e-05,
      "loss": 0.361,
      "step": 970
    },
    {
      "epoch": 0.6758620689655173,
      "grad_norm": 0.3575455844402313,
      "learning_rate": 1.4905728202465596e-05,
      "loss": 0.3287,
      "step": 980
    },
    {
      "epoch": 0.6827586206896552,
      "grad_norm": 0.3853475749492645,
      "learning_rate": 1.4810878705646005e-05,
      "loss": 0.3494,
      "step": 990
    },
    {
      "epoch": 0.6896551724137931,
      "grad_norm": 0.3955055773258209,
      "learning_rate": 1.4715462679032134e-05,
      "loss": 0.3315,
      "step": 1000
    },
    {
      "epoch": 0.696551724137931,
      "grad_norm": 0.35350847244262695,
      "learning_rate": 1.4619491358829502e-05,
      "loss": 0.3509,
      "step": 1010
    },
    {
      "epoch": 0.7034482758620689,
      "grad_norm": 1.0967334508895874,
      "learning_rate": 1.452297604663511e-05,
      "loss": 0.3372,
      "step": 1020
    },
    {
      "epoch": 0.7103448275862069,
      "grad_norm": 0.37854182720184326,
      "learning_rate": 1.4425928108106519e-05,
      "loss": 0.3435,
      "step": 1030
    },
    {
      "epoch": 0.7172413793103448,
      "grad_norm": 0.38235145807266235,
      "learning_rate": 1.4328358971623455e-05,
      "loss": 0.3559,
      "step": 1040
    },
    {
      "epoch": 0.7241379310344828,
      "grad_norm": 0.3998170495033264,
      "learning_rate": 1.4230280126941987e-05,
      "loss": 0.3487,
      "step": 1050
    },
    {
      "epoch": 0.7310344827586207,
      "grad_norm": 0.36734989285469055,
      "learning_rate": 1.4131703123841503e-05,
      "loss": 0.3427,
      "step": 1060
    },
    {
      "epoch": 0.7379310344827587,
      "grad_norm": 0.3236992359161377,
      "learning_rate": 1.4032639570764595e-05,
      "loss": 0.3444,
      "step": 1070
    },
    {
      "epoch": 0.7448275862068966,
      "grad_norm": 0.358686238527298,
      "learning_rate": 1.393310113345006e-05,
      "loss": 0.3464,
      "step": 1080
    },
    {
      "epoch": 0.7517241379310344,
      "grad_norm": 0.37738487124443054,
      "learning_rate": 1.3833099533559129e-05,
      "loss": 0.3471,
      "step": 1090
    },
    {
      "epoch": 0.7586206896551724,
      "grad_norm": 0.3707297742366791,
      "learning_rate": 1.3732646547295128e-05,
      "loss": 0.3375,
      "step": 1100
    },
    {
      "epoch": 0.7655172413793103,
      "grad_norm": 0.3965558111667633,
      "learning_rate": 1.3631754004016708e-05,
      "loss": 0.346,
      "step": 1110
    },
    {
      "epoch": 0.7724137931034483,
      "grad_norm": 0.3977488875389099,
      "learning_rate": 1.353043378484482e-05,
      "loss": 0.3463,
      "step": 1120
    },
    {
      "epoch": 0.7793103448275862,
      "grad_norm": 0.3367382884025574,
      "learning_rate": 1.34286978212636e-05,
      "loss": 0.3275,
      "step": 1130
    },
    {
      "epoch": 0.7862068965517242,
      "grad_norm": 0.34938156604766846,
      "learning_rate": 1.3326558093715294e-05,
      "loss": 0.3294,
      "step": 1140
    },
    {
      "epoch": 0.7931034482758621,
      "grad_norm": 0.40094876289367676,
      "learning_rate": 1.3224026630189465e-05,
      "loss": 0.3487,
      "step": 1150
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.3996707499027252,
      "learning_rate": 1.3121115504806554e-05,
      "loss": 0.3332,
      "step": 1160
    },
    {
      "epoch": 0.8068965517241379,
      "grad_norm": 0.3693000078201294,
      "learning_rate": 1.3017836836396046e-05,
      "loss": 0.3505,
      "step": 1170
    },
    {
      "epoch": 0.8137931034482758,
      "grad_norm": 0.37665337324142456,
      "learning_rate": 1.2914202787069345e-05,
      "loss": 0.3484,
      "step": 1180
    },
    {
      "epoch": 0.8206896551724138,
      "grad_norm": 0.4543519616127014,
      "learning_rate": 1.2810225560787561e-05,
      "loss": 0.3344,
      "step": 1190
    },
    {
      "epoch": 0.8275862068965517,
      "grad_norm": 0.41112464666366577,
      "learning_rate": 1.2705917401924382e-05,
      "loss": 0.3318,
      "step": 1200
    },
    {
      "epoch": 0.8344827586206897,
      "grad_norm": 0.34009355306625366,
      "learning_rate": 1.2601290593824155e-05,
      "loss": 0.3433,
      "step": 1210
    },
    {
      "epoch": 0.8413793103448276,
      "grad_norm": 0.3639461100101471,
      "learning_rate": 1.2496357457355423e-05,
      "loss": 0.3356,
      "step": 1220
    },
    {
      "epoch": 0.8482758620689655,
      "grad_norm": 0.38871145248413086,
      "learning_rate": 1.239113034945999e-05,
      "loss": 0.3356,
      "step": 1230
    },
    {
      "epoch": 0.8551724137931035,
      "grad_norm": 0.37231284379959106,
      "learning_rate": 1.2285621661697787e-05,
      "loss": 0.3391,
      "step": 1240
    },
    {
      "epoch": 0.8620689655172413,
      "grad_norm": 0.4226093590259552,
      "learning_rate": 1.2179843818787625e-05,
      "loss": 0.3368,
      "step": 1250
    },
    {
      "epoch": 0.8689655172413793,
      "grad_norm": 0.38445547223091125,
      "learning_rate": 1.207380927714407e-05,
      "loss": 0.3346,
      "step": 1260
    },
    {
      "epoch": 0.8758620689655172,
      "grad_norm": 0.3846871852874756,
      "learning_rate": 1.1967530523410578e-05,
      "loss": 0.3317,
      "step": 1270
    },
    {
      "epoch": 0.8827586206896552,
      "grad_norm": 0.39090198278427124,
      "learning_rate": 1.186102007298904e-05,
      "loss": 0.3269,
      "step": 1280
    },
    {
      "epoch": 0.8896551724137931,
      "grad_norm": 0.37910962104797363,
      "learning_rate": 1.1754290468565995e-05,
      "loss": 0.335,
      "step": 1290
    },
    {
      "epoch": 0.896551724137931,
      "grad_norm": 0.4016290009021759,
      "learning_rate": 1.1647354278635583e-05,
      "loss": 0.3174,
      "step": 1300
    },
    {
      "epoch": 0.903448275862069,
      "grad_norm": 0.44334378838539124,
      "learning_rate": 1.1540224096019495e-05,
      "loss": 0.3336,
      "step": 1310
    },
    {
      "epoch": 0.9103448275862069,
      "grad_norm": 0.43010950088500977,
      "learning_rate": 1.1432912536384013e-05,
      "loss": 0.3243,
      "step": 1320
    },
    {
      "epoch": 0.9172413793103448,
      "grad_norm": 0.43141403794288635,
      "learning_rate": 1.1325432236754424e-05,
      "loss": 0.3129,
      "step": 1330
    },
    {
      "epoch": 0.9241379310344827,
      "grad_norm": 0.3727686405181885,
      "learning_rate": 1.121779585402684e-05,
      "loss": 0.3329,
      "step": 1340
    },
    {
      "epoch": 0.9310344827586207,
      "grad_norm": 0.3882504105567932,
      "learning_rate": 1.1110016063477763e-05,
      "loss": 0.3413,
      "step": 1350
    },
    {
      "epoch": 0.9379310344827586,
      "grad_norm": 0.35927873849868774,
      "learning_rate": 1.1002105557271405e-05,
      "loss": 0.3327,
      "step": 1360
    },
    {
      "epoch": 0.9448275862068966,
      "grad_norm": 0.3875282108783722,
      "learning_rate": 1.0894077042965084e-05,
      "loss": 0.3197,
      "step": 1370
    },
    {
      "epoch": 0.9517241379310345,
      "grad_norm": 0.38652679324150085,
      "learning_rate": 1.0785943242012763e-05,
      "loss": 0.3221,
      "step": 1380
    },
    {
      "epoch": 0.9586206896551724,
      "grad_norm": 0.3589502274990082,
      "learning_rate": 1.0677716888266979e-05,
      "loss": 0.3425,
      "step": 1390
    },
    {
      "epoch": 0.9655172413793104,
      "grad_norm": 0.4354589879512787,
      "learning_rate": 1.0569410726479301e-05,
      "loss": 0.3331,
      "step": 1400
    },
    {
      "epoch": 0.9724137931034482,
      "grad_norm": 0.37696993350982666,
      "learning_rate": 1.0461037510799499e-05,
      "loss": 0.3257,
      "step": 1410
    },
    {
      "epoch": 0.9793103448275862,
      "grad_norm": 0.3829285502433777,
      "learning_rate": 1.035261000327363e-05,
      "loss": 0.3359,
      "step": 1420
    },
    {
      "epoch": 0.9862068965517241,
      "grad_norm": 0.39606785774230957,
      "learning_rate": 1.0244140972341155e-05,
      "loss": 0.3308,
      "step": 1430
    },
    {
      "epoch": 0.993103448275862,
      "grad_norm": 0.39620161056518555,
      "learning_rate": 1.0135643191331344e-05,
      "loss": 0.3181,
      "step": 1440
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.4035971164703369,
      "learning_rate": 1.0027129436959082e-05,
      "loss": 0.3279,
      "step": 1450
    },
    {
      "epoch": 1.006896551724138,
      "grad_norm": 0.4206071197986603,
      "learning_rate": 9.918612487820274e-06,
      "loss": 0.2983,
      "step": 1460
    },
    {
      "epoch": 1.013793103448276,
      "grad_norm": 0.4079793691635132,
      "learning_rate": 9.810105122887049e-06,
      "loss": 0.3047,
      "step": 1470
    },
    {
      "epoch": 1.0206896551724138,
      "grad_norm": 0.41654348373413086,
      "learning_rate": 9.701620120002885e-06,
      "loss": 0.3042,
      "step": 1480
    },
    {
      "epoch": 1.0275862068965518,
      "grad_norm": 0.4444591999053955,
      "learning_rate": 9.593170254377915e-06,
      "loss": 0.3013,
      "step": 1490
    },
    {
      "epoch": 1.0344827586206897,
      "grad_norm": 0.41996005177497864,
      "learning_rate": 9.484768297084504e-06,
      "loss": 0.316,
      "step": 1500
    },
    {
      "epoch": 1.0413793103448277,
      "grad_norm": 0.44924113154411316,
      "learning_rate": 9.376427013553311e-06,
      "loss": 0.3081,
      "step": 1510
    },
    {
      "epoch": 1.0482758620689656,
      "grad_norm": 0.4679083526134491,
      "learning_rate": 9.268159162070058e-06,
      "loss": 0.3211,
      "step": 1520
    },
    {
      "epoch": 1.0551724137931036,
      "grad_norm": 0.40640076994895935,
      "learning_rate": 9.159977492273086e-06,
      "loss": 0.3054,
      "step": 1530
    },
    {
      "epoch": 1.0620689655172413,
      "grad_norm": 0.40685632824897766,
      "learning_rate": 9.05189474365198e-06,
      "loss": 0.3091,
      "step": 1540
    },
    {
      "epoch": 1.0689655172413792,
      "grad_norm": 0.37624281644821167,
      "learning_rate": 8.943923644047343e-06,
      "loss": 0.3168,
      "step": 1550
    },
    {
      "epoch": 1.0758620689655172,
      "grad_norm": 0.3869267702102661,
      "learning_rate": 8.836076908151981e-06,
      "loss": 0.3061,
      "step": 1560
    },
    {
      "epoch": 1.0827586206896551,
      "grad_norm": 0.39858728647232056,
      "learning_rate": 8.728367236013595e-06,
      "loss": 0.313,
      "step": 1570
    },
    {
      "epoch": 1.089655172413793,
      "grad_norm": 0.51518315076828,
      "learning_rate": 8.620807311539258e-06,
      "loss": 0.3121,
      "step": 1580
    },
    {
      "epoch": 1.096551724137931,
      "grad_norm": 0.4207751154899597,
      "learning_rate": 8.513409801001731e-06,
      "loss": 0.3196,
      "step": 1590
    },
    {
      "epoch": 1.103448275862069,
      "grad_norm": 0.40880653262138367,
      "learning_rate": 8.406187351547872e-06,
      "loss": 0.3279,
      "step": 1600
    },
    {
      "epoch": 1.110344827586207,
      "grad_norm": 0.4437348246574402,
      "learning_rate": 8.299152589709336e-06,
      "loss": 0.2977,
      "step": 1610
    },
    {
      "epoch": 1.1172413793103448,
      "grad_norm": 0.41408559679985046,
      "learning_rate": 8.192318119915644e-06,
      "loss": 0.3095,
      "step": 1620
    },
    {
      "epoch": 1.1241379310344828,
      "grad_norm": 0.3982033133506775,
      "learning_rate": 8.085696523009907e-06,
      "loss": 0.3009,
      "step": 1630
    },
    {
      "epoch": 1.1310344827586207,
      "grad_norm": 0.4263189136981964,
      "learning_rate": 7.979300354767282e-06,
      "loss": 0.2997,
      "step": 1640
    },
    {
      "epoch": 1.1379310344827587,
      "grad_norm": 0.4281570613384247,
      "learning_rate": 7.873142144416423e-06,
      "loss": 0.3188,
      "step": 1650
    },
    {
      "epoch": 1.1448275862068966,
      "grad_norm": 0.43769124150276184,
      "learning_rate": 7.767234393164017e-06,
      "loss": 0.2901,
      "step": 1660
    },
    {
      "epoch": 1.1517241379310346,
      "grad_norm": 0.4312380850315094,
      "learning_rate": 7.66158957272266e-06,
      "loss": 0.2957,
      "step": 1670
    },
    {
      "epoch": 1.1586206896551725,
      "grad_norm": 0.4726354777812958,
      "learning_rate": 7.556220123842173e-06,
      "loss": 0.2995,
      "step": 1680
    },
    {
      "epoch": 1.1655172413793102,
      "grad_norm": 0.5434174537658691,
      "learning_rate": 7.451138454844575e-06,
      "loss": 0.3035,
      "step": 1690
    },
    {
      "epoch": 1.1724137931034484,
      "grad_norm": 0.4383169114589691,
      "learning_rate": 7.346356940162895e-06,
      "loss": 0.2985,
      "step": 1700
    },
    {
      "epoch": 1.1793103448275861,
      "grad_norm": 0.4151988625526428,
      "learning_rate": 7.241887918883932e-06,
      "loss": 0.3089,
      "step": 1710
    },
    {
      "epoch": 1.186206896551724,
      "grad_norm": 0.42332586646080017,
      "learning_rate": 7.137743693295225e-06,
      "loss": 0.3064,
      "step": 1720
    },
    {
      "epoch": 1.193103448275862,
      "grad_norm": 0.47737500071525574,
      "learning_rate": 7.033936527436318e-06,
      "loss": 0.3261,
      "step": 1730
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.3947485089302063,
      "learning_rate": 6.930478645654554e-06,
      "loss": 0.3054,
      "step": 1740
    },
    {
      "epoch": 1.206896551724138,
      "grad_norm": 0.46381211280822754,
      "learning_rate": 6.827382231165531e-06,
      "loss": 0.3075,
      "step": 1750
    },
    {
      "epoch": 1.2137931034482758,
      "grad_norm": 0.4203891456127167,
      "learning_rate": 6.724659424618401e-06,
      "loss": 0.3011,
      "step": 1760
    },
    {
      "epoch": 1.2206896551724138,
      "grad_norm": 0.39563339948654175,
      "learning_rate": 6.6223223226661994e-06,
      "loss": 0.2913,
      "step": 1770
    },
    {
      "epoch": 1.2275862068965517,
      "grad_norm": 0.4333066940307617,
      "learning_rate": 6.520382976541313e-06,
      "loss": 0.3081,
      "step": 1780
    },
    {
      "epoch": 1.2344827586206897,
      "grad_norm": 0.4271548390388489,
      "learning_rate": 6.418853390636363e-06,
      "loss": 0.3085,
      "step": 1790
    },
    {
      "epoch": 1.2413793103448276,
      "grad_norm": 0.41574525833129883,
      "learning_rate": 6.31774552109053e-06,
      "loss": 0.3267,
      "step": 1800
    },
    {
      "epoch": 1.2482758620689656,
      "grad_norm": 0.4482097029685974,
      "learning_rate": 6.217071274381623e-06,
      "loss": 0.3088,
      "step": 1810
    },
    {
      "epoch": 1.2551724137931035,
      "grad_norm": 0.47548264265060425,
      "learning_rate": 6.116842505923955e-06,
      "loss": 0.3018,
      "step": 1820
    },
    {
      "epoch": 1.2620689655172415,
      "grad_norm": 0.4770122766494751,
      "learning_rate": 6.0170710186722605e-06,
      "loss": 0.3038,
      "step": 1830
    },
    {
      "epoch": 1.2689655172413792,
      "grad_norm": 0.449155330657959,
      "learning_rate": 5.917768561731763e-06,
      "loss": 0.3003,
      "step": 1840
    },
    {
      "epoch": 1.2758620689655173,
      "grad_norm": 0.4363805949687958,
      "learning_rate": 5.8189468289746075e-06,
      "loss": 0.3081,
      "step": 1850
    },
    {
      "epoch": 1.282758620689655,
      "grad_norm": 0.4759491980075836,
      "learning_rate": 5.720617457662801e-06,
      "loss": 0.3069,
      "step": 1860
    },
    {
      "epoch": 1.2896551724137932,
      "grad_norm": 0.4171496033668518,
      "learning_rate": 5.622792027077773e-06,
      "loss": 0.3092,
      "step": 1870
    },
    {
      "epoch": 1.296551724137931,
      "grad_norm": 0.4659416973590851,
      "learning_rate": 5.525482057156833e-06,
      "loss": 0.3056,
      "step": 1880
    },
    {
      "epoch": 1.303448275862069,
      "grad_norm": 0.47213783860206604,
      "learning_rate": 5.4286990071365516e-06,
      "loss": 0.3122,
      "step": 1890
    },
    {
      "epoch": 1.3103448275862069,
      "grad_norm": 0.42599424719810486,
      "learning_rate": 5.332454274203349e-06,
      "loss": 0.3112,
      "step": 1900
    },
    {
      "epoch": 1.3172413793103448,
      "grad_norm": 0.4196832478046417,
      "learning_rate": 5.236759192151336e-06,
      "loss": 0.305,
      "step": 1910
    },
    {
      "epoch": 1.3241379310344827,
      "grad_norm": 0.4312722384929657,
      "learning_rate": 5.141625030047659e-06,
      "loss": 0.3038,
      "step": 1920
    },
    {
      "epoch": 1.3310344827586207,
      "grad_norm": 0.43008244037628174,
      "learning_rate": 5.047062990905436e-06,
      "loss": 0.303,
      "step": 1930
    },
    {
      "epoch": 1.3379310344827586,
      "grad_norm": 0.4375515580177307,
      "learning_rate": 4.953084210364508e-06,
      "loss": 0.2898,
      "step": 1940
    },
    {
      "epoch": 1.3448275862068966,
      "grad_norm": 0.4264649450778961,
      "learning_rate": 4.859699755380106e-06,
      "loss": 0.2988,
      "step": 1950
    },
    {
      "epoch": 1.3517241379310345,
      "grad_norm": 0.4864591062068939,
      "learning_rate": 4.766920622919575e-06,
      "loss": 0.2909,
      "step": 1960
    },
    {
      "epoch": 1.3586206896551725,
      "grad_norm": 0.47046753764152527,
      "learning_rate": 4.674757738667405e-06,
      "loss": 0.2978,
      "step": 1970
    },
    {
      "epoch": 1.3655172413793104,
      "grad_norm": 0.45069000124931335,
      "learning_rate": 4.5832219557385896e-06,
      "loss": 0.3092,
      "step": 1980
    },
    {
      "epoch": 1.3724137931034484,
      "grad_norm": 0.4273606836795807,
      "learning_rate": 4.492324053400592e-06,
      "loss": 0.2891,
      "step": 1990
    },
    {
      "epoch": 1.3793103448275863,
      "grad_norm": 0.41725239157676697,
      "learning_rate": 4.402074735803955e-06,
      "loss": 0.3083,
      "step": 2000
    },
    {
      "epoch": 1.386206896551724,
      "grad_norm": 0.44200557470321655,
      "learning_rate": 4.312484630721786e-06,
      "loss": 0.3024,
      "step": 2010
    },
    {
      "epoch": 1.3931034482758622,
      "grad_norm": 0.418535053730011,
      "learning_rate": 4.223564288298233e-06,
      "loss": 0.3003,
      "step": 2020
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.44532710313796997,
      "learning_rate": 4.135324179806079e-06,
      "loss": 0.314,
      "step": 2030
    },
    {
      "epoch": 1.4068965517241379,
      "grad_norm": 0.46681806445121765,
      "learning_rate": 4.047774696413679e-06,
      "loss": 0.3092,
      "step": 2040
    },
    {
      "epoch": 1.4137931034482758,
      "grad_norm": 0.48413142561912537,
      "learning_rate": 3.960926147961253e-06,
      "loss": 0.306,
      "step": 2050
    },
    {
      "epoch": 1.4206896551724137,
      "grad_norm": 0.4380413889884949,
      "learning_rate": 3.874788761746836e-06,
      "loss": 0.3108,
      "step": 2060
    },
    {
      "epoch": 1.4275862068965517,
      "grad_norm": 0.4479829668998718,
      "learning_rate": 3.7893726813218734e-06,
      "loss": 0.296,
      "step": 2070
    },
    {
      "epoch": 1.4344827586206896,
      "grad_norm": 0.4049298167228699,
      "learning_rate": 3.704687965296746e-06,
      "loss": 0.2998,
      "step": 2080
    },
    {
      "epoch": 1.4413793103448276,
      "grad_norm": 0.4382656216621399,
      "learning_rate": 3.6207445861562497e-06,
      "loss": 0.2921,
      "step": 2090
    },
    {
      "epoch": 1.4482758620689655,
      "grad_norm": 0.4671691358089447,
      "learning_rate": 3.5375524290852394e-06,
      "loss": 0.3088,
      "step": 2100
    },
    {
      "epoch": 1.4551724137931035,
      "grad_norm": 0.374409019947052,
      "learning_rate": 3.4551212908045497e-06,
      "loss": 0.2966,
      "step": 2110
    },
    {
      "epoch": 1.4620689655172414,
      "grad_norm": 0.4487498104572296,
      "learning_rate": 3.373460878417315e-06,
      "loss": 0.29,
      "step": 2120
    },
    {
      "epoch": 1.4689655172413794,
      "grad_norm": 0.41721078753471375,
      "learning_rate": 3.292580808265897e-06,
      "loss": 0.3072,
      "step": 2130
    },
    {
      "epoch": 1.4758620689655173,
      "grad_norm": 0.4524286389350891,
      "learning_rate": 3.2124906047994165e-06,
      "loss": 0.2881,
      "step": 2140
    },
    {
      "epoch": 1.4827586206896552,
      "grad_norm": 0.47671154141426086,
      "learning_rate": 3.1331996994521917e-06,
      "loss": 0.2898,
      "step": 2150
    },
    {
      "epoch": 1.489655172413793,
      "grad_norm": 0.4694278836250305,
      "learning_rate": 3.054717429533063e-06,
      "loss": 0.289,
      "step": 2160
    },
    {
      "epoch": 1.4965517241379311,
      "grad_norm": 0.47081834077835083,
      "learning_rate": 2.977053037125849e-06,
      "loss": 0.3007,
      "step": 2170
    },
    {
      "epoch": 1.5034482758620689,
      "grad_norm": 0.43376439809799194,
      "learning_rate": 2.900215668000991e-06,
      "loss": 0.3066,
      "step": 2180
    },
    {
      "epoch": 1.510344827586207,
      "grad_norm": 0.4274931252002716,
      "learning_rate": 2.8242143705385417e-06,
      "loss": 0.2976,
      "step": 2190
    },
    {
      "epoch": 1.5172413793103448,
      "grad_norm": 0.4647962749004364,
      "learning_rate": 2.7490580946626355e-06,
      "loss": 0.3073,
      "step": 2200
    },
    {
      "epoch": 1.524137931034483,
      "grad_norm": 0.9885451793670654,
      "learning_rate": 2.674755690787526e-06,
      "loss": 0.2951,
      "step": 2210
    },
    {
      "epoch": 1.5310344827586206,
      "grad_norm": 0.4687930941581726,
      "learning_rate": 2.6013159087753927e-06,
      "loss": 0.2899,
      "step": 2220
    },
    {
      "epoch": 1.5379310344827586,
      "grad_norm": 0.4708999991416931,
      "learning_rate": 2.5287473969059174e-06,
      "loss": 0.3165,
      "step": 2230
    },
    {
      "epoch": 1.5448275862068965,
      "grad_norm": 0.4447675943374634,
      "learning_rate": 2.4570587008578896e-06,
      "loss": 0.2971,
      "step": 2240
    },
    {
      "epoch": 1.5517241379310345,
      "grad_norm": 0.48059698939323425,
      "learning_rate": 2.386258262702851e-06,
      "loss": 0.2927,
      "step": 2250
    },
    {
      "epoch": 1.5586206896551724,
      "grad_norm": 0.48232901096343994,
      "learning_rate": 2.3163544199109656e-06,
      "loss": 0.2847,
      "step": 2260
    },
    {
      "epoch": 1.5655172413793104,
      "grad_norm": 0.4311966598033905,
      "learning_rate": 2.2473554043691915e-06,
      "loss": 0.2957,
      "step": 2270
    },
    {
      "epoch": 1.5724137931034483,
      "grad_norm": 0.45672059059143066,
      "learning_rate": 2.179269341411896e-06,
      "loss": 0.2954,
      "step": 2280
    },
    {
      "epoch": 1.5793103448275863,
      "grad_norm": 0.46816766262054443,
      "learning_rate": 2.1121042488640166e-06,
      "loss": 0.3068,
      "step": 2290
    },
    {
      "epoch": 1.5862068965517242,
      "grad_norm": 0.4610837996006012,
      "learning_rate": 2.045868036096864e-06,
      "loss": 0.3059,
      "step": 2300
    },
    {
      "epoch": 1.593103448275862,
      "grad_norm": 0.5581039786338806,
      "learning_rate": 1.9805685030967527e-06,
      "loss": 0.2879,
      "step": 2310
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.4789639413356781,
      "learning_rate": 1.916213339546421e-06,
      "loss": 0.2856,
      "step": 2320
    },
    {
      "epoch": 1.6068965517241378,
      "grad_norm": 0.4363045394420624,
      "learning_rate": 1.8528101239195394e-06,
      "loss": 0.2993,
      "step": 2330
    },
    {
      "epoch": 1.613793103448276,
      "grad_norm": 0.4429803490638733,
      "learning_rate": 1.790366322588236e-06,
      "loss": 0.3005,
      "step": 2340
    },
    {
      "epoch": 1.6206896551724137,
      "grad_norm": 0.4457874298095703,
      "learning_rate": 1.728889288943877e-06,
      "loss": 0.2866,
      "step": 2350
    },
    {
      "epoch": 1.6275862068965519,
      "grad_norm": 0.48540210723876953,
      "learning_rate": 1.6683862625311165e-06,
      "loss": 0.296,
      "step": 2360
    },
    {
      "epoch": 1.6344827586206896,
      "grad_norm": 0.4374246597290039,
      "learning_rate": 1.6088643681953752e-06,
      "loss": 0.2993,
      "step": 2370
    },
    {
      "epoch": 1.6413793103448275,
      "grad_norm": 0.40937936305999756,
      "learning_rate": 1.5503306152438146e-06,
      "loss": 0.3084,
      "step": 2380
    },
    {
      "epoch": 1.6482758620689655,
      "grad_norm": 0.42589929699897766,
      "learning_rate": 1.4927918966199095e-06,
      "loss": 0.2943,
      "step": 2390
    },
    {
      "epoch": 1.6551724137931034,
      "grad_norm": 0.49601200222969055,
      "learning_rate": 1.4362549880917609e-06,
      "loss": 0.2957,
      "step": 2400
    },
    {
      "epoch": 1.6620689655172414,
      "grad_norm": 0.4291629493236542,
      "learning_rate": 1.3807265474541465e-06,
      "loss": 0.3029,
      "step": 2410
    },
    {
      "epoch": 1.6689655172413793,
      "grad_norm": 0.4797789454460144,
      "learning_rate": 1.3262131137445266e-06,
      "loss": 0.2957,
      "step": 2420
    },
    {
      "epoch": 1.6758620689655173,
      "grad_norm": 0.4567699134349823,
      "learning_rate": 1.2727211064729862e-06,
      "loss": 0.2924,
      "step": 2430
    },
    {
      "epoch": 1.6827586206896552,
      "grad_norm": 0.4812210202217102,
      "learning_rate": 1.220256824866285e-06,
      "loss": 0.2995,
      "step": 2440
    },
    {
      "epoch": 1.6896551724137931,
      "grad_norm": 0.47853559255599976,
      "learning_rate": 1.1688264471260546e-06,
      "loss": 0.2859,
      "step": 2450
    },
    {
      "epoch": 1.6965517241379309,
      "grad_norm": 0.4923928380012512,
      "learning_rate": 1.1184360297012532e-06,
      "loss": 0.3107,
      "step": 2460
    },
    {
      "epoch": 1.703448275862069,
      "grad_norm": 0.46322131156921387,
      "learning_rate": 1.0690915065749564e-06,
      "loss": 0.3064,
      "step": 2470
    },
    {
      "epoch": 1.7103448275862068,
      "grad_norm": 0.43052518367767334,
      "learning_rate": 1.0207986885655664e-06,
      "loss": 0.3062,
      "step": 2480
    },
    {
      "epoch": 1.717241379310345,
      "grad_norm": 0.45459702610969543,
      "learning_rate": 9.735632626425463e-07,
      "loss": 0.3002,
      "step": 2490
    },
    {
      "epoch": 1.7241379310344827,
      "grad_norm": 0.4774603545665741,
      "learning_rate": 9.273907912566959e-07,
      "loss": 0.2939,
      "step": 2500
    },
    {
      "epoch": 1.7310344827586208,
      "grad_norm": 0.45360633730888367,
      "learning_rate": 8.822867116851397e-07,
      "loss": 0.3074,
      "step": 2510
    },
    {
      "epoch": 1.7379310344827585,
      "grad_norm": 0.47272172570228577,
      "learning_rate": 8.382563353910122e-07,
      "loss": 0.2962,
      "step": 2520
    },
    {
      "epoch": 1.7448275862068967,
      "grad_norm": 0.5571438074111938,
      "learning_rate": 7.953048473980041e-07,
      "loss": 0.3078,
      "step": 2530
    },
    {
      "epoch": 1.7517241379310344,
      "grad_norm": 0.4040922522544861,
      "learning_rate": 7.534373056797451e-07,
      "loss": 0.2996,
      "step": 2540
    },
    {
      "epoch": 1.7586206896551724,
      "grad_norm": 0.47191426157951355,
      "learning_rate": 7.126586405641989e-07,
      "loss": 0.2962,
      "step": 2550
    },
    {
      "epoch": 1.7655172413793103,
      "grad_norm": 0.6003004908561707,
      "learning_rate": 6.729736541530551e-07,
      "loss": 0.2978,
      "step": 2560
    },
    {
      "epoch": 1.7724137931034483,
      "grad_norm": 0.44826099276542664,
      "learning_rate": 6.343870197562307e-07,
      "loss": 0.2915,
      "step": 2570
    },
    {
      "epoch": 1.7793103448275862,
      "grad_norm": 0.4819903075695038,
      "learning_rate": 5.969032813415577e-07,
      "loss": 0.2964,
      "step": 2580
    },
    {
      "epoch": 1.7862068965517242,
      "grad_norm": 0.44000864028930664,
      "learning_rate": 5.605268529996588e-07,
      "loss": 0.3083,
      "step": 2590
    },
    {
      "epoch": 1.793103448275862,
      "grad_norm": 0.46449145674705505,
      "learning_rate": 5.252620184241697e-07,
      "loss": 0.3003,
      "step": 2600
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.5213032960891724,
      "learning_rate": 4.911129304072648e-07,
      "loss": 0.2946,
      "step": 2610
    },
    {
      "epoch": 1.806896551724138,
      "grad_norm": 0.46566128730773926,
      "learning_rate": 4.5808361035065364e-07,
      "loss": 0.3108,
      "step": 2620
    },
    {
      "epoch": 1.8137931034482757,
      "grad_norm": 0.4286237061023712,
      "learning_rate": 4.261779477919892e-07,
      "loss": 0.295,
      "step": 2630
    },
    {
      "epoch": 1.8206896551724139,
      "grad_norm": 0.46043071150779724,
      "learning_rate": 3.9539969994685676e-07,
      "loss": 0.304,
      "step": 2640
    },
    {
      "epoch": 1.8275862068965516,
      "grad_norm": 0.4789038598537445,
      "learning_rate": 3.6575249126631683e-07,
      "loss": 0.2924,
      "step": 2650
    },
    {
      "epoch": 1.8344827586206898,
      "grad_norm": 0.4262341856956482,
      "learning_rate": 3.372398130100851e-07,
      "loss": 0.2924,
      "step": 2660
    },
    {
      "epoch": 1.8413793103448275,
      "grad_norm": 0.5365864634513855,
      "learning_rate": 3.0986502283541055e-07,
      "loss": 0.3003,
      "step": 2670
    },
    {
      "epoch": 1.8482758620689657,
      "grad_norm": 0.44947096705436707,
      "learning_rate": 2.8363134440166806e-07,
      "loss": 0.3044,
      "step": 2680
    },
    {
      "epoch": 1.8551724137931034,
      "grad_norm": 0.5541318655014038,
      "learning_rate": 2.585418669907458e-07,
      "loss": 0.3109,
      "step": 2690
    },
    {
      "epoch": 1.8620689655172413,
      "grad_norm": 0.4530777931213379,
      "learning_rate": 2.345995451432448e-07,
      "loss": 0.3022,
      "step": 2700
    },
    {
      "epoch": 1.8689655172413793,
      "grad_norm": 0.4495127201080322,
      "learning_rate": 2.1180719831056184e-07,
      "loss": 0.3236,
      "step": 2710
    },
    {
      "epoch": 1.8758620689655172,
      "grad_norm": 0.43805280327796936,
      "learning_rate": 1.9016751052285952e-07,
      "loss": 0.2842,
      "step": 2720
    },
    {
      "epoch": 1.8827586206896552,
      "grad_norm": 0.41076233983039856,
      "learning_rate": 1.6968303007300124e-07,
      "loss": 0.2961,
      "step": 2730
    },
    {
      "epoch": 1.889655172413793,
      "grad_norm": 0.42312535643577576,
      "learning_rate": 1.5035616921646234e-07,
      "loss": 0.3061,
      "step": 2740
    },
    {
      "epoch": 1.896551724137931,
      "grad_norm": 0.4278232753276825,
      "learning_rate": 1.3218920388725853e-07,
      "loss": 0.2887,
      "step": 2750
    },
    {
      "epoch": 1.903448275862069,
      "grad_norm": 0.43519821763038635,
      "learning_rate": 1.1518427342994243e-07,
      "loss": 0.2859,
      "step": 2760
    },
    {
      "epoch": 1.910344827586207,
      "grad_norm": 0.44634494185447693,
      "learning_rate": 9.934338034765956e-08,
      "loss": 0.2939,
      "step": 2770
    },
    {
      "epoch": 1.9172413793103447,
      "grad_norm": 0.4991797208786011,
      "learning_rate": 8.466839006634364e-08,
      "loss": 0.3073,
      "step": 2780
    },
    {
      "epoch": 1.9241379310344828,
      "grad_norm": 0.4483862817287445,
      "learning_rate": 7.116103071503788e-08,
      "loss": 0.2922,
      "step": 2790
    },
    {
      "epoch": 1.9310344827586206,
      "grad_norm": 0.44655242562294006,
      "learning_rate": 5.8822892922399956e-08,
      "loss": 0.2952,
      "step": 2800
    },
    {
      "epoch": 1.9379310344827587,
      "grad_norm": 0.4598047733306885,
      "learning_rate": 4.7655429629372975e-08,
      "loss": 0.2954,
      "step": 2810
    },
    {
      "epoch": 1.9448275862068964,
      "grad_norm": 0.39303305745124817,
      "learning_rate": 3.7659955918103455e-08,
      "loss": 0.2951,
      "step": 2820
    },
    {
      "epoch": 1.9517241379310346,
      "grad_norm": 0.5094866752624512,
      "learning_rate": 2.8837648857066304e-08,
      "loss": 0.2947,
      "step": 2830
    },
    {
      "epoch": 1.9586206896551723,
      "grad_norm": 0.39912378787994385,
      "learning_rate": 2.118954736245682e-08,
      "loss": 0.3023,
      "step": 2840
    },
    {
      "epoch": 1.9655172413793105,
      "grad_norm": 0.4718001186847687,
      "learning_rate": 1.4716552075849655e-08,
      "loss": 0.2983,
      "step": 2850
    },
    {
      "epoch": 1.9724137931034482,
      "grad_norm": 0.6775331497192383,
      "learning_rate": 9.419425258135884e-09,
      "loss": 0.3001,
      "step": 2860
    },
    {
      "epoch": 1.9793103448275862,
      "grad_norm": 0.4532780945301056,
      "learning_rate": 5.2987906997581385e-09,
      "loss": 0.2983,
      "step": 2870
    },
    {
      "epoch": 1.986206896551724,
      "grad_norm": 0.42868056893348694,
      "learning_rate": 2.3551336472582563e-09,
      "loss": 0.301,
      "step": 2880
    },
    {
      "epoch": 1.993103448275862,
      "grad_norm": 0.45943140983581543,
      "learning_rate": 5.888007461307688e-10,
      "loss": 0.304,
      "step": 2890
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.47802913188934326,
      "learning_rate": 0.0,
      "loss": 0.3064,
      "step": 2900
    },
    {
      "epoch": 2.0,
      "step": 2900,
      "total_flos": 9.673912624441459e+18,
      "train_loss": 0.3315750180441758,
      "train_runtime": 28095.3111,
      "train_samples_per_second": 6.606,
      "train_steps_per_second": 0.103
    }
  ],
  "logging_steps": 10,
  "max_steps": 2900,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 9.673912624441459e+18,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
