{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 1450,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.013793103448275862,
      "grad_norm": 0.3590846657752991,
      "learning_rate": 1.9999409160138695e-05,
      "loss": 5.7713,
      "step": 10
    },
    {
      "epoch": 0.027586206896551724,
      "grad_norm": 0.5120812654495239,
      "learning_rate": 1.9994682860150073e-05,
      "loss": 5.7319,
      "step": 20
    },
    {
      "epoch": 0.041379310344827586,
      "grad_norm": 0.5659735798835754,
      "learning_rate": 1.9985232494095982e-05,
      "loss": 5.7247,
      "step": 30
    },
    {
      "epoch": 0.05517241379310345,
      "grad_norm": 0.4825066030025482,
      "learning_rate": 1.9971062528766825e-05,
      "loss": 5.355,
      "step": 40
    },
    {
      "epoch": 0.06896551724137931,
      "grad_norm": 0.47817665338516235,
      "learning_rate": 1.9952179661709028e-05,
      "loss": 5.3124,
      "step": 50
    },
    {
      "epoch": 0.08275862068965517,
      "grad_norm": 0.5412585139274597,
      "learning_rate": 1.992859281805935e-05,
      "loss": 5.0662,
      "step": 60
    },
    {
      "epoch": 0.09655172413793103,
      "grad_norm": 0.5475751161575317,
      "learning_rate": 1.9900313146326384e-05,
      "loss": 4.798,
      "step": 70
    },
    {
      "epoch": 0.1103448275862069,
      "grad_norm": 0.5014691352844238,
      "learning_rate": 1.98673540131211e-05,
      "loss": 4.5853,
      "step": 80
    },
    {
      "epoch": 0.12413793103448276,
      "grad_norm": 0.45115968585014343,
      "learning_rate": 1.982973099683902e-05,
      "loss": 4.4003,
      "step": 90
    },
    {
      "epoch": 0.13793103448275862,
      "grad_norm": 0.4143872559070587,
      "learning_rate": 1.9787461880296964e-05,
      "loss": 4.2691,
      "step": 100
    },
    {
      "epoch": 0.15172413793103448,
      "grad_norm": 0.37778782844543457,
      "learning_rate": 1.9740566642327868e-05,
      "loss": 4.137,
      "step": 110
    },
    {
      "epoch": 0.16551724137931034,
      "grad_norm": 0.37770015001296997,
      "learning_rate": 1.968906744833762e-05,
      "loss": 4.1211,
      "step": 120
    },
    {
      "epoch": 0.1793103448275862,
      "grad_norm": 0.4582783281803131,
      "learning_rate": 1.9632988639828407e-05,
      "loss": 4.0644,
      "step": 130
    },
    {
      "epoch": 0.19310344827586207,
      "grad_norm": 0.403521329164505,
      "learning_rate": 1.957235672289352e-05,
      "loss": 3.8842,
      "step": 140
    },
    {
      "epoch": 0.20689655172413793,
      "grad_norm": 0.4204026758670807,
      "learning_rate": 1.9507200355689028e-05,
      "loss": 3.8606,
      "step": 150
    },
    {
      "epoch": 0.2206896551724138,
      "grad_norm": 0.4734439551830292,
      "learning_rate": 1.9437550334888277e-05,
      "loss": 3.89,
      "step": 160
    },
    {
      "epoch": 0.23448275862068965,
      "grad_norm": 0.4431666433811188,
      "learning_rate": 1.9363439581125603e-05,
      "loss": 3.9656,
      "step": 170
    },
    {
      "epoch": 0.2482758620689655,
      "grad_norm": 0.4413367211818695,
      "learning_rate": 1.9284903123436126e-05,
      "loss": 4.0053,
      "step": 180
    },
    {
      "epoch": 0.2620689655172414,
      "grad_norm": 0.4448445737361908,
      "learning_rate": 1.9201978082699008e-05,
      "loss": 3.719,
      "step": 190
    },
    {
      "epoch": 0.27586206896551724,
      "grad_norm": 0.4734037518501282,
      "learning_rate": 1.911470365409196e-05,
      "loss": 3.9086,
      "step": 200
    },
    {
      "epoch": 0.2896551724137931,
      "grad_norm": 0.44161713123321533,
      "learning_rate": 1.9023121088565353e-05,
      "loss": 3.8327,
      "step": 210
    },
    {
      "epoch": 0.30344827586206896,
      "grad_norm": 0.4590662121772766,
      "learning_rate": 1.89272736733446e-05,
      "loss": 3.8127,
      "step": 220
    },
    {
      "epoch": 0.31724137931034485,
      "grad_norm": 0.48991939425468445,
      "learning_rate": 1.882720671147014e-05,
      "loss": 3.6931,
      "step": 230
    },
    {
      "epoch": 0.3310344827586207,
      "grad_norm": 0.4819628596305847,
      "learning_rate": 1.8722967500384564e-05,
      "loss": 3.7114,
      "step": 240
    },
    {
      "epoch": 0.3448275862068966,
      "grad_norm": 0.48566797375679016,
      "learning_rate": 1.8614605309577135e-05,
      "loss": 3.6602,
      "step": 250
    },
    {
      "epoch": 0.3586206896551724,
      "grad_norm": 0.4895278215408325,
      "learning_rate": 1.8502171357296144e-05,
      "loss": 3.6081,
      "step": 260
    },
    {
      "epoch": 0.3724137931034483,
      "grad_norm": 0.5084953904151917,
      "learning_rate": 1.8385718786340216e-05,
      "loss": 3.7649,
      "step": 270
    },
    {
      "epoch": 0.38620689655172413,
      "grad_norm": 0.6020566821098328,
      "learning_rate": 1.826530263893995e-05,
      "loss": 3.6493,
      "step": 280
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5564821362495422,
      "learning_rate": 1.8140979830741753e-05,
      "loss": 3.7073,
      "step": 290
    },
    {
      "epoch": 0.41379310344827586,
      "grad_norm": 0.5707618594169617,
      "learning_rate": 1.801280912390623e-05,
      "loss": 3.724,
      "step": 300
    },
    {
      "epoch": 0.42758620689655175,
      "grad_norm": 0.5073804259300232,
      "learning_rate": 1.7880851099333762e-05,
      "loss": 3.6646,
      "step": 310
    },
    {
      "epoch": 0.4413793103448276,
      "grad_norm": 0.5874117016792297,
      "learning_rate": 1.7745168128030483e-05,
      "loss": 3.7437,
      "step": 320
    },
    {
      "epoch": 0.45517241379310347,
      "grad_norm": 0.5739294290542603,
      "learning_rate": 1.760582434162812e-05,
      "loss": 3.6263,
      "step": 330
    },
    {
      "epoch": 0.4689655172413793,
      "grad_norm": 0.6097328662872314,
      "learning_rate": 1.7462885602071663e-05,
      "loss": 3.5709,
      "step": 340
    },
    {
      "epoch": 0.4827586206896552,
      "grad_norm": 0.6457644701004028,
      "learning_rate": 1.731641947048921e-05,
      "loss": 3.5124,
      "step": 350
    },
    {
      "epoch": 0.496551724137931,
      "grad_norm": 0.6452886462211609,
      "learning_rate": 1.7166495175258654e-05,
      "loss": 3.5483,
      "step": 360
    },
    {
      "epoch": 0.5103448275862069,
      "grad_norm": 0.5898196697235107,
      "learning_rate": 1.701318357928634e-05,
      "loss": 3.5258,
      "step": 370
    },
    {
      "epoch": 0.5241379310344828,
      "grad_norm": 0.6641446948051453,
      "learning_rate": 1.685655714651316e-05,
      "loss": 3.5971,
      "step": 380
    },
    {
      "epoch": 0.5379310344827586,
      "grad_norm": 0.6322223544120789,
      "learning_rate": 1.669668990766388e-05,
      "loss": 3.7061,
      "step": 390
    },
    {
      "epoch": 0.5517241379310345,
      "grad_norm": 0.5816009640693665,
      "learning_rate": 1.6533657425255954e-05,
      "loss": 3.6234,
      "step": 400
    },
    {
      "epoch": 0.5655172413793104,
      "grad_norm": 0.6225245594978333,
      "learning_rate": 1.6367536757884285e-05,
      "loss": 3.5234,
      "step": 410
    },
    {
      "epoch": 0.5793103448275863,
      "grad_norm": 0.6260892748832703,
      "learning_rate": 1.619840642379888e-05,
      "loss": 3.5996,
      "step": 420
    },
    {
      "epoch": 0.593103448275862,
      "grad_norm": 0.6955966353416443,
      "learning_rate": 1.6026346363792565e-05,
      "loss": 3.5911,
      "step": 430
    },
    {
      "epoch": 0.6068965517241379,
      "grad_norm": 0.6980264782905579,
      "learning_rate": 1.585143790341634e-05,
      "loss": 3.5139,
      "step": 440
    },
    {
      "epoch": 0.6206896551724138,
      "grad_norm": 0.6304488778114319,
      "learning_rate": 1.5673763714540214e-05,
      "loss": 3.4874,
      "step": 450
    },
    {
      "epoch": 0.6344827586206897,
      "grad_norm": 0.7263900637626648,
      "learning_rate": 1.54934077762777e-05,
      "loss": 3.523,
      "step": 460
    },
    {
      "epoch": 0.6482758620689655,
      "grad_norm": 0.6774764060974121,
      "learning_rate": 1.5310455335292404e-05,
      "loss": 3.3694,
      "step": 470
    },
    {
      "epoch": 0.6620689655172414,
      "grad_norm": 0.7204694747924805,
      "learning_rate": 1.5124992865505523e-05,
      "loss": 3.5285,
      "step": 480
    },
    {
      "epoch": 0.6758620689655173,
      "grad_norm": 0.7196255922317505,
      "learning_rate": 1.4937108027223266e-05,
      "loss": 3.4138,
      "step": 490
    },
    {
      "epoch": 0.6896551724137931,
      "grad_norm": 0.7424966096878052,
      "learning_rate": 1.4746889625703502e-05,
      "loss": 3.4402,
      "step": 500
    },
    {
      "epoch": 0.7034482758620689,
      "grad_norm": 0.688184916973114,
      "learning_rate": 1.455442756918126e-05,
      "loss": 3.4499,
      "step": 510
    },
    {
      "epoch": 0.7172413793103448,
      "grad_norm": 0.7719296216964722,
      "learning_rate": 1.4359812826372894e-05,
      "loss": 3.5109,
      "step": 520
    },
    {
      "epoch": 0.7310344827586207,
      "grad_norm": 0.7140275239944458,
      "learning_rate": 1.4163137383478984e-05,
      "loss": 3.5434,
      "step": 530
    },
    {
      "epoch": 0.7448275862068966,
      "grad_norm": 0.7019361853599548,
      "learning_rate": 1.3964494200706344e-05,
      "loss": 3.5414,
      "step": 540
    },
    {
      "epoch": 0.7586206896551724,
      "grad_norm": 0.7393417954444885,
      "learning_rate": 1.3763977168329632e-05,
      "loss": 3.4868,
      "step": 550
    },
    {
      "epoch": 0.7724137931034483,
      "grad_norm": 1.032709002494812,
      "learning_rate": 1.356168106231337e-05,
      "loss": 3.5361,
      "step": 560
    },
    {
      "epoch": 0.7862068965517242,
      "grad_norm": 0.7497976422309875,
      "learning_rate": 1.3357701499515345e-05,
      "loss": 3.4044,
      "step": 570
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.8263685703277588,
      "learning_rate": 1.3152134892492525e-05,
      "loss": 3.4937,
      "step": 580
    },
    {
      "epoch": 0.8137931034482758,
      "grad_norm": 0.6852840185165405,
      "learning_rate": 1.2945078403930916e-05,
      "loss": 3.5947,
      "step": 590
    },
    {
      "epoch": 0.8275862068965517,
      "grad_norm": 0.765390932559967,
      "learning_rate": 1.2736629900720832e-05,
      "loss": 3.4501,
      "step": 600
    },
    {
      "epoch": 0.8413793103448276,
      "grad_norm": 0.684719443321228,
      "learning_rate": 1.2526887907699349e-05,
      "loss": 3.4983,
      "step": 610
    },
    {
      "epoch": 0.8551724137931035,
      "grad_norm": 0.7553801536560059,
      "learning_rate": 1.2315951561081754e-05,
      "loss": 3.392,
      "step": 620
    },
    {
      "epoch": 0.8689655172413793,
      "grad_norm": 0.7552453279495239,
      "learning_rate": 1.2103920561604027e-05,
      "loss": 3.4864,
      "step": 630
    },
    {
      "epoch": 0.8827586206896552,
      "grad_norm": 0.7380560636520386,
      "learning_rate": 1.1890895127398497e-05,
      "loss": 3.3891,
      "step": 640
    },
    {
      "epoch": 0.896551724137931,
      "grad_norm": 0.8101640343666077,
      "learning_rate": 1.1676975946624945e-05,
      "loss": 3.3808,
      "step": 650
    },
    {
      "epoch": 0.9103448275862069,
      "grad_norm": 0.7860739827156067,
      "learning_rate": 1.1462264129879555e-05,
      "loss": 3.4077,
      "step": 660
    },
    {
      "epoch": 0.9241379310344827,
      "grad_norm": 0.8209277391433716,
      "learning_rate": 1.1246861162404184e-05,
      "loss": 3.4216,
      "step": 670
    },
    {
      "epoch": 0.9379310344827586,
      "grad_norm": 0.7841299176216125,
      "learning_rate": 1.103086885611856e-05,
      "loss": 3.4068,
      "step": 680
    },
    {
      "epoch": 0.9517241379310345,
      "grad_norm": 0.7028266787528992,
      "learning_rate": 1.0814389301498067e-05,
      "loss": 3.387,
      "step": 690
    },
    {
      "epoch": 0.9655172413793104,
      "grad_norm": 0.8418737649917603,
      "learning_rate": 1.059752481931988e-05,
      "loss": 3.4855,
      "step": 700
    },
    {
      "epoch": 0.9793103448275862,
      "grad_norm": 0.7361438274383545,
      "learning_rate": 1.0380377912300231e-05,
      "loss": 3.3923,
      "step": 710
    },
    {
      "epoch": 0.993103448275862,
      "grad_norm": 0.8683695793151855,
      "learning_rate": 1.0163051216645693e-05,
      "loss": 3.4215,
      "step": 720
    },
    {
      "epoch": 1.006896551724138,
      "grad_norm": 0.871021032333374,
      "learning_rate": 9.94564745354137e-06,
      "loss": 3.3737,
      "step": 730
    },
    {
      "epoch": 1.0206896551724138,
      "grad_norm": 0.8115626573562622,
      "learning_rate": 9.728269380598891e-06,
      "loss": 3.35,
      "step": 740
    },
    {
      "epoch": 1.0344827586206897,
      "grad_norm": 0.8441176414489746,
      "learning_rate": 9.511019743287242e-06,
      "loss": 3.3838,
      "step": 750
    },
    {
      "epoch": 1.0482758620689656,
      "grad_norm": 0.8195377588272095,
      "learning_rate": 9.294001226369281e-06,
      "loss": 3.3706,
      "step": 760
    },
    {
      "epoch": 1.0620689655172413,
      "grad_norm": 0.8391619324684143,
      "learning_rate": 9.07731640536698e-06,
      "loss": 3.4097,
      "step": 770
    },
    {
      "epoch": 1.0758620689655172,
      "grad_norm": 0.8289809226989746,
      "learning_rate": 8.8610676980783e-06,
      "loss": 3.3513,
      "step": 780
    },
    {
      "epoch": 1.089655172413793,
      "grad_norm": 0.8560364842414856,
      "learning_rate": 8.64535731616859e-06,
      "loss": 3.375,
      "step": 790
    },
    {
      "epoch": 1.103448275862069,
      "grad_norm": 0.7742759585380554,
      "learning_rate": 8.430287216859444e-06,
      "loss": 3.4627,
      "step": 800
    },
    {
      "epoch": 1.1172413793103448,
      "grad_norm": 0.8548633456230164,
      "learning_rate": 8.215959054737817e-06,
      "loss": 3.3104,
      "step": 810
    },
    {
      "epoch": 1.1310344827586207,
      "grad_norm": 0.7343088388442993,
      "learning_rate": 8.002474133708163e-06,
      "loss": 3.2969,
      "step": 820
    },
    {
      "epoch": 1.1448275862068966,
      "grad_norm": 0.8405981063842773,
      "learning_rate": 7.789933359110355e-06,
      "loss": 3.363,
      "step": 830
    },
    {
      "epoch": 1.1586206896551725,
      "grad_norm": 0.830214262008667,
      "learning_rate": 7.578437190025972e-06,
      "loss": 3.3301,
      "step": 840
    },
    {
      "epoch": 1.1724137931034484,
      "grad_norm": 0.8315776586532593,
      "learning_rate": 7.368085591795522e-06,
      "loss": 3.3692,
      "step": 850
    },
    {
      "epoch": 1.186206896551724,
      "grad_norm": 0.8455898761749268,
      "learning_rate": 7.1589779887690235e-06,
      "loss": 3.3526,
      "step": 860
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.8142572045326233,
      "learning_rate": 6.951213217312301e-06,
      "loss": 3.4605,
      "step": 870
    },
    {
      "epoch": 1.2137931034482758,
      "grad_norm": 0.8428767323493958,
      "learning_rate": 6.744889479091197e-06,
      "loss": 3.3467,
      "step": 880
    },
    {
      "epoch": 1.2275862068965517,
      "grad_norm": 0.7964645028114319,
      "learning_rate": 6.540104294655778e-06,
      "loss": 3.3219,
      "step": 890
    },
    {
      "epoch": 1.2413793103448276,
      "grad_norm": 0.7992496490478516,
      "learning_rate": 6.336954457346463e-06,
      "loss": 3.4285,
      "step": 900
    },
    {
      "epoch": 1.2551724137931035,
      "grad_norm": 0.829196035861969,
      "learning_rate": 6.1355359875438995e-06,
      "loss": 3.3516,
      "step": 910
    },
    {
      "epoch": 1.2689655172413792,
      "grad_norm": 0.8071413636207581,
      "learning_rate": 5.935944087284155e-06,
      "loss": 3.4143,
      "step": 920
    },
    {
      "epoch": 1.282758620689655,
      "grad_norm": 0.8408955931663513,
      "learning_rate": 5.738273095260728e-06,
      "loss": 3.3369,
      "step": 930
    },
    {
      "epoch": 1.296551724137931,
      "grad_norm": 0.8780843615531921,
      "learning_rate": 5.542616442234618e-06,
      "loss": 3.3622,
      "step": 940
    },
    {
      "epoch": 1.3103448275862069,
      "grad_norm": 0.7613481879234314,
      "learning_rate": 5.349066606873525e-06,
      "loss": 3.3547,
      "step": 950
    },
    {
      "epoch": 1.3241379310344827,
      "grad_norm": 0.8860822319984436,
      "learning_rate": 5.157715072041094e-06,
      "loss": 3.4272,
      "step": 960
    },
    {
      "epoch": 1.3379310344827586,
      "grad_norm": 0.8719221353530884,
      "learning_rate": 4.968652281556794e-06,
      "loss": 3.3076,
      "step": 970
    },
    {
      "epoch": 1.3517241379310345,
      "grad_norm": 0.9113892912864685,
      "learning_rate": 4.781967597446936e-06,
      "loss": 3.2852,
      "step": 980
    },
    {
      "epoch": 1.3655172413793104,
      "grad_norm": 0.8299299478530884,
      "learning_rate": 4.5977492577070196e-06,
      "loss": 3.3156,
      "step": 990
    },
    {
      "epoch": 1.3793103448275863,
      "grad_norm": 0.8602921962738037,
      "learning_rate": 4.416084334595314e-06,
      "loss": 3.3645,
      "step": 1000
    },
    {
      "epoch": 1.3931034482758622,
      "grad_norm": 0.8938947319984436,
      "learning_rate": 4.237058693477499e-06,
      "loss": 3.3391,
      "step": 1010
    },
    {
      "epoch": 1.4068965517241379,
      "grad_norm": 0.9021371603012085,
      "learning_rate": 4.060756952241691e-06,
      "loss": 3.4512,
      "step": 1020
    },
    {
      "epoch": 1.4206896551724137,
      "grad_norm": 0.9141986966133118,
      "learning_rate": 3.887262441303139e-06,
      "loss": 3.3462,
      "step": 1030
    },
    {
      "epoch": 1.4344827586206896,
      "grad_norm": 0.8653215169906616,
      "learning_rate": 3.716657164217454e-06,
      "loss": 3.3336,
      "step": 1040
    },
    {
      "epoch": 1.4482758620689655,
      "grad_norm": 0.9094055891036987,
      "learning_rate": 3.5490217589209554e-06,
      "loss": 3.2963,
      "step": 1050
    },
    {
      "epoch": 1.4620689655172414,
      "grad_norm": 0.8651955723762512,
      "learning_rate": 3.3844354596165364e-06,
      "loss": 3.2916,
      "step": 1060
    },
    {
      "epoch": 1.4758620689655173,
      "grad_norm": 0.8651198148727417,
      "learning_rate": 3.2229760593229686e-06,
      "loss": 3.3047,
      "step": 1070
    },
    {
      "epoch": 1.489655172413793,
      "grad_norm": 0.8677419424057007,
      "learning_rate": 3.064719873105424e-06,
      "loss": 3.1664,
      "step": 1080
    },
    {
      "epoch": 1.5034482758620689,
      "grad_norm": 0.9651962518692017,
      "learning_rate": 2.909741702004565e-06,
      "loss": 3.386,
      "step": 1090
    },
    {
      "epoch": 1.5172413793103448,
      "grad_norm": 0.9476147890090942,
      "learning_rate": 2.758114797681215e-06,
      "loss": 3.3983,
      "step": 1100
    },
    {
      "epoch": 1.5310344827586206,
      "grad_norm": 0.8672407865524292,
      "learning_rate": 2.6099108277934105e-06,
      "loss": 3.3628,
      "step": 1110
    },
    {
      "epoch": 1.5448275862068965,
      "grad_norm": 0.901292085647583,
      "learning_rate": 2.4651998421220847e-06,
      "loss": 3.4412,
      "step": 1120
    },
    {
      "epoch": 1.5586206896551724,
      "grad_norm": 0.8020268678665161,
      "learning_rate": 2.324050239461507e-06,
      "loss": 3.2477,
      "step": 1130
    },
    {
      "epoch": 1.5724137931034483,
      "grad_norm": 0.8829179406166077,
      "learning_rate": 2.186528735290041e-06,
      "loss": 3.2621,
      "step": 1140
    },
    {
      "epoch": 1.5862068965517242,
      "grad_norm": 0.9259974360466003,
      "learning_rate": 2.052700330236541e-06,
      "loss": 3.3923,
      "step": 1150
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.8636610507965088,
      "learning_rate": 1.9226282793572927e-06,
      "loss": 3.2609,
      "step": 1160
    },
    {
      "epoch": 1.613793103448276,
      "grad_norm": 0.9116529822349548,
      "learning_rate": 1.7963740622380199e-06,
      "loss": 3.3923,
      "step": 1170
    },
    {
      "epoch": 1.6275862068965519,
      "grad_norm": 0.8075158596038818,
      "learning_rate": 1.673997353935054e-06,
      "loss": 3.2596,
      "step": 1180
    },
    {
      "epoch": 1.6413793103448275,
      "grad_norm": 0.8222276568412781,
      "learning_rate": 1.5555559967694522e-06,
      "loss": 3.3387,
      "step": 1190
    },
    {
      "epoch": 1.6551724137931034,
      "grad_norm": 0.835981011390686,
      "learning_rate": 1.4411059729873767e-06,
      "loss": 3.2791,
      "step": 1200
    },
    {
      "epoch": 1.6689655172413793,
      "grad_norm": 0.9129842519760132,
      "learning_rate": 1.3307013782996237e-06,
      "loss": 3.3131,
      "step": 1210
    },
    {
      "epoch": 1.6827586206896552,
      "grad_norm": 0.8057200908660889,
      "learning_rate": 1.2243943963128735e-06,
      "loss": 3.3126,
      "step": 1220
    },
    {
      "epoch": 1.6965517241379309,
      "grad_norm": 0.9218168258666992,
      "learning_rate": 1.1222352738646825e-06,
      "loss": 3.3356,
      "step": 1230
    },
    {
      "epoch": 1.7103448275862068,
      "grad_norm": 0.9286395311355591,
      "learning_rate": 1.024272297273925e-06,
      "loss": 3.405,
      "step": 1240
    },
    {
      "epoch": 1.7241379310344827,
      "grad_norm": 0.9580958485603333,
      "learning_rate": 9.305517695178833e-07,
      "loss": 3.3539,
      "step": 1250
    },
    {
      "epoch": 1.7379310344827585,
      "grad_norm": 0.9007027745246887,
      "learning_rate": 8.411179883467668e-07,
      "loss": 3.4111,
      "step": 1260
    },
    {
      "epoch": 1.7517241379310344,
      "grad_norm": 0.8328389525413513,
      "learning_rate": 7.560132253460484e-07,
      "loss": 3.3953,
      "step": 1270
    },
    {
      "epoch": 1.7655172413793103,
      "grad_norm": 0.8703793287277222,
      "learning_rate": 6.752777059564431e-07,
      "loss": 3.3662,
      "step": 1280
    },
    {
      "epoch": 1.7793103448275862,
      "grad_norm": 0.8917354345321655,
      "learning_rate": 5.989495904610509e-07,
      "loss": 3.3294,
      "step": 1290
    },
    {
      "epoch": 1.793103448275862,
      "grad_norm": 0.9029352068901062,
      "learning_rate": 5.270649559485908e-07,
      "loss": 3.426,
      "step": 1300
    },
    {
      "epoch": 1.806896551724138,
      "grad_norm": 0.8622052073478699,
      "learning_rate": 4.5965777926127554e-07,
      "loss": 3.3744,
      "step": 1310
    },
    {
      "epoch": 1.8206896551724139,
      "grad_norm": 0.8645127415657043,
      "learning_rate": 3.9675992093539674e-07,
      "loss": 3.3538,
      "step": 1320
    },
    {
      "epoch": 1.8344827586206898,
      "grad_norm": 0.8750634789466858,
      "learning_rate": 3.3840111014218027e-07,
      "loss": 3.2645,
      "step": 1330
    },
    {
      "epoch": 1.8482758620689657,
      "grad_norm": 0.820907711982727,
      "learning_rate": 2.8460893063606e-07,
      "loss": 3.3765,
      "step": 1340
    },
    {
      "epoch": 1.8620689655172413,
      "grad_norm": 0.8949401378631592,
      "learning_rate": 2.3540880771700802e-07,
      "loss": 3.4233,
      "step": 1350
    },
    {
      "epoch": 1.8758620689655172,
      "grad_norm": 0.9079912304878235,
      "learning_rate": 1.9082399621304758e-07,
      "loss": 3.4191,
      "step": 1360
    },
    {
      "epoch": 1.889655172413793,
      "grad_norm": 0.8985913395881653,
      "learning_rate": 1.5087556948868876e-07,
      "loss": 3.4313,
      "step": 1370
    },
    {
      "epoch": 1.903448275862069,
      "grad_norm": 0.9214896559715271,
      "learning_rate": 1.1558240948443045e-07,
      "loss": 3.3617,
      "step": 1380
    },
    {
      "epoch": 1.9172413793103447,
      "grad_norm": 0.8552213311195374,
      "learning_rate": 8.496119779205724e-08,
      "loss": 3.3904,
      "step": 1390
    },
    {
      "epoch": 1.9310344827586206,
      "grad_norm": 0.8683410286903381,
      "learning_rate": 5.9026407769963156e-08,
      "loss": 3.2815,
      "step": 1400
    },
    {
      "epoch": 1.9448275862068964,
      "grad_norm": 0.8605615496635437,
      "learning_rate": 3.7790297702193776e-08,
      "loss": 3.3111,
      "step": 1410
    },
    {
      "epoch": 1.9586206896551723,
      "grad_norm": 0.9132377505302429,
      "learning_rate": 2.1262905004475477e-08,
      "loss": 3.348,
      "step": 1420
    },
    {
      "epoch": 1.9724137931034482,
      "grad_norm": 1.0065280199050903,
      "learning_rate": 9.45204147995482e-09,
      "loss": 3.4192,
      "step": 1430
    },
    {
      "epoch": 1.986206896551724,
      "grad_norm": 0.8805037140846252,
      "learning_rate": 2.363289626882148e-09,
      "loss": 3.3472,
      "step": 1440
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.8617809414863586,
      "learning_rate": 0.0,
      "loss": 3.4534,
      "step": 1450
    },
    {
      "epoch": 2.0,
      "step": 1450,
      "total_flos": 9.297737544454111e+18,
      "train_loss": 3.5851921923407195,
      "train_runtime": 22775.5521,
      "train_samples_per_second": 8.148,
      "train_steps_per_second": 0.064
    }
  ],
  "logging_steps": 10,
  "max_steps": 1450,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 9.297737544454111e+18,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
