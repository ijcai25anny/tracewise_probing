{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.9989656064132402,
  "eval_steps": 500,
  "global_step": 966,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02068787173519524,
      "grad_norm": 1.723508874790258,
      "learning_rate": 1.999866416347573e-05,
      "loss": 0.6082,
      "step": 10
    },
    {
      "epoch": 0.04137574347039048,
      "grad_norm": 1.1409828390719947,
      "learning_rate": 1.998797961253727e-05,
      "loss": 0.5025,
      "step": 20
    },
    {
      "epoch": 0.062063615205585725,
      "grad_norm": 1.0519601358026742,
      "learning_rate": 1.996662192814842e-05,
      "loss": 0.4796,
      "step": 30
    },
    {
      "epoch": 0.08275148694078097,
      "grad_norm": 0.9950485971166277,
      "learning_rate": 1.993461393308461e-05,
      "loss": 0.4743,
      "step": 40
    },
    {
      "epoch": 0.10343935867597621,
      "grad_norm": 0.9899868243219863,
      "learning_rate": 1.9891989831020252e-05,
      "loss": 0.4549,
      "step": 50
    },
    {
      "epoch": 0.12412723041117145,
      "grad_norm": 0.9342240673322411,
      "learning_rate": 1.9838795169978794e-05,
      "loss": 0.4507,
      "step": 60
    },
    {
      "epoch": 0.1448151021463667,
      "grad_norm": 0.8628746045859246,
      "learning_rate": 1.977508679366018e-05,
      "loss": 0.4392,
      "step": 70
    },
    {
      "epoch": 0.16550297388156193,
      "grad_norm": 0.8819691497724292,
      "learning_rate": 1.97009327806978e-05,
      "loss": 0.4389,
      "step": 80
    },
    {
      "epoch": 0.18619084561675717,
      "grad_norm": 0.8577741820934937,
      "learning_rate": 1.961641237190981e-05,
      "loss": 0.4255,
      "step": 90
    },
    {
      "epoch": 0.20687871735195243,
      "grad_norm": 0.8449118243499318,
      "learning_rate": 1.9521615885622566e-05,
      "loss": 0.4115,
      "step": 100
    },
    {
      "epoch": 0.22756658908714766,
      "grad_norm": 0.7990592589906337,
      "learning_rate": 1.9416644621156657e-05,
      "loss": 0.4169,
      "step": 110
    },
    {
      "epoch": 0.2482544608223429,
      "grad_norm": 0.7651457897721636,
      "learning_rate": 1.9301610750578662e-05,
      "loss": 0.4237,
      "step": 120
    },
    {
      "epoch": 0.26894233255753813,
      "grad_norm": 0.8157714527211247,
      "learning_rate": 1.9176637198834323e-05,
      "loss": 0.4018,
      "step": 130
    },
    {
      "epoch": 0.2896302042927334,
      "grad_norm": 0.7429104111351581,
      "learning_rate": 1.9041857512391227e-05,
      "loss": 0.4136,
      "step": 140
    },
    {
      "epoch": 0.3103180760279286,
      "grad_norm": 0.7881153663972646,
      "learning_rate": 1.8897415716531324e-05,
      "loss": 0.4022,
      "step": 150
    },
    {
      "epoch": 0.33100594776312386,
      "grad_norm": 0.9024932002216662,
      "learning_rate": 1.8743466161445823e-05,
      "loss": 0.3936,
      "step": 160
    },
    {
      "epoch": 0.3516938194983191,
      "grad_norm": 0.7034243292816501,
      "learning_rate": 1.8580173357296923e-05,
      "loss": 0.3871,
      "step": 170
    },
    {
      "epoch": 0.37238169123351433,
      "grad_norm": 0.7058113462942355,
      "learning_rate": 1.8407711798422597e-05,
      "loss": 0.392,
      "step": 180
    },
    {
      "epoch": 0.3930695629687096,
      "grad_norm": 0.759385845361269,
      "learning_rate": 1.8226265776872317e-05,
      "loss": 0.3864,
      "step": 190
    },
    {
      "epoch": 0.41375743470390486,
      "grad_norm": 0.7511291946896071,
      "learning_rate": 1.8036029185472982e-05,
      "loss": 0.3881,
      "step": 200
    },
    {
      "epoch": 0.43444530643910007,
      "grad_norm": 0.7198583673108222,
      "learning_rate": 1.7837205310635452e-05,
      "loss": 0.3853,
      "step": 210
    },
    {
      "epoch": 0.4551331781742953,
      "grad_norm": 0.742133624009223,
      "learning_rate": 1.7630006615123118e-05,
      "loss": 0.392,
      "step": 220
    },
    {
      "epoch": 0.47582104990949053,
      "grad_norm": 0.7713771892329917,
      "learning_rate": 1.7414654511014684e-05,
      "loss": 0.3797,
      "step": 230
    },
    {
      "epoch": 0.4965089216446858,
      "grad_norm": 0.6807789901046825,
      "learning_rate": 1.719137912310366e-05,
      "loss": 0.372,
      "step": 240
    },
    {
      "epoch": 0.517196793379881,
      "grad_norm": 0.7655107044947531,
      "learning_rate": 1.6960419042987525e-05,
      "loss": 0.3697,
      "step": 250
    },
    {
      "epoch": 0.5378846651150763,
      "grad_norm": 0.7379604132938711,
      "learning_rate": 1.6722021074109265e-05,
      "loss": 0.3885,
      "step": 260
    },
    {
      "epoch": 0.5585725368502715,
      "grad_norm": 0.7103241184151431,
      "learning_rate": 1.6476439968023727e-05,
      "loss": 0.3804,
      "step": 270
    },
    {
      "epoch": 0.5792604085854668,
      "grad_norm": 0.7151685790348609,
      "learning_rate": 1.6223938152170678e-05,
      "loss": 0.3718,
      "step": 280
    },
    {
      "epoch": 0.599948280320662,
      "grad_norm": 0.685316009147685,
      "learning_rate": 1.5964785449445405e-05,
      "loss": 0.3754,
      "step": 290
    },
    {
      "epoch": 0.6206361520558572,
      "grad_norm": 0.750763060398114,
      "learning_rate": 1.5699258789866537e-05,
      "loss": 0.37,
      "step": 300
    },
    {
      "epoch": 0.6413240237910525,
      "grad_norm": 0.6485670681294681,
      "learning_rate": 1.5427641914649246e-05,
      "loss": 0.365,
      "step": 310
    },
    {
      "epoch": 0.6620118955262477,
      "grad_norm": 0.6637000317967238,
      "learning_rate": 1.5150225072999969e-05,
      "loss": 0.3566,
      "step": 320
    },
    {
      "epoch": 0.682699767261443,
      "grad_norm": 0.635792686220756,
      "learning_rate": 1.4867304711956776e-05,
      "loss": 0.3626,
      "step": 330
    },
    {
      "epoch": 0.7033876389966383,
      "grad_norm": 0.6737049253568161,
      "learning_rate": 1.457918315960666e-05,
      "loss": 0.3455,
      "step": 340
    },
    {
      "epoch": 0.7240755107318335,
      "grad_norm": 0.6845809330315494,
      "learning_rate": 1.4286168302018423e-05,
      "loss": 0.3595,
      "step": 350
    },
    {
      "epoch": 0.7447633824670287,
      "grad_norm": 0.6915348013805844,
      "learning_rate": 1.3988573254236281e-05,
      "loss": 0.3597,
      "step": 360
    },
    {
      "epoch": 0.7654512542022239,
      "grad_norm": 0.7137869226359173,
      "learning_rate": 1.36867160256858e-05,
      "loss": 0.3587,
      "step": 370
    },
    {
      "epoch": 0.7861391259374192,
      "grad_norm": 0.6102096465765587,
      "learning_rate": 1.338091918034971e-05,
      "loss": 0.3458,
      "step": 380
    },
    {
      "epoch": 0.8068269976726145,
      "grad_norm": 0.7415569548817718,
      "learning_rate": 1.307150949207674e-05,
      "loss": 0.3644,
      "step": 390
    },
    {
      "epoch": 0.8275148694078097,
      "grad_norm": 0.6531227746247993,
      "learning_rate": 1.275881759539178e-05,
      "loss": 0.3547,
      "step": 400
    },
    {
      "epoch": 0.8482027411430049,
      "grad_norm": 0.691568505976861,
      "learning_rate": 1.2443177632180535e-05,
      "loss": 0.3565,
      "step": 410
    },
    {
      "epoch": 0.8688906128782001,
      "grad_norm": 0.6708985889958847,
      "learning_rate": 1.2124926894626244e-05,
      "loss": 0.3521,
      "step": 420
    },
    {
      "epoch": 0.8895784846133954,
      "grad_norm": 0.6779057830795077,
      "learning_rate": 1.180440546477997e-05,
      "loss": 0.3406,
      "step": 430
    },
    {
      "epoch": 0.9102663563485907,
      "grad_norm": 0.6239121935886517,
      "learning_rate": 1.148195585114966e-05,
      "loss": 0.3307,
      "step": 440
    },
    {
      "epoch": 0.9309542280837859,
      "grad_norm": 0.6336709966322592,
      "learning_rate": 1.1157922622696278e-05,
      "loss": 0.3399,
      "step": 450
    },
    {
      "epoch": 0.9516420998189811,
      "grad_norm": 0.6091908278172727,
      "learning_rate": 1.0832652040628182e-05,
      "loss": 0.3355,
      "step": 460
    },
    {
      "epoch": 0.9723299715541763,
      "grad_norm": 0.662592693721229,
      "learning_rate": 1.0506491688387128e-05,
      "loss": 0.3454,
      "step": 470
    },
    {
      "epoch": 0.9930178432893716,
      "grad_norm": 0.6776839272781787,
      "learning_rate": 1.0179790100221355e-05,
      "loss": 0.3418,
      "step": 480
    },
    {
      "epoch": 1.0142229118179467,
      "grad_norm": 0.6101314755766356,
      "learning_rate": 9.852896388742641e-06,
      "loss": 0.3053,
      "step": 490
    },
    {
      "epoch": 1.034910783553142,
      "grad_norm": 0.6934744325994942,
      "learning_rate": 9.526159871865329e-06,
      "loss": 0.2427,
      "step": 500
    },
    {
      "epoch": 1.0555986552883372,
      "grad_norm": 0.617421188429402,
      "learning_rate": 9.199929699525947e-06,
      "loss": 0.2408,
      "step": 510
    },
    {
      "epoch": 1.0762865270235324,
      "grad_norm": 0.6235359309836073,
      "learning_rate": 8.874554480582334e-06,
      "loss": 0.2411,
      "step": 520
    },
    {
      "epoch": 1.0969743987587277,
      "grad_norm": 0.6441892129625907,
      "learning_rate": 8.55038191029099e-06,
      "loss": 0.2411,
      "step": 530
    },
    {
      "epoch": 1.117662270493923,
      "grad_norm": 0.6434908537585953,
      "learning_rate": 8.227758398760653e-06,
      "loss": 0.2387,
      "step": 540
    },
    {
      "epoch": 1.1383501422291182,
      "grad_norm": 0.6594483843896437,
      "learning_rate": 7.907028700779215e-06,
      "loss": 0.2343,
      "step": 550
    },
    {
      "epoch": 1.1590380139643135,
      "grad_norm": 0.6960675162725282,
      "learning_rate": 7.588535547409502e-06,
      "loss": 0.2231,
      "step": 560
    },
    {
      "epoch": 1.1797258856995088,
      "grad_norm": 0.5971350337269328,
      "learning_rate": 7.27261927974759e-06,
      "loss": 0.237,
      "step": 570
    },
    {
      "epoch": 1.200413757434704,
      "grad_norm": 0.6424112287916559,
      "learning_rate": 6.9596174852350585e-06,
      "loss": 0.2432,
      "step": 580
    },
    {
      "epoch": 1.221101629169899,
      "grad_norm": 0.6438237304568722,
      "learning_rate": 6.649864636913768e-06,
      "loss": 0.232,
      "step": 590
    },
    {
      "epoch": 1.2417895009050943,
      "grad_norm": 0.6313443589727364,
      "learning_rate": 6.343691736008691e-06,
      "loss": 0.2405,
      "step": 600
    },
    {
      "epoch": 1.2624773726402896,
      "grad_norm": 0.6715234673959064,
      "learning_rate": 6.041425958220719e-06,
      "loss": 0.2336,
      "step": 610
    },
    {
      "epoch": 1.2831652443754848,
      "grad_norm": 0.6433590220855493,
      "learning_rate": 5.743390304107424e-06,
      "loss": 0.2336,
      "step": 620
    },
    {
      "epoch": 1.30385311611068,
      "grad_norm": 0.6423429994495984,
      "learning_rate": 5.449903253925346e-06,
      "loss": 0.2382,
      "step": 630
    },
    {
      "epoch": 1.3245409878458754,
      "grad_norm": 0.6240555630135617,
      "learning_rate": 5.16127842730268e-06,
      "loss": 0.2369,
      "step": 640
    },
    {
      "epoch": 1.3452288595810706,
      "grad_norm": 0.628887796777515,
      "learning_rate": 4.8778242481060375e-06,
      "loss": 0.2296,
      "step": 650
    },
    {
      "epoch": 1.365916731316266,
      "grad_norm": 0.6257705034061152,
      "learning_rate": 4.599843614859339e-06,
      "loss": 0.2271,
      "step": 660
    },
    {
      "epoch": 1.3866046030514612,
      "grad_norm": 0.636761193154752,
      "learning_rate": 4.327633577067125e-06,
      "loss": 0.2314,
      "step": 670
    },
    {
      "epoch": 1.4072924747866562,
      "grad_norm": 0.6359095191627515,
      "learning_rate": 4.061485017788088e-06,
      "loss": 0.2345,
      "step": 680
    },
    {
      "epoch": 1.4279803465218515,
      "grad_norm": 0.6421464693053279,
      "learning_rate": 3.8016823427980842e-06,
      "loss": 0.2315,
      "step": 690
    },
    {
      "epoch": 1.4486682182570467,
      "grad_norm": 0.6366012008416863,
      "learning_rate": 3.54850317667469e-06,
      "loss": 0.225,
      "step": 700
    },
    {
      "epoch": 1.469356089992242,
      "grad_norm": 0.6576619352554026,
      "learning_rate": 3.3022180661282353e-06,
      "loss": 0.2253,
      "step": 710
    },
    {
      "epoch": 1.4900439617274372,
      "grad_norm": 0.654938148679077,
      "learning_rate": 3.0630901908961297e-06,
      "loss": 0.2154,
      "step": 720
    },
    {
      "epoch": 1.5107318334626325,
      "grad_norm": 0.617919770536757,
      "learning_rate": 2.8313750825095756e-06,
      "loss": 0.23,
      "step": 730
    },
    {
      "epoch": 1.5314197051978278,
      "grad_norm": 0.6222237953826923,
      "learning_rate": 2.6073203512331393e-06,
      "loss": 0.2285,
      "step": 740
    },
    {
      "epoch": 1.552107576933023,
      "grad_norm": 0.7684928903368717,
      "learning_rate": 2.3911654214689385e-06,
      "loss": 0.229,
      "step": 750
    },
    {
      "epoch": 1.5727954486682183,
      "grad_norm": 0.6414607200084983,
      "learning_rate": 2.183141275908247e-06,
      "loss": 0.2195,
      "step": 760
    },
    {
      "epoch": 1.5934833204034136,
      "grad_norm": 0.6352726491905509,
      "learning_rate": 1.9834702087039027e-06,
      "loss": 0.2276,
      "step": 770
    },
    {
      "epoch": 1.6141711921386088,
      "grad_norm": 0.6448153027158089,
      "learning_rate": 1.7923655879272395e-06,
      "loss": 0.2231,
      "step": 780
    },
    {
      "epoch": 1.634859063873804,
      "grad_norm": 0.6292176916531397,
      "learning_rate": 1.6100316275634265e-06,
      "loss": 0.2182,
      "step": 790
    },
    {
      "epoch": 1.6555469356089993,
      "grad_norm": 0.648542041830972,
      "learning_rate": 1.4366631692888656e-06,
      "loss": 0.2225,
      "step": 800
    },
    {
      "epoch": 1.6762348073441946,
      "grad_norm": 0.6103637822490542,
      "learning_rate": 1.2724454742637714e-06,
      "loss": 0.2224,
      "step": 810
    },
    {
      "epoch": 1.6969226790793899,
      "grad_norm": 0.6362748843169189,
      "learning_rate": 1.1175540251625106e-06,
      "loss": 0.2222,
      "step": 820
    },
    {
      "epoch": 1.717610550814585,
      "grad_norm": 0.6421936815476854,
      "learning_rate": 9.721543386531907e-07,
      "loss": 0.2322,
      "step": 830
    },
    {
      "epoch": 1.7382984225497802,
      "grad_norm": 0.6298918304897112,
      "learning_rate": 8.364017885269026e-07,
      "loss": 0.2278,
      "step": 840
    },
    {
      "epoch": 1.7589862942849754,
      "grad_norm": 0.6274637168242054,
      "learning_rate": 7.10441439665629e-07,
      "loss": 0.224,
      "step": 850
    },
    {
      "epoch": 1.7796741660201707,
      "grad_norm": 0.6671628057889898,
      "learning_rate": 5.94407893026222e-07,
      "loss": 0.2191,
      "step": 860
    },
    {
      "epoch": 1.800362037755366,
      "grad_norm": 0.7236025576696403,
      "learning_rate": 4.884251418061092e-07,
      "loss": 0.2283,
      "step": 870
    },
    {
      "epoch": 1.821049909490561,
      "grad_norm": 0.6617252706414912,
      "learning_rate": 3.9260643894443063e-07,
      "loss": 0.2233,
      "step": 880
    },
    {
      "epoch": 1.8417377812257563,
      "grad_norm": 0.6211010418071009,
      "learning_rate": 3.0705417610019886e-07,
      "loss": 0.2188,
      "step": 890
    },
    {
      "epoch": 1.8624256529609515,
      "grad_norm": 0.6162898499201198,
      "learning_rate": 2.3185977423678453e-07,
      "loss": 0.228,
      "step": 900
    },
    {
      "epoch": 1.8831135246961468,
      "grad_norm": 0.6143268905275987,
      "learning_rate": 1.671035859296788e-07,
      "loss": 0.2229,
      "step": 910
    },
    {
      "epoch": 1.903801396431342,
      "grad_norm": 0.6658406651906165,
      "learning_rate": 1.1285480950189997e-07,
      "loss": 0.2214,
      "step": 920
    },
    {
      "epoch": 1.9244892681665373,
      "grad_norm": 0.6902590513353046,
      "learning_rate": 6.91714150788192e-08,
      "loss": 0.2231,
      "step": 930
    },
    {
      "epoch": 1.9451771399017326,
      "grad_norm": 0.6318464604862816,
      "learning_rate": 3.6100082641405964e-08,
      "loss": 0.2178,
      "step": 940
    },
    {
      "epoch": 1.9658650116369278,
      "grad_norm": 0.6755187302729113,
      "learning_rate": 1.3676152144105336e-08,
      "loss": 0.2249,
      "step": 950
    },
    {
      "epoch": 1.986552883372123,
      "grad_norm": 0.6622645751334488,
      "learning_rate": 1.9235857506316734e-09,
      "loss": 0.2229,
      "step": 960
    },
    {
      "epoch": 1.9989656064132402,
      "step": 966,
      "total_flos": 680809548349440.0,
      "train_loss": 0.3105136875533663,
      "train_runtime": 21710.2865,
      "train_samples_per_second": 8.548,
      "train_steps_per_second": 0.044
    }
  ],
  "logging_steps": 10,
  "max_steps": 966,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 680809548349440.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
