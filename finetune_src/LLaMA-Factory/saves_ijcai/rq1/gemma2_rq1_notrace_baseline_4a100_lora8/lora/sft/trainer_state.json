{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.9983379501385041,
  "eval_steps": 500,
  "global_step": 1352,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.014773776546629732,
      "grad_norm": 0.30368557572364807,
      "learning_rate": 1.9999320061480424e-05,
      "loss": 0.7429,
      "step": 10
    },
    {
      "epoch": 0.029547553093259463,
      "grad_norm": 0.22885435819625854,
      "learning_rate": 1.999388110809091e-05,
      "loss": 0.6584,
      "step": 20
    },
    {
      "epoch": 0.0443213296398892,
      "grad_norm": 0.2745916545391083,
      "learning_rate": 1.9983006159734433e-05,
      "loss": 0.5941,
      "step": 30
    },
    {
      "epoch": 0.05909510618651893,
      "grad_norm": 0.1980789303779602,
      "learning_rate": 1.9966701131646914e-05,
      "loss": 0.5468,
      "step": 40
    },
    {
      "epoch": 0.07386888273314866,
      "grad_norm": 0.18705151975154877,
      "learning_rate": 1.9944974892660158e-05,
      "loss": 0.5092,
      "step": 50
    },
    {
      "epoch": 0.0886426592797784,
      "grad_norm": 0.18957000970840454,
      "learning_rate": 1.991783926037781e-05,
      "loss": 0.5178,
      "step": 60
    },
    {
      "epoch": 0.10341643582640812,
      "grad_norm": 0.19624371826648712,
      "learning_rate": 1.988530899474737e-05,
      "loss": 0.4987,
      "step": 70
    },
    {
      "epoch": 0.11819021237303785,
      "grad_norm": 0.20331290364265442,
      "learning_rate": 1.9847401790031792e-05,
      "loss": 0.4988,
      "step": 80
    },
    {
      "epoch": 0.1329639889196676,
      "grad_norm": 0.21194866299629211,
      "learning_rate": 1.9804138265184995e-05,
      "loss": 0.4996,
      "step": 90
    },
    {
      "epoch": 0.14773776546629733,
      "grad_norm": 0.22733961045742035,
      "learning_rate": 1.9755541952636553e-05,
      "loss": 0.4962,
      "step": 100
    },
    {
      "epoch": 0.16251154201292706,
      "grad_norm": 0.22823475301265717,
      "learning_rate": 1.9701639285491633e-05,
      "loss": 0.4721,
      "step": 110
    },
    {
      "epoch": 0.1772853185595568,
      "grad_norm": 0.23144373297691345,
      "learning_rate": 1.96424595831532e-05,
      "loss": 0.4787,
      "step": 120
    },
    {
      "epoch": 0.19205909510618652,
      "grad_norm": 0.2501784563064575,
      "learning_rate": 1.9578035035374214e-05,
      "loss": 0.4741,
      "step": 130
    },
    {
      "epoch": 0.20683287165281625,
      "grad_norm": 0.2650637924671173,
      "learning_rate": 1.9508400684748615e-05,
      "loss": 0.4994,
      "step": 140
    },
    {
      "epoch": 0.22160664819944598,
      "grad_norm": 0.27288320660591125,
      "learning_rate": 1.9433594407650493e-05,
      "loss": 0.4683,
      "step": 150
    },
    {
      "epoch": 0.2363804247460757,
      "grad_norm": 0.24692562222480774,
      "learning_rate": 1.9353656893631923e-05,
      "loss": 0.4648,
      "step": 160
    },
    {
      "epoch": 0.25115420129270544,
      "grad_norm": 0.29137831926345825,
      "learning_rate": 1.926863162329061e-05,
      "loss": 0.4632,
      "step": 170
    },
    {
      "epoch": 0.2659279778393352,
      "grad_norm": 0.27519652247428894,
      "learning_rate": 1.9178564844619362e-05,
      "loss": 0.4647,
      "step": 180
    },
    {
      "epoch": 0.2807017543859649,
      "grad_norm": 0.27773937582969666,
      "learning_rate": 1.908350554785032e-05,
      "loss": 0.4591,
      "step": 190
    },
    {
      "epoch": 0.29547553093259465,
      "grad_norm": 0.27238771319389343,
      "learning_rate": 1.898350543880761e-05,
      "loss": 0.4534,
      "step": 200
    },
    {
      "epoch": 0.31024930747922436,
      "grad_norm": 0.2826217710971832,
      "learning_rate": 1.8878618910782834e-05,
      "loss": 0.4454,
      "step": 210
    },
    {
      "epoch": 0.3250230840258541,
      "grad_norm": 0.27760836482048035,
      "learning_rate": 1.8768903014948838e-05,
      "loss": 0.4397,
      "step": 220
    },
    {
      "epoch": 0.3397968605724838,
      "grad_norm": 0.29725316166877747,
      "learning_rate": 1.865441742932771e-05,
      "loss": 0.4463,
      "step": 230
    },
    {
      "epoch": 0.3545706371191136,
      "grad_norm": 0.33152055740356445,
      "learning_rate": 1.8535224426329992e-05,
      "loss": 0.4562,
      "step": 240
    },
    {
      "epoch": 0.36934441366574333,
      "grad_norm": 0.3028409779071808,
      "learning_rate": 1.841138883888269e-05,
      "loss": 0.4388,
      "step": 250
    },
    {
      "epoch": 0.38411819021237303,
      "grad_norm": 0.3562365472316742,
      "learning_rate": 1.8282978025164553e-05,
      "loss": 0.4374,
      "step": 260
    },
    {
      "epoch": 0.3988919667590028,
      "grad_norm": 0.3009369969367981,
      "learning_rate": 1.8150061831967786e-05,
      "loss": 0.4406,
      "step": 270
    },
    {
      "epoch": 0.4136657433056325,
      "grad_norm": 0.33146724104881287,
      "learning_rate": 1.8012712556706117e-05,
      "loss": 0.4464,
      "step": 280
    },
    {
      "epoch": 0.42843951985226225,
      "grad_norm": 0.34507840871810913,
      "learning_rate": 1.787100490808991e-05,
      "loss": 0.4386,
      "step": 290
    },
    {
      "epoch": 0.44321329639889195,
      "grad_norm": 0.3289661705493927,
      "learning_rate": 1.7725015965489656e-05,
      "loss": 0.4382,
      "step": 300
    },
    {
      "epoch": 0.4579870729455217,
      "grad_norm": 0.3247112035751343,
      "learning_rate": 1.757482513701004e-05,
      "loss": 0.4474,
      "step": 310
    },
    {
      "epoch": 0.4727608494921514,
      "grad_norm": 0.34488755464553833,
      "learning_rate": 1.7420514116297294e-05,
      "loss": 0.4506,
      "step": 320
    },
    {
      "epoch": 0.48753462603878117,
      "grad_norm": 0.3364969789981842,
      "learning_rate": 1.7262166838103373e-05,
      "loss": 0.4496,
      "step": 330
    },
    {
      "epoch": 0.5023084025854109,
      "grad_norm": 0.3374275863170624,
      "learning_rate": 1.7099869432631152e-05,
      "loss": 0.4384,
      "step": 340
    },
    {
      "epoch": 0.5170821791320406,
      "grad_norm": 0.34164977073669434,
      "learning_rate": 1.6933710178685406e-05,
      "loss": 0.4486,
      "step": 350
    },
    {
      "epoch": 0.5318559556786704,
      "grad_norm": 0.3412092328071594,
      "learning_rate": 1.6763779455655122e-05,
      "loss": 0.4441,
      "step": 360
    },
    {
      "epoch": 0.5466297322253001,
      "grad_norm": 0.3552905321121216,
      "learning_rate": 1.6590169694353227e-05,
      "loss": 0.4338,
      "step": 370
    },
    {
      "epoch": 0.5614035087719298,
      "grad_norm": 0.3690870702266693,
      "learning_rate": 1.6412975326740485e-05,
      "loss": 0.4446,
      "step": 380
    },
    {
      "epoch": 0.5761772853185596,
      "grad_norm": 0.3917013704776764,
      "learning_rate": 1.623229273456089e-05,
      "loss": 0.4412,
      "step": 390
    },
    {
      "epoch": 0.5909510618651893,
      "grad_norm": 0.3627662658691406,
      "learning_rate": 1.6048220196916537e-05,
      "loss": 0.4326,
      "step": 400
    },
    {
      "epoch": 0.605724838411819,
      "grad_norm": 0.38999035954475403,
      "learning_rate": 1.5860857836810427e-05,
      "loss": 0.432,
      "step": 410
    },
    {
      "epoch": 0.6204986149584487,
      "grad_norm": 0.3350315988063812,
      "learning_rate": 1.567030756668634e-05,
      "loss": 0.4422,
      "step": 420
    },
    {
      "epoch": 0.6352723915050785,
      "grad_norm": 0.33030855655670166,
      "learning_rate": 1.5476673032995345e-05,
      "loss": 0.4208,
      "step": 430
    },
    {
      "epoch": 0.6500461680517082,
      "grad_norm": 0.44963347911834717,
      "learning_rate": 1.5280059559819177e-05,
      "loss": 0.4413,
      "step": 440
    },
    {
      "epoch": 0.6648199445983379,
      "grad_norm": 0.3450147211551666,
      "learning_rate": 1.5080574091581031e-05,
      "loss": 0.4332,
      "step": 450
    },
    {
      "epoch": 0.6795937211449676,
      "grad_norm": 0.42091065645217896,
      "learning_rate": 1.4878325134875046e-05,
      "loss": 0.4353,
      "step": 460
    },
    {
      "epoch": 0.6943674976915974,
      "grad_norm": 0.38180476427078247,
      "learning_rate": 1.4673422699446078e-05,
      "loss": 0.4344,
      "step": 470
    },
    {
      "epoch": 0.7091412742382271,
      "grad_norm": 0.4219379425048828,
      "learning_rate": 1.4465978238351812e-05,
      "loss": 0.4361,
      "step": 480
    },
    {
      "epoch": 0.7239150507848569,
      "grad_norm": 0.36758485436439514,
      "learning_rate": 1.4256104587339869e-05,
      "loss": 0.4464,
      "step": 490
    },
    {
      "epoch": 0.7386888273314867,
      "grad_norm": 0.38270190358161926,
      "learning_rate": 1.4043915903472777e-05,
      "loss": 0.4284,
      "step": 500
    },
    {
      "epoch": 0.7534626038781164,
      "grad_norm": 0.38080263137817383,
      "learning_rate": 1.382952760303428e-05,
      "loss": 0.4304,
      "step": 510
    },
    {
      "epoch": 0.7682363804247461,
      "grad_norm": 0.4002308249473572,
      "learning_rate": 1.3613056298750641e-05,
      "loss": 0.436,
      "step": 520
    },
    {
      "epoch": 0.7830101569713758,
      "grad_norm": 0.3834175169467926,
      "learning_rate": 1.3394619736361278e-05,
      "loss": 0.4249,
      "step": 530
    },
    {
      "epoch": 0.7977839335180056,
      "grad_norm": 0.40361613035202026,
      "learning_rate": 1.3174336730572997e-05,
      "loss": 0.4253,
      "step": 540
    },
    {
      "epoch": 0.8125577100646353,
      "grad_norm": 0.3985684812068939,
      "learning_rate": 1.2952327100432853e-05,
      "loss": 0.4383,
      "step": 550
    },
    {
      "epoch": 0.827331486611265,
      "grad_norm": 0.41503554582595825,
      "learning_rate": 1.2728711604154702e-05,
      "loss": 0.4278,
      "step": 560
    },
    {
      "epoch": 0.8421052631578947,
      "grad_norm": 0.3666650950908661,
      "learning_rate": 1.2503611873434886e-05,
      "loss": 0.4267,
      "step": 570
    },
    {
      "epoch": 0.8568790397045245,
      "grad_norm": 0.4000672996044159,
      "learning_rate": 1.2277150347292854e-05,
      "loss": 0.4291,
      "step": 580
    },
    {
      "epoch": 0.8716528162511542,
      "grad_norm": 0.4108470678329468,
      "learning_rate": 1.2049450205472585e-05,
      "loss": 0.4362,
      "step": 590
    },
    {
      "epoch": 0.8864265927977839,
      "grad_norm": 0.41372424364089966,
      "learning_rate": 1.1820635301441168e-05,
      "loss": 0.4071,
      "step": 600
    },
    {
      "epoch": 0.9012003693444137,
      "grad_norm": 0.40422990918159485,
      "learning_rate": 1.1590830095020896e-05,
      "loss": 0.4352,
      "step": 610
    },
    {
      "epoch": 0.9159741458910434,
      "grad_norm": 0.4114076495170593,
      "learning_rate": 1.1360159584691529e-05,
      "loss": 0.4355,
      "step": 620
    },
    {
      "epoch": 0.9307479224376731,
      "grad_norm": 0.42024925351142883,
      "learning_rate": 1.1128749239599603e-05,
      "loss": 0.4252,
      "step": 630
    },
    {
      "epoch": 0.9455216989843028,
      "grad_norm": 0.4221544563770294,
      "learning_rate": 1.0896724931311693e-05,
      "loss": 0.424,
      "step": 640
    },
    {
      "epoch": 0.9602954755309326,
      "grad_norm": 0.46255800127983093,
      "learning_rate": 1.0664212865348798e-05,
      "loss": 0.42,
      "step": 650
    },
    {
      "epoch": 0.9750692520775623,
      "grad_norm": 0.40400803089141846,
      "learning_rate": 1.0431339512539082e-05,
      "loss": 0.4132,
      "step": 660
    },
    {
      "epoch": 0.989843028624192,
      "grad_norm": 0.4575559198856354,
      "learning_rate": 1.0198231540226307e-05,
      "loss": 0.4276,
      "step": 670
    },
    {
      "epoch": 1.005540166204986,
      "grad_norm": 0.41040489077568054,
      "learning_rate": 9.965015743371368e-06,
      "loss": 0.4513,
      "step": 680
    },
    {
      "epoch": 1.020313942751616,
      "grad_norm": 0.4531465172767639,
      "learning_rate": 9.7318189755844e-06,
      "loss": 0.4323,
      "step": 690
    },
    {
      "epoch": 1.0350877192982457,
      "grad_norm": 0.4640171527862549,
      "learning_rate": 9.49876808012503e-06,
      "loss": 0.4209,
      "step": 700
    },
    {
      "epoch": 1.0498614958448753,
      "grad_norm": 0.5330958962440491,
      "learning_rate": 9.2659898209082e-06,
      "loss": 0.4241,
      "step": 710
    },
    {
      "epoch": 1.0646352723915051,
      "grad_norm": 0.4762114882469177,
      "learning_rate": 9.033610813553196e-06,
      "loss": 0.4173,
      "step": 720
    },
    {
      "epoch": 1.0794090489381347,
      "grad_norm": 0.4255176782608032,
      "learning_rate": 8.801757456513306e-06,
      "loss": 0.4043,
      "step": 730
    },
    {
      "epoch": 1.0941828254847645,
      "grad_norm": 0.4135897159576416,
      "learning_rate": 8.570555862323612e-06,
      "loss": 0.4195,
      "step": 740
    },
    {
      "epoch": 1.1089566020313943,
      "grad_norm": 0.39713388681411743,
      "learning_rate": 8.340131789004334e-06,
      "loss": 0.4191,
      "step": 750
    },
    {
      "epoch": 1.123730378578024,
      "grad_norm": 0.42913374304771423,
      "learning_rate": 8.110610571656946e-06,
      "loss": 0.4283,
      "step": 760
    },
    {
      "epoch": 1.1385041551246537,
      "grad_norm": 0.4467225670814514,
      "learning_rate": 7.882117054290375e-06,
      "loss": 0.4201,
      "step": 770
    },
    {
      "epoch": 1.1532779316712836,
      "grad_norm": 0.4781864285469055,
      "learning_rate": 7.65477552191432e-06,
      "loss": 0.426,
      "step": 780
    },
    {
      "epoch": 1.1680517082179132,
      "grad_norm": 0.43485039472579956,
      "learning_rate": 7.428709632936599e-06,
      "loss": 0.4234,
      "step": 790
    },
    {
      "epoch": 1.182825484764543,
      "grad_norm": 0.4185786545276642,
      "learning_rate": 7.204042351901359e-06,
      "loss": 0.414,
      "step": 800
    },
    {
      "epoch": 1.1975992613111726,
      "grad_norm": 0.40078961849212646,
      "learning_rate": 6.98089588260467e-06,
      "loss": 0.41,
      "step": 810
    },
    {
      "epoch": 1.2123730378578024,
      "grad_norm": 0.41888427734375,
      "learning_rate": 6.75939160162395e-06,
      "loss": 0.4139,
      "step": 820
    },
    {
      "epoch": 1.2271468144044322,
      "grad_norm": 0.42936626076698303,
      "learning_rate": 6.539649992297311e-06,
      "loss": 0.4255,
      "step": 830
    },
    {
      "epoch": 1.2419205909510618,
      "grad_norm": 0.4064824879169464,
      "learning_rate": 6.321790579188773e-06,
      "loss": 0.4041,
      "step": 840
    },
    {
      "epoch": 1.2566943674976916,
      "grad_norm": 0.46478480100631714,
      "learning_rate": 6.105931863074995e-06,
      "loss": 0.4107,
      "step": 850
    },
    {
      "epoch": 1.2714681440443214,
      "grad_norm": 0.4308682978153229,
      "learning_rate": 5.8921912564888775e-06,
      "loss": 0.4092,
      "step": 860
    },
    {
      "epoch": 1.286241920590951,
      "grad_norm": 0.41336485743522644,
      "learning_rate": 5.680685019855084e-06,
      "loss": 0.3988,
      "step": 870
    },
    {
      "epoch": 1.3010156971375808,
      "grad_norm": 0.45081230998039246,
      "learning_rate": 5.471528198252224e-06,
      "loss": 0.4116,
      "step": 880
    },
    {
      "epoch": 1.3157894736842106,
      "grad_norm": 0.5140630006790161,
      "learning_rate": 5.264834558836156e-06,
      "loss": 0.4078,
      "step": 890
    },
    {
      "epoch": 1.3305632502308402,
      "grad_norm": 0.4621298909187317,
      "learning_rate": 5.060716528958316e-06,
      "loss": 0.4164,
      "step": 900
    },
    {
      "epoch": 1.34533702677747,
      "grad_norm": 0.45160460472106934,
      "learning_rate": 4.8592851350128615e-06,
      "loss": 0.4156,
      "step": 910
    },
    {
      "epoch": 1.3601108033240998,
      "grad_norm": 0.4537543058395386,
      "learning_rate": 4.660649942045826e-06,
      "loss": 0.4008,
      "step": 920
    },
    {
      "epoch": 1.3748845798707294,
      "grad_norm": 0.48568663001060486,
      "learning_rate": 4.464918994159154e-06,
      "loss": 0.4215,
      "step": 930
    },
    {
      "epoch": 1.3896583564173592,
      "grad_norm": 0.4289899468421936,
      "learning_rate": 4.272198755742011e-06,
      "loss": 0.4012,
      "step": 940
    },
    {
      "epoch": 1.404432132963989,
      "grad_norm": 0.408372163772583,
      "learning_rate": 4.082594053561369e-06,
      "loss": 0.4128,
      "step": 950
    },
    {
      "epoch": 1.4192059095106186,
      "grad_norm": 0.43147575855255127,
      "learning_rate": 3.89620801974334e-06,
      "loss": 0.4026,
      "step": 960
    },
    {
      "epoch": 1.4339796860572485,
      "grad_norm": 0.4910199046134949,
      "learning_rate": 3.7131420356762726e-06,
      "loss": 0.4288,
      "step": 970
    },
    {
      "epoch": 1.448753462603878,
      "grad_norm": 0.483407586812973,
      "learning_rate": 3.533495676866141e-06,
      "loss": 0.4107,
      "step": 980
    },
    {
      "epoch": 1.4635272391505079,
      "grad_norm": 0.46970105171203613,
      "learning_rate": 3.3573666587742192e-06,
      "loss": 0.3995,
      "step": 990
    },
    {
      "epoch": 1.4783010156971375,
      "grad_norm": 0.4364846348762512,
      "learning_rate": 3.1848507836664634e-06,
      "loss": 0.4054,
      "step": 1000
    },
    {
      "epoch": 1.4930747922437673,
      "grad_norm": 0.4780067503452301,
      "learning_rate": 3.016041888503578e-06,
      "loss": 0.4102,
      "step": 1010
    },
    {
      "epoch": 1.507848568790397,
      "grad_norm": 0.43761879205703735,
      "learning_rate": 2.8510317939000474e-06,
      "loss": 0.4141,
      "step": 1020
    },
    {
      "epoch": 1.5226223453370267,
      "grad_norm": 0.47140106558799744,
      "learning_rate": 2.689910254179949e-06,
      "loss": 0.4015,
      "step": 1030
    },
    {
      "epoch": 1.5373961218836565,
      "grad_norm": 0.4407450556755066,
      "learning_rate": 2.532764908556675e-06,
      "loss": 0.4245,
      "step": 1040
    },
    {
      "epoch": 1.5521698984302863,
      "grad_norm": 0.42477914690971375,
      "learning_rate": 2.379681233463118e-06,
      "loss": 0.4126,
      "step": 1050
    },
    {
      "epoch": 1.566943674976916,
      "grad_norm": 0.4394546449184418,
      "learning_rate": 2.2307424960582836e-06,
      "loss": 0.4173,
      "step": 1060
    },
    {
      "epoch": 1.5817174515235457,
      "grad_norm": 0.4533335864543915,
      "learning_rate": 2.0860297089355943e-06,
      "loss": 0.4217,
      "step": 1070
    },
    {
      "epoch": 1.5964912280701755,
      "grad_norm": 0.4041076898574829,
      "learning_rate": 1.945621586057519e-06,
      "loss": 0.4209,
      "step": 1080
    },
    {
      "epoch": 1.611265004616805,
      "grad_norm": 0.50835120677948,
      "learning_rate": 1.8095944999405025e-06,
      "loss": 0.4102,
      "step": 1090
    },
    {
      "epoch": 1.626038781163435,
      "grad_norm": 0.4748114347457886,
      "learning_rate": 1.6780224401134903e-06,
      "loss": 0.4132,
      "step": 1100
    },
    {
      "epoch": 1.6408125577100647,
      "grad_norm": 0.44062405824661255,
      "learning_rate": 1.5509769728726243e-06,
      "loss": 0.4128,
      "step": 1110
    },
    {
      "epoch": 1.6555863342566943,
      "grad_norm": 0.44341906905174255,
      "learning_rate": 1.4285272023540297e-06,
      "loss": 0.4263,
      "step": 1120
    },
    {
      "epoch": 1.6703601108033241,
      "grad_norm": 0.46035322546958923,
      "learning_rate": 1.3107397329458348e-06,
      "loss": 0.411,
      "step": 1130
    },
    {
      "epoch": 1.685133887349954,
      "grad_norm": 0.4693083167076111,
      "learning_rate": 1.1976786330598978e-06,
      "loss": 0.4175,
      "step": 1140
    },
    {
      "epoch": 1.6999076638965835,
      "grad_norm": 0.48193198442459106,
      "learning_rate": 1.0894054002829192e-06,
      "loss": 0.4159,
      "step": 1150
    },
    {
      "epoch": 1.7146814404432131,
      "grad_norm": 0.6876865029335022,
      "learning_rate": 9.859789279259225e-07,
      "loss": 0.4274,
      "step": 1160
    },
    {
      "epoch": 1.7294552169898432,
      "grad_norm": 0.4514949321746826,
      "learning_rate": 8.874554729902796e-07,
      "loss": 0.4182,
      "step": 1170
    },
    {
      "epoch": 1.7442289935364728,
      "grad_norm": 0.5673884749412537,
      "learning_rate": 7.938886255676992e-07,
      "loss": 0.4223,
      "step": 1180
    },
    {
      "epoch": 1.7590027700831024,
      "grad_norm": 0.4316501319408417,
      "learning_rate": 7.053292796908629e-07,
      "loss": 0.413,
      "step": 1190
    },
    {
      "epoch": 1.7737765466297324,
      "grad_norm": 0.46359217166900635,
      "learning_rate": 6.218256056504923e-07,
      "loss": 0.4295,
      "step": 1200
    },
    {
      "epoch": 1.788550323176362,
      "grad_norm": 0.4594498574733734,
      "learning_rate": 5.434230237939919e-07,
      "loss": 0.4072,
      "step": 1210
    },
    {
      "epoch": 1.8033240997229916,
      "grad_norm": 0.46312394738197327,
      "learning_rate": 4.701641798198353e-07,
      "loss": 0.4122,
      "step": 1220
    },
    {
      "epoch": 1.8180978762696214,
      "grad_norm": 0.46581628918647766,
      "learning_rate": 4.020889215812085e-07,
      "loss": 0.4076,
      "step": 1230
    },
    {
      "epoch": 1.8328716528162512,
      "grad_norm": 0.45050424337387085,
      "learning_rate": 3.392342774114643e-07,
      "loss": 0.4171,
      "step": 1240
    },
    {
      "epoch": 1.8476454293628808,
      "grad_norm": 0.4735950827598572,
      "learning_rate": 2.81634435983219e-07,
      "loss": 0.4003,
      "step": 1250
    },
    {
      "epoch": 1.8624192059095106,
      "grad_norm": 0.43260666728019714,
      "learning_rate": 2.2932072771202464e-07,
      "loss": 0.406,
      "step": 1260
    },
    {
      "epoch": 1.8771929824561404,
      "grad_norm": 0.49645787477493286,
      "learning_rate": 1.8232160771474494e-07,
      "loss": 0.422,
      "step": 1270
    },
    {
      "epoch": 1.89196675900277,
      "grad_norm": 0.5024728775024414,
      "learning_rate": 1.4066264033190002e-07,
      "loss": 0.4208,
      "step": 1280
    },
    {
      "epoch": 1.9067405355493998,
      "grad_norm": 0.43229833245277405,
      "learning_rate": 1.0436648522239245e-07,
      "loss": 0.4047,
      "step": 1290
    },
    {
      "epoch": 1.9215143120960296,
      "grad_norm": 0.4683065712451935,
      "learning_rate": 7.345288503818771e-08,
      "loss": 0.4116,
      "step": 1300
    },
    {
      "epoch": 1.9362880886426592,
      "grad_norm": 0.47505122423171997,
      "learning_rate": 4.79386546856464e-08,
      "loss": 0.4162,
      "step": 1310
    },
    {
      "epoch": 1.951061865189289,
      "grad_norm": 0.44137197732925415,
      "learning_rate": 2.7837672179351625e-08,
      "loss": 0.4214,
      "step": 1320
    },
    {
      "epoch": 1.9658356417359188,
      "grad_norm": 0.49393004179000854,
      "learning_rate": 1.3160871093416127e-08,
      "loss": 0.4246,
      "step": 1330
    },
    {
      "epoch": 1.9806094182825484,
      "grad_norm": 0.5956236124038696,
      "learning_rate": 3.916234614346204e-09,
      "loss": 0.3963,
      "step": 1340
    },
    {
      "epoch": 1.9953831948291783,
      "grad_norm": 0.4487331807613373,
      "learning_rate": 1.0879119873852262e-10,
      "loss": 0.3989,
      "step": 1350
    },
    {
      "epoch": 1.9983379501385041,
      "step": 1352,
      "total_flos": 5.280528142497219e+18,
      "train_loss": 0.4366567368955302,
      "train_runtime": 10906.8132,
      "train_samples_per_second": 11.915,
      "train_steps_per_second": 0.124
    }
  ],
  "logging_steps": 10,
  "max_steps": 1352,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.280528142497219e+18,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
